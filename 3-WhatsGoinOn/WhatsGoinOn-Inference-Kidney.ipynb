{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-njGXZoIu7l",
    "papermill": {
     "duration": 0.009365,
     "end_time": "2021-05-12T18:31:16.661237",
     "exception": false,
     "start_time": "2021-05-12T18:31:16.651872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1> HubMap - Hacking the Kidney </h1>\n",
    "<h3> Goal - Mapping the human body at function tissue unit level - detect glomeuli FTUs in kidney </h3>\n",
    "\n",
    "Implementation of Kaggle Notebook - Accuracy Prize Winner - WhatsGoinOn <br>\n",
    "Description - Use 2-5 fold models to predict on test image masks <br>\n",
    "Input - models, test images, sample_submission.csv  <br>\n",
    "Output - submission_whatsgoinon.csv (rle for test images) <br>\n",
    "\n",
    "<b>How to use?</b><br> \n",
    "Change the basepath to where your data lives and you're good to go. <br>\n",
    "\n",
    "<h6> Step 1 - Import useful libraries </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-12T18:31:16.685202Z",
     "iopub.status.busy": "2021-05-12T18:31:16.684395Z",
     "iopub.status.idle": "2021-05-12T18:31:19.754541Z",
     "shell.execute_reply": "2021-05-12T18:31:19.753943Z"
    },
    "id": "pHEON1kvIu7r",
    "papermill": {
     "duration": 3.08492,
     "end_time": "2021-05-12T18:31:19.754675",
     "exception": false,
     "start_time": "2021-05-12T18:31:16.669755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsC7s0NBIu7s",
    "papermill": {
     "duration": 0.008339,
     "end_time": "2021-05-12T18:31:19.811650",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.803311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h6> Step 2 - Helper functions </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-05-12T18:31:19.845150Z",
     "iopub.status.busy": "2021-05-12T18:31:19.844195Z",
     "iopub.status.idle": "2021-05-12T18:31:19.846957Z",
     "shell.execute_reply": "2021-05-12T18:31:19.846517Z"
    },
    "id": "bjjwgkUnIu7s",
    "papermill": {
     "duration": 0.026863,
     "end_time": "2021-05-12T18:31:19.847047",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.820184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions to convert encoding to mask and mask to encoding\n",
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for m,enc in enumerate(encs):\n",
    "        if isinstance(enc,np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2enc(mask, n=1):\n",
    "    pixels = mask.T.flatten()\n",
    "    encs = []\n",
    "    for i in range(1,n+1):\n",
    "        p = (pixels == i).astype(np.int8)\n",
    "        if p.sum() == 0: encs.append(np.nan)\n",
    "        else:\n",
    "            p = np.concatenate([[0], p, [0]])\n",
    "            runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "            runs[1::2] -= runs[::2]\n",
    "            encs.append(' '.join(str(x) for x in runs))\n",
    "    return encs\n",
    "\n",
    "#https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n",
    "#with transposed mask\n",
    "def rle_encode_less_memory(img):\n",
    "    #the image should be transposed\n",
    "    pixels = img.T.flatten()\n",
    "    \n",
    "    # This simplified method requires first and last pixel to be zero\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    \n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T18:31:19.894110Z",
     "iopub.status.busy": "2021-05-12T18:31:19.878060Z",
     "iopub.status.idle": "2021-05-12T18:31:19.896896Z",
     "shell.execute_reply": "2021-05-12T18:31:19.896436Z"
    },
    "id": "TR94UeLoIu7t",
    "papermill": {
     "duration": 0.041336,
     "end_time": "2021-05-12T18:31:19.896992",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.855656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sz = 2048   #the size of tiles\n",
    "sz_reduction = 2 #reduce the original images by 4 times\n",
    "expansion = 512\n",
    "TH = 0.5  #threshold for positive predictions\n",
    "\n",
    "# https://www.kaggle.com/iafoss/256x256-images\n",
    "mean = np.array([0.65459856,0.48386562,0.69428385])\n",
    "std = np.array([0.15167958,0.23584107,0.13146145])\n",
    "\n",
    "s_th = 40  #saturation blancking threshold\n",
    "p_th = 1000*(sz//256)**2 #threshold for the minimum number of pixels\n",
    "identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "\n",
    "def img2tensor(img,dtype:np.dtype=np.float32):\n",
    "    if img.ndim==2 : img = np.expand_dims(img,2)\n",
    "    img = np.transpose(img,(2,0,1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self, idx, sz=sz, sz_reduction=sz_reduction, expansion=expansion):\n",
    "        self.data = rasterio.open(os.path.join(test,idx+'.tiff'), transform = identity,\n",
    "                                 num_threads='all_cpus')\n",
    "        # some images have issues with their format \n",
    "        # and must be saved correctly before reading with rasterio\n",
    "        if self.data.count != 3:\n",
    "            subdatasets = self.data.subdatasets\n",
    "            self.layers = []\n",
    "            if len(subdatasets) > 0:\n",
    "                for i, subdataset in enumerate(subdatasets, 0):\n",
    "                    self.layers.append(rasterio.open(subdataset))\n",
    "        self.shape = self.data.shape\n",
    "        self.sz_reduction = sz_reduction\n",
    "        self.sz = sz_reduction*sz\n",
    "        self.expansion = sz_reduction*expansion\n",
    "        self.pad0 = (self.sz - self.shape[0]%self.sz)%self.sz\n",
    "        self.pad1 = (self.sz - self.shape[1]%self.sz)%self.sz\n",
    "        self.n0max = (self.shape[0] + self.pad0)//self.sz\n",
    "        self.n1max = (self.shape[1] + self.pad1)//self.sz\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n0max*self.n1max\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # the code below may be a little bit difficult to understand,\n",
    "        # but the thing it does is mapping the original image to\n",
    "        # tiles created with adding padding, as done in\n",
    "        # https://www.kaggle.com/iafoss/256x256-images ,\n",
    "        # and then the tiles are loaded with rasterio\n",
    "        # n0,n1 - are the x and y index of the tile (idx = n0*self.n1max + n1)\n",
    "        n0,n1 = idx//self.n1max, idx%self.n1max\n",
    "        # x0,y0 - are the coordinates of the lower left corner of the tile in the image\n",
    "        # negative numbers correspond to padding (which must not be loaded)\n",
    "        x0,y0 = -self.pad0//2 + n0*self.sz - self.expansion//2, -self.pad1//2 + n1*self.sz- self.expansion//2\n",
    "        # make sure that the region to read is within the image\n",
    "        p00,p01 = max(0,x0), min(x0+self.sz+self.expansion,self.shape[0])\n",
    "        p10,p11 = max(0,y0), min(y0+self.sz+self.expansion,self.shape[1])\n",
    "        img = np.zeros((self.sz+self.expansion,self.sz+self.expansion,3),np.uint8)\n",
    "        # mapping the loade region to the tile\n",
    "        if self.data.count == 3:\n",
    "            img[(p00-x0):(p01-x0),(p10-y0):(p11-y0)] = np.moveaxis(self.data.read([1,2,3],\n",
    "                window=Window.from_slices((p00,p01),(p10,p11))), 0, -1)\n",
    "        else:\n",
    "            for i,layer in enumerate(self.layers):\n",
    "                img[(p00-x0):(p01-x0),(p10-y0):(p11-y0),i] =\\\n",
    "                  layer.read(1,window=Window.from_slices((p00,p01),(p10,p11)))\n",
    "        \n",
    "        if self.sz_reduction != 1:\n",
    "            img = cv2.resize(img,((self.sz+self.expansion)//self.sz_reduction,(self.sz+self.expansion)//self.sz_reduction),\n",
    "                             interpolation = cv2.INTER_AREA)\n",
    "        #check for empty imges\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h,s,v = cv2.split(hsv)\n",
    "        if (s>s_th).sum() <= p_th or img.sum() <= p_th:\n",
    "            #images with -1 will be skipped\n",
    "            return img2tensor((img/255.0 - mean)/std), -1\n",
    "        else: return img2tensor((img/255.0 - mean)/std), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T18:31:19.932109Z",
     "iopub.status.busy": "2021-05-12T18:31:19.930326Z",
     "iopub.status.idle": "2021-05-12T18:31:19.932698Z",
     "shell.execute_reply": "2021-05-12T18:31:19.933108Z"
    },
    "id": "oza-gjKAIu7t",
    "papermill": {
     "duration": 0.027498,
     "end_time": "2021-05-12T18:31:19.933229",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.905731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterator like wrapper that returns predicted masks\n",
    "class Model_pred:\n",
    "    def __init__(self, models, dl, tta:bool=True, half:bool=False):\n",
    "        self.models = models\n",
    "        self.dl = dl\n",
    "        self.tta = tta\n",
    "        self.half = half\n",
    "        \n",
    "    def __iter__(self):\n",
    "        count=0\n",
    "        with torch.no_grad():\n",
    "            for x,y in iter(self.dl):\n",
    "                if ((y>=0).sum() > 0): #exclude empty images\n",
    "                    x = x[y>=0].to(device)\n",
    "                    y = y[y>=0]\n",
    "                    if self.half: x = x.half()\n",
    "                    py = None\n",
    "                    for model in self.models:\n",
    "                        p = model(x)\n",
    "                        p = torch.sigmoid(p).detach()\n",
    "                        if py is None: py = p\n",
    "                        else: py += p\n",
    "                    if self.tta:\n",
    "                        #x,y,xy flips as TTA\n",
    "                        flips = [[-1],[-2],[-2,-1]]\n",
    "                        for f in flips:\n",
    "                            xf = torch.flip(x,f)\n",
    "                            for model in self.models:\n",
    "                                p = model(xf)\n",
    "                                p = torch.flip(p,f)\n",
    "                                py += torch.sigmoid(p).detach()\n",
    "                        py /= (1+len(flips))        \n",
    "                    py /= len(self.models)\n",
    "\n",
    "                    py = F.upsample(py, scale_factor=sz_reduction, mode=\"bilinear\")\n",
    "                    py = py.permute(0,2,3,1).float().cpu()\n",
    "                    \n",
    "                    batch_size = len(py)\n",
    "                    for i in range(batch_size):\n",
    "                        yield py[i,expansion*sz_reduction//2:-expansion*sz_reduction//2,expansion*sz_reduction//2:-expansion*sz_reduction//2],y[i]\n",
    "                        count += 1\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-05-12T18:31:19.972831Z",
     "iopub.status.busy": "2021-05-12T18:31:19.971923Z",
     "iopub.status.idle": "2021-05-12T18:31:20.021696Z",
     "shell.execute_reply": "2021-05-12T18:31:20.021210Z"
    },
    "id": "gpVGG-_5Iu7u",
    "papermill": {
     "duration": 0.061964,
     "end_time": "2021-05-12T18:31:20.021808",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.959844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# import torch.tensor as Tensor\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self, input_channels:list, output_channels:list):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Sequential(nn.Conv2d(in_ch, out_ch*2, kernel_size=3, padding=1),\n",
    "             nn.ReLU(inplace=True), nn.BatchNorm2d(out_ch*2),\n",
    "             nn.Conv2d(out_ch*2, out_ch, kernel_size=3, padding=1))\n",
    "            for in_ch, out_ch in zip(input_channels, output_channels)])\n",
    "\n",
    "    def forward(self, xs:list, last_layer):\n",
    "        hcs = [F.interpolate(c(x),scale_factor=2**(len(self.convs)-i),mode='bilinear')\n",
    "               for i,(c,x) in enumerate(zip(self.convs, xs))]\n",
    "        hcs.append(last_layer)\n",
    "        return torch.cat(hcs, dim=1)\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in_c:int, x_in_c:int, nf:int=None, blur:bool=False,\n",
    "                 self_attention:bool=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(x_in_c)\n",
    "        ni = up_in_c//2 + x_in_c\n",
    "        nf = nf if nf is not None else max(up_in_c//2,32)\n",
    "        self.conv1 = ConvLayer(ni, nf, norm_type=None, **kwargs)\n",
    "        self.conv2 = ConvLayer(nf, nf, norm_type=None,\n",
    "            xtra=SelfAttention(nf) if self_attention else None, **kwargs)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, up_in:Tensor, left_in:Tensor) -> Tensor:\n",
    "        s = left_in\n",
    "        up_out = self.shuf(up_in)\n",
    "        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n",
    "        return self.conv2(self.conv1(cat_x))\n",
    "\n",
    "class _ASPPModule(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size, padding, dilation, groups=1):\n",
    "        super().__init__()\n",
    "        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                stride=1, padding=padding, dilation=dilation, bias=False, groups=groups)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_conv(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, inplanes=512, mid_c=256, dilations=[6, 12, 18, 24], out_c=None):\n",
    "        super().__init__()\n",
    "        self.aspps = [_ASPPModule(inplanes, mid_c, 1, padding=0, dilation=1)] + \\\n",
    "            [_ASPPModule(inplanes, mid_c, 3, padding=d, dilation=d,groups=4) for d in dilations]\n",
    "        self.aspps = nn.ModuleList(self.aspps)\n",
    "        self.global_pool = nn.Sequential(nn.AdaptiveMaxPool2d((1, 1)),\n",
    "                        nn.Conv2d(inplanes, mid_c, 1, stride=1, bias=False),\n",
    "                        nn.BatchNorm2d(mid_c), nn.ReLU())\n",
    "        out_c = out_c if out_c is not None else mid_c\n",
    "        self.out_conv = nn.Sequential(nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False),\n",
    "                                    nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n",
    "        self.conv1 = nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False)\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.global_pool(x)\n",
    "        xs = [aspp(x) for aspp in self.aspps]\n",
    "        x0 = F.interpolate(x0, size=xs[0].size()[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x0] + xs, dim=1)\n",
    "        return self.out_conv(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "import torch.hub\n",
    "# hub_model = torch.hub.load(\n",
    "#     'moskomule/senet.pytorch',\n",
    "#     'se_resnet50',\n",
    "#     pretrained=True,)\n",
    "import torchvision\n",
    "class UneXt(nn.Module):\n",
    "    def __init__(self, m, stride=1, **kwargs):\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "        # m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models',\n",
    "        #                    'resnext101_32x4d_swsl')\n",
    "#         m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models',\n",
    "#                            'resnext50_32x4d_swsl', pretrained=False)\n",
    "        #m = ResNet(Bottleneck, [3, 4, 23, 3], groups=32, width_per_group=4)\n",
    "        #m = torchvision.models.resnext50_32x4d(pretrained=False)\n",
    "        # m = torch.hub.load(\n",
    "        #     'moskomule/senet.pytorch',\n",
    "        #     'se_resnet101',\n",
    "        #     pretrained=True,)\n",
    "\n",
    "        #m=torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "        self.enc0 = nn.Sequential(m.conv1, m.bn1, nn.ReLU(inplace=True))\n",
    "        self.enc1 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "                            m.layer1) #256\n",
    "        self.enc2 = m.layer2 #512\n",
    "        self.enc3 = m.layer3 #1024\n",
    "        self.enc4 = m.layer4 #2048\n",
    "        #aspp with customized dilatations\n",
    "        self.aspp = ASPP(2048,256,out_c=512,dilations=[stride*1,stride*2,stride*3,stride*4])\n",
    "        self.drop_aspp = nn.Dropout2d(0.5)\n",
    "        #decoder\n",
    "        self.dec4 = UnetBlock(512,1024,256)\n",
    "        self.dec3 = UnetBlock(256,512,128)\n",
    "        self.dec2 = UnetBlock(128,256,64)\n",
    "        self.dec1 = UnetBlock(64,64,32)\n",
    "        self.fpn = FPN([512,256,128,64],[16]*4)\n",
    "        self.drop = nn.Dropout2d(0.1)\n",
    "        self.final_conv = ConvLayer(32+16*4, 1, ks=1, norm_type=None, act_cls=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc0 = self.enc0(x)\n",
    "        enc1 = self.enc1(enc0)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        enc5 = self.aspp(enc4)\n",
    "        dec3 = self.dec4(self.drop_aspp(enc5),enc3)\n",
    "        dec2 = self.dec3(dec3,enc2)\n",
    "        dec1 = self.dec2(dec2,enc1)\n",
    "        dec0 = self.dec1(dec1,enc0)\n",
    "        x = self.fpn([enc5, dec3, dec2, dec1], dec0)\n",
    "        x = self.final_conv(self.drop(x))\n",
    "        x = F.interpolate(x,scale_factor=2,mode='bilinear')\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcJ0WYIuIu7x",
    "papermill": {
     "duration": 0.008819,
     "end_time": "2021-05-12T18:32:04.820874",
     "exception": false,
     "start_time": "2021-05-12T18:32:04.812055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h6> Step 3 - Set configuration and paths </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T18:31:19.785345Z",
     "iopub.status.busy": "2021-05-12T18:31:19.784636Z",
     "iopub.status.idle": "2021-05-12T18:31:19.794209Z",
     "shell.execute_reply": "2021-05-12T18:31:19.793758Z"
    },
    "id": "WfY_KuBPIu7s",
    "papermill": {
     "duration": 0.029592,
     "end_time": "2021-05-12T18:31:19.794350",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.764758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA = Path(r'C:\\Users\\soodn\\Downloads\\Naveksha\\Kaggle HuBMAP\\Data\\kidney-data')\n",
    "MODELS_rsxt50 = [f'model_OG/hubmaptest44/fold{i}.pth' for i in range(5)]\n",
    "MODELS_rsxt101 = [f'model_OG/hubmaptest45/fold{i}.pth' for i in range(5)]\n",
    "\n",
    "test = DATA/'private test'\n",
    "df_sample = pd.read_csv(DATA/'sample_submission_pvt.csv')\n",
    "df_test = pd.read_csv(DATA/'private_test.csv')\n",
    "bs = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T18:31:20.048620Z",
     "iopub.status.busy": "2021-05-12T18:31:20.048003Z",
     "iopub.status.idle": "2021-05-12T18:32:04.802642Z",
     "shell.execute_reply": "2021-05-12T18:32:04.802104Z"
    },
    "id": "4NmLCbtVIu7w",
    "papermill": {
     "duration": 44.771748,
     "end_time": "2021-05-12T18:32:04.802749",
     "exception": false,
     "start_time": "2021-05-12T18:31:20.031001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc \n",
    "models = []\n",
    "for path in MODELS_rsxt50:\n",
    "    state_dict = torch.load(path)\n",
    "    model = UneXt(m=torchvision.models.resnext50_32x4d(pretrained=False)).cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.float()\n",
    "    model.eval()\n",
    "    #model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "for path in MODELS_rsxt101:\n",
    "    state_dict = torch.load(path)\n",
    "    model = UneXt(m=ResNet(Bottleneck, [3, 4, 23, 3], groups=32, width_per_group=4)).cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.float()\n",
    "    model.eval()\n",
    "    #model.to(device)\n",
    "    models.append(model)    \n",
    "    \n",
    "    \n",
    "del state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Step 4 - Make Prediction </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "referenced_widgets": [
      "112d789b9c824b0786d2a71bc3e4f38f"
     ]
    },
    "execution": {
     "iopub.execute_input": "2021-05-12T18:32:04.851742Z",
     "iopub.status.busy": "2021-05-12T18:32:04.851143Z",
     "iopub.status.idle": "2021-05-12T20:15:53.328290Z",
     "shell.execute_reply": "2021-05-12T20:15:53.324774Z"
    },
    "id": "exgfYD2aIu7y",
    "outputId": "ac17da08-7794-4fbe-86f3-b2b308331460",
    "papermill": {
     "duration": 6228.498649,
     "end_time": "2021-05-12T20:15:53.328441",
     "exception": false,
     "start_time": "2021-05-12T18:32:04.829792",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fed19a8e194a5d8a90acadffcddc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names,preds = [],[]\n",
    "for idx,row in tqdm(df_sample.iterrows(),total=len(df_sample)):\n",
    "    idx = row['id']\n",
    "    ds = HuBMAPDataset(idx)\n",
    "    #rasterio cannot be used with multiple workers\n",
    "    dl = DataLoader(ds,bs,num_workers=0,shuffle=False,pin_memory=True)\n",
    "    mp = Model_pred(models,dl)\n",
    "    #generate masks\n",
    "    mask = torch.zeros(len(ds),ds.sz,ds.sz,dtype=torch.int8)\n",
    "    for p,i in iter(mp): \n",
    "        # print(p.shape)\n",
    "        mask[i.item()] = p.squeeze(-1) > TH\n",
    "    \n",
    "    #reshape tiled masks into a single mask and crop padding\n",
    "    mask = mask.view(ds.n0max,ds.n1max,ds.sz,ds.sz).\\\n",
    "        permute(0,2,1,3).reshape(ds.n0max*ds.sz,ds.n1max*ds.sz)\n",
    "    mask = mask[ds.pad0//2:-(ds.pad0-ds.pad0//2) if ds.pad0 > 0 else ds.n0max*ds.sz,\n",
    "        ds.pad1//2:-(ds.pad1-ds.pad1//2) if ds.pad1 > 0 else ds.n1max*ds.sz]\n",
    "    \n",
    "    rle = rle_encode_less_memory(mask.numpy())\n",
    "    names.append(idx)\n",
    "    preds.append(rle)\n",
    "    del mask, ds, dl\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T20:15:53.451599Z",
     "iopub.status.busy": "2021-05-12T20:15:53.450983Z",
     "iopub.status.idle": "2021-05-12T20:15:53.900909Z",
     "shell.execute_reply": "2021-05-12T20:15:53.899785Z"
    },
    "id": "Vs-ofmkEIu7y",
    "papermill": {
     "duration": 0.513902,
     "end_time": "2021-05-12T20:15:53.901034",
     "exception": false,
     "start_time": "2021-05-12T20:15:53.387132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':names,'predicted':preds})\n",
    "df.to_csv('submission-wgo.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TeamWhatsGoinOn_hubmap-3rd-place-inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "papermill": {
   "duration": 6281.678928,
   "end_time": "2021-05-12T20:15:54.323461",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T18:31:12.644533",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
