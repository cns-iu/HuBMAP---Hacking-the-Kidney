{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HubMap- Hacking the Kidney\n",
    "<h3> Goal - Mapping the human body at function tissue unit level - detect crypts FTUs in colon </h3>\n",
    "\n",
    "Implementation of Kaggle Notebook -  Prize Winner - Deep Flash2 <br>\n",
    "Description - Use 5 fold models to predict on test image masks <br>\n",
    "Input - models, test images, sample_submission.csv  <br>\n",
    "Output - submission_df2_generalized.csv (rle for test images) <br>\n",
    "\n",
    "<b>How to use?</b><br> \n",
    "Change the basepath to where your data lives and you're good to go. <br>\n",
    "\n",
    "Link 1 - https://github.com/navekshasood/HubMap\n",
    "\n",
    "###### Step 1 - Install useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import random\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tifffile as tiff\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from rasterio.windows import Window\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2 - Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    \n",
    "SEED = 2021\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"ftus\"]\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "MEAN = np.array([0.66437738, 0.50478148, 0.70114894])\n",
    "STD = np.array([0.15825711, 0.24371008, 0.13832686])\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "IDENTITY = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "FLIPS = [[-1], [-2], [-2, -1]]\n",
    "\n",
    "DATA_PATH = r'C:/Users/soodn/Downloads/Naveksha/Kaggle HuBMAP/'\n",
    "IMG_PATH = DATA_PATH + 'Data/colon-data-reprocessed/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, df_info, reduce_factor=1):\n",
    "    \"\"\"\n",
    "    Load image and make sure sizes matches df_info\n",
    "    \"\"\"\n",
    "    image_fname = img_path.rsplit(\"/\", -1)[-1]\n",
    "    \n",
    "    \n",
    "    W = int(df_info[df_info.image_file == image_fname][\"width_pixels\"])\n",
    "    H = int(df_info[df_info.image_file == image_fname][\"height_pixels\"])\n",
    "\n",
    "    img = tiff.imread(img_path).squeeze()\n",
    "\n",
    "    channel_pos = np.argwhere(np.array(img.shape) == 3)[0][0]\n",
    "    W_pos = np.argwhere(np.array(img.shape) == W)[0][0]\n",
    "    H_pos = np.argwhere(np.array(img.shape) == H)[0][0]\n",
    "\n",
    "    img = np.moveaxis(img, (H_pos, W_pos, channel_pos), (0, 1, 2))\n",
    "    \n",
    "    if reduce_factor > 1:\n",
    "        img = cv2.resize(\n",
    "            img,\n",
    "            (img.shape[1] // reduce_factor, img.shape[0] // reduce_factor),\n",
    "            interpolation=cv2.INTER_AREA,\n",
    "        )\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def HE_preprocess(augment=False, visualize=False, mean=MEAN, std=STD):\n",
    "    if visualize:\n",
    "        normalizer = albu.Compose(\n",
    "            [albu.Normalize(mean=[0, 0, 0], std=[1, 1, 1]), ToTensorV2()], p=1\n",
    "        )\n",
    "    else:\n",
    "        normalizer = albu.Compose(\n",
    "            [albu.Normalize(mean=mean, std=std), ToTensorV2()], p=1\n",
    "        )\n",
    "    \n",
    "    if augment:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode_less_memory(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def enc2mask(encs, shape):\n",
    "    print (encs)\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for m, enc in enumerate(encs):\n",
    "        if isinstance(enc, np.float) and np.isnan(enc):\n",
    "            continue\n",
    "        enc_split = enc.split()\n",
    "        for i in range(len(enc_split) // 2):\n",
    "            start = int(enc_split[2 * i]) - 1\n",
    "            length = int(enc_split[2 * i + 1])\n",
    "            img[start: start + length] = 1 + m\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_img_path,\n",
    "        rle=None,\n",
    "        overlap_factor=1,\n",
    "        tile_size=256,\n",
    "        reduce_factor=4,\n",
    "        transforms=None,\n",
    "    ):\n",
    "        self.original_img = load_image(original_img_path, full_size=reduce_factor > 1)\n",
    "        self.orig_size = self.original_img.shape\n",
    "        self.raw_tile_size = tile_size\n",
    "        self.reduce_factor = reduce_factor\n",
    "        self.tile_size = tile_size * reduce_factor\n",
    "        self.overlap_factor = overlap_factor\n",
    "        self.positions = self.get_positions()\n",
    "        self.transforms = transforms\n",
    "\n",
    "        if rle is not None:\n",
    "            self.mask = enc2mask(rle, (self.orig_size[1], self.orig_size[0])) > 0\n",
    "        else:\n",
    "            self.mask = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.positions)\n",
    "\n",
    "    def get_positions(self):\n",
    "        top_x = np.arange(\n",
    "            0,\n",
    "            self.orig_size[0],  # +self.tile_size,\n",
    "            int(self.tile_size / self.overlap_factor),\n",
    "        )\n",
    "        top_y = np.arange(\n",
    "            0,\n",
    "            self.orig_size[1],  # +self.tile_size,\n",
    "            int(self.tile_size / self.overlap_factor),\n",
    "        )\n",
    "        starting_positions = []\n",
    "        for x in top_x:\n",
    "            right_space = self.orig_size[0] - (x + self.tile_size)\n",
    "            if right_space > 0:\n",
    "                boundaries_x = (x, x + self.tile_size)\n",
    "            else:\n",
    "                boundaries_x = (x + right_space, x + right_space + self.tile_size)\n",
    "\n",
    "            for y in top_y:\n",
    "                down_space = self.orig_size[1] - (y + self.tile_size)\n",
    "                if down_space > 0:\n",
    "                    boundaries_y = (y, y + self.tile_size)\n",
    "                else:\n",
    "                    boundaries_y = (y + down_space, y + down_space + self.tile_size)\n",
    "                starting_positions.append((boundaries_x, boundaries_y))\n",
    "\n",
    "        return starting_positions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pos_x, pos_y = self.positions[idx]\n",
    "        img = self.original_img[pos_x[0]: pos_x[1], pos_y[0]: pos_y[1], :]\n",
    "\n",
    "        if self.reduce_factor > 1:\n",
    "            img = cv2.resize(\n",
    "                img, (self.raw_tile_size, self.raw_tile_size), interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "\n",
    "        pos = np.array([pos_x[0], pos_x[1], pos_y[0], pos_y[1]])\n",
    "\n",
    "        return img, pos\n",
    "    \n",
    "class InferenceEfficientDataset(InferenceDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_img_path,\n",
    "        rle=None,\n",
    "        overlap_factor=1,\n",
    "        tile_size=256,\n",
    "        reduce_factor=4,\n",
    "        transforms=None,\n",
    "    ):\n",
    "            \n",
    "        self.raw_tile_size = tile_size\n",
    "        self.reduce_factor = reduce_factor\n",
    "        self.tile_size = tile_size * reduce_factor\n",
    "        \n",
    "        self.overlap_factor = overlap_factor\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # Load image with rasterio        \n",
    "        self.original_img = rasterio.open(original_img_path, transform=IDENTITY, num_threads='all_cpus')\n",
    "        if self.original_img.count != 3:\n",
    "            self.layers = [rasterio.open(subd) for subd in self.original_img.subdatasets]\n",
    "                    \n",
    "        self.orig_size = self.original_img.shape\n",
    "\n",
    "        self.positions = self.get_positions()\n",
    "        \n",
    "        if rle is not None:\n",
    "            self.mask = enc2mask(rle, (self.orig_size[1], self.orig_size[0])) > 0\n",
    "        else:\n",
    "            self.mask = None\n",
    "\n",
    "    def __getitem__(self, idx):        \n",
    "        # Window\n",
    "        pos_x, pos_y = self.positions[idx]\n",
    "        x1, x2 = pos_x[0], pos_x[1]\n",
    "        y1, y2 = pos_y[0], pos_y[1]\n",
    "        window = Window.from_slices((x1, x2), (y1, y2))\n",
    "\n",
    "        # Retrieve slice\n",
    "        if self.original_img.count == 3:  # normal\n",
    "            img = self.original_img.read([1, 2, 3], window=window)\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        else:  # with subdatasets/layers\n",
    "            img = np.zeros((self.tile_size, self.tile_size, 3), dtype=np.uint8)\n",
    "            for fl in range(3):\n",
    "                img[:, :, fl] = self.layers[fl].read(window=window) \n",
    "\n",
    "        # Downscale to tile size\n",
    "        img = cv2.resize(\n",
    "            img, (self.raw_tile_size, self.raw_tile_size), interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "        img = self.transforms(image=img)[\"image\"]\n",
    "        \n",
    "        pos = np.array([pos_x[0], pos_x[1], pos_y[0], pos_y[1]])\n",
    "\n",
    "        return img, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_weights(model, filename, verbose=1, cp_folder=\"\"):\n",
    "    if verbose:\n",
    "        print(f\"\\n -> Loading weights from {os.path.join(cp_folder,filename)}\\n\")\n",
    "    try:\n",
    "        model.load_state_dict(os.path.join(cp_folder, filename), strict=True)\n",
    "    except BaseException:\n",
    "        model.load_state_dict(\n",
    "            torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\"),\n",
    "            strict=True,\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch\n",
    "from segmentation_models_pytorch.encoders import encoders\n",
    "\n",
    "\n",
    "DECODERS = [\"Unet\", \"Linknet\", \"FPN\", \"PSPNet\", \"DeepLabV3\", \"DeepLabV3Plus\", \"PAN\"]\n",
    "ENCODERS = list(encoders.keys())\n",
    "\n",
    "\n",
    "def define_model(\n",
    "    decoder_name, encoder_name, num_classes=1, activation=None, encoder_weights=\"imagenet\"\n",
    "):\n",
    "    assert decoder_name in DECODERS, \"Decoder name not supported\"\n",
    "    assert encoder_name in ENCODERS, \"Encoder name not supported\"\n",
    "\n",
    "    decoder = getattr(segmentation_models_pytorch, decoder_name)\n",
    "\n",
    "    model = decoder(\n",
    "        encoder_name,\n",
    "        encoder_weights=encoder_weights,\n",
    "        classes=num_classes,\n",
    "        activation=activation,\n",
    "    )\n",
    "    model.num_classes = num_classes\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(cp_folder):\n",
    "    config = json.load(open(cp_folder + 'config.json', 'r'))\n",
    "    config = Config(**config)\n",
    "    \n",
    "    weights = sorted(glob.glob(cp_folder + \"*.pt\"))\n",
    "    models = []\n",
    "    \n",
    "    for weight in weights:\n",
    "        model = define_model(\n",
    "            config.decoder,\n",
    "            config.encoder,\n",
    "            num_classes=config.num_classes,\n",
    "            encoder_weights=None,\n",
    "        )\n",
    "        \n",
    "        model = load_model_weights(model, weight).to(DEVICE)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "        \n",
    "#         break\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_scores_img(pred, truth, eps=1e-8):\n",
    "    pred = pred.reshape(-1) > 0\n",
    "    truth = truth.reshape(-1) > 0\n",
    "    intersect = (pred & truth).sum(-1)\n",
    "    union = pred.sum(-1) + truth.sum(-1)\n",
    "\n",
    "    dice = (2.0 * intersect + eps) / (union + eps)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_weighting(size, sigma=1, alpha=1, eps=1e-6):\n",
    "    half = size // 2\n",
    "    w = np.ones((size, size), np.float32)\n",
    "\n",
    "    x = np.concatenate([np.mgrid[-half:0], np.mgrid[1: half + 1]])[:, None]\n",
    "    x = np.tile(x, (1, size))\n",
    "    x = half + 1 - np.abs(x)\n",
    "    y = x.T\n",
    "\n",
    "    w = np.minimum(x, y)\n",
    "    w = (w / w.max()) ** sigma\n",
    "    w = np.minimum(w, 1)\n",
    "\n",
    "    w = (w - np.min(w) + eps) / (np.max(w) - np.min(w) + eps)\n",
    "\n",
    "    w = np.where(w > alpha, 1, w)\n",
    "    w = w / alpha\n",
    "    w = np.clip(w, 1e-3, 1)\n",
    "\n",
    "    w = np.round(w, 3)\n",
    "    return w.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entire_mask(dataset, models, batch_size=32, tta=False):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    weighting = torch.from_numpy(get_tile_weighting(dataset.tile_size, sigma=1, alpha=1))\n",
    "    weighting_cuda = weighting.clone().cuda().unsqueeze(0)\n",
    "    weighting = weighting.cuda().half()\n",
    "\n",
    "    global_pred = torch.zeros(\n",
    "        (dataset.orig_size[0], dataset.orig_size[1]),\n",
    "        dtype=torch.half, device=\"cuda\"\n",
    "    )\n",
    "    global_counter = torch.zeros(\n",
    "        (dataset.orig_size[0], dataset.orig_size[1]),\n",
    "        dtype=torch.half, device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, pos in tqdm(loader):\n",
    "            img = img.to(\"cuda\")\n",
    "            _, _, h, w = img.shape\n",
    "            \n",
    "            model_preds = []\n",
    "            for model in models:\n",
    "                if model.num_classes == 1:\n",
    "                    pred = model(img).view(1, -1, h, w).sigmoid().detach()\n",
    "                else:\n",
    "                    pred = model(img)[:, 0].view(1, -1, h, w).sigmoid().detach()\n",
    "\n",
    "                if tta:\n",
    "                    for f in FLIPS:\n",
    "                        pred_flip = model(torch.flip(img, f))\n",
    "                        if model.num_classes == 2:\n",
    "                            pred_flip = pred_flip[:, :1]\n",
    "\n",
    "                        pred_flip = torch.flip(pred_flip, f).view(1, -1, h, w).sigmoid().detach()\n",
    "                        pred += pred_flip\n",
    "                    pred = torch.div(pred, len(FLIPS) + 1)\n",
    "\n",
    "                model_preds.append(pred)\n",
    "\n",
    "            pred = torch.cat(model_preds, 0).mean(0)\n",
    "\n",
    "            pred = torch.nn.functional.interpolate(\n",
    "                pred.unsqueeze(1), (dataset.tile_size, dataset.tile_size), mode='area'\n",
    "            ).squeeze(1)\n",
    "            \n",
    "            pred = (pred * weighting_cuda).half()\n",
    "\n",
    "            for tile_idx, (x0, x1, y0, y1) in enumerate(pos):\n",
    "                global_pred[x0: x1, y0: y1] += pred[tile_idx]\n",
    "                global_counter[x0: x1, y0: y1] += weighting\n",
    "\n",
    "    for i in range(len(global_pred)):\n",
    "        global_pred[i] = torch.div(global_pred[i], global_counter[i])\n",
    "\n",
    "    return global_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_metrics(gt, pred):\n",
    "    n = 0\n",
    "    d = 0\n",
    "    for i in range(gt.shape[0]):\n",
    "        for j in range (gt.shape[1]):\n",
    "            if (gt[i][j]==pred[i][j]):\n",
    "                n = n+1\n",
    "            d = d+1\n",
    "    \n",
    "    return n/d, jaccard_score(gt.flatten(order='C'), pred.flatten(order='C')), directed_hausdorff(gt, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 3 - Predict colon rle and calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"ftus\"]\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "MEAN = np.array([0.66437738, 0.50478148, 0.70114894])\n",
    "STD = np.array([0.15825711, 0.24371008, 0.13832686])\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "IDENTITY = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "FLIPS = [[-1], [-2], [-2, -1]]\n",
    "\n",
    "DATA_PATH = r'C:/Users/soodn/Downloads/Naveksha/Kaggle HuBMAP/'\n",
    "IMG_PATH = DATA_PATH+'Data/colon-data-reprocessed/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "USE_TTA = True # not DEBUG\n",
    "OVERLAP_FACTOR = 1.5\n",
    "\n",
    "CP_FOLDERS = [\n",
    "    r'C:/Users/soodn/Downloads/Naveksha/Kaggle HuBMAP/Scripts/4. DeepLive/HubMap/logs/2021-09-13/2/',\n",
    "#     DATA_PATH + 'Scripts/4. DeepLive/hubmap-cp/b1_last/b1_last/'\n",
    "]\n",
    "CP_FOLDER = CP_FOLDERS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH + 'Data/colon-data-reprocessed/sample_submission.csv')\n",
    "df_info = pd.read_csv(DATA_PATH + 'Data/colon-data-reprocessed/HuBMAP-20-dataset_information.csv')\n",
    "rles = pd.read_csv(DATA_PATH + 'Data/colon-data-reprocessed/test.csv')\n",
    "\n",
    "config = json.load(open(CP_FOLDER + 'config.json', 'r'))\n",
    "config = Config(**config)\n",
    "config.overlap_factor = OVERLAP_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = r'C:\\Users\\soodn\\Downloads\\Naveksha\\Kaggle HuBMAP\\Data\\colon-data-reprocessed\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading weights from C:/Users/soodn/Downloads/Naveksha/Kaggle HuBMAP/Scripts/4. DeepLive/HubMap/logs/2021-09-13/2\\Unet_efficientnet-b1_0.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for cp_folder in CP_FOLDERS:\n",
    "    models += load_models(cp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Image CL_HandE_1234_B004_bottomleft\n",
      "\n",
      " - Building dataset\n",
      "\n",
      " - Predicting masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\rasterio\\__init__.py:219: NotGeoreferencedWarning: Dataset has no geotransform set. The identity matrix may be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aad30d01566454d8cbb2ec4575592c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Encoding\n",
      "0    398887 19 403421 23 407956 25 412488 30 417022...\n",
      "Name: predicted, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ca9df8e2b550>:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(enc, np.float) and np.isnan(enc):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Scored 0.9364 with threshold 0.50, and Pixel Accuracy 0.9848, and Jaccard Index 0.8804, and Hausdroff's (17.52141546793523, 1538, 1538)\n",
      "****** 0    398887 19 403421 23 407956 25 412488 30 417022...\n",
      "Name: predicted, dtype: object\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Image HandE_B005_CL_b_RGB_bottomleft\n",
      "\n",
      " - Building dataset\n",
      "\n",
      " - Predicting masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\rasterio\\__init__.py:219: NotGeoreferencedWarning: Dataset has no geotransform set. The identity matrix may be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9c860c1b054b379b06ce21d99dca43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Encoding\n",
      "1    13716716 23 13721248 29 13725782 32 13730316 3...\n",
      "Name: predicted, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ca9df8e2b550>:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(enc, np.float) and np.isnan(enc):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Scored 0.8500 with threshold 0.50, and Pixel Accuracy 0.9901, and Jaccard Index 0.7392, and Hausdroff's (11.661903789690601, 3993, 3892)\n",
      "****** 1    13716716 23 13721248 29 13725782 32 13730316 3...\n",
      "Name: predicted, dtype: object\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.786461723548513 1.9748541805390585 1.6196361275671827 29.183319257625833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "DEBUG = False\n",
    "sum_score = 0\n",
    "sum_pa = 0\n",
    "sum_ji = 0\n",
    "sum_haus = 0\n",
    "for img in df['id'].unique():\n",
    "    if DEBUG:  # Check performances on a validation image\n",
    "        img = \"2f6ecfcdf\"  # check repro\n",
    "#         img = \"4ef6695ce\" # biggest img\n",
    "        IMG_PATH = DATA_PATH + \"train\"\n",
    "        models = [models[0], models[5]]\n",
    "                  \n",
    "    \n",
    "    print(f'\\n\\t Image {img}')\n",
    "    \n",
    "    if img == \"d488c759a\":\n",
    "        print('\\n - Using precomputed rle')\n",
    "        local_file_fc = '../input/hubmap-fast-submission/submission_0933_fc.csv'\n",
    "        df_local_fc = pd.read_csv(local_file_fc, index_col='id')\n",
    "        rle = df_local_fc.loc['d488c759a', 'predicted']\n",
    "        df.loc[df.id == img, 'predicted'] = rle\n",
    "\n",
    "        continue\n",
    "    \n",
    "    print(f'\\n - Building dataset')\n",
    "    \n",
    "    rle_truth = rles[rles['id'] == img][\"encoding\"] if DEBUG else None\n",
    "    \n",
    "    predict_dataset = InferenceEfficientDataset(\n",
    "        f\"{IMG_PATH}/{img}.tiff\",\n",
    "        rle=rle_truth,\n",
    "        overlap_factor=config.overlap_factor,\n",
    "        reduce_factor=config.reduce_factor,\n",
    "        tile_size=config.tile_size,\n",
    "        transforms=HE_preprocess(augment=False, visualize=False),\n",
    "    )\n",
    "    \n",
    "    print(f'\\n - Predicting masks')\n",
    "\n",
    "    global_pred = predict_entire_mask(\n",
    "        predict_dataset, models, batch_size=config.val_bs, tta=USE_TTA\n",
    "    )\n",
    "    \n",
    "    del predict_dataset\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    print('\\n - Encoding')\n",
    "    \n",
    "    global_pred_np = np.zeros(global_pred.size(), dtype=np.uint8)\n",
    "\n",
    "    for i in range(global_pred_np.shape[0]):\n",
    "        global_pred_np[i] = (global_pred[i] > THRESHOLD).cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "        \n",
    "    ########## Performance Metrics ###########    \n",
    "    \n",
    "    colon_shape = (4704, 4536)\n",
    "    shape = colon_shape\n",
    "    rle_truth = rles[rles['id'] == img][\"predicted\"]\n",
    "    mask_truth = enc2mask(rle_truth, shape)\n",
    "    score = dice_scores_img(global_pred_np, mask_truth)\n",
    "    pa, ji, haus = perf_metrics(global_pred_np, mask_truth)\n",
    "    sum_score += score\n",
    "    sum_pa += pa\n",
    "    sum_ji += ji\n",
    "    sum_haus += haus[0]\n",
    "    print(f\" -> Scored {score :.4f} with threshold {THRESHOLD:.2f}, and Pixel Accuracy {pa :.4f}, and Jaccard Index {ji :.4f}, and Hausdroff's {haus}\")\n",
    "    \n",
    "    print (\"******\", rle_truth)\n",
    "    plt.imshow(mask_truth, interpolation='nearest')\n",
    "    plt.show()\n",
    "    plt.imshow(global_pred_np, interpolation = 'nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    rle = rle_encode_less_memory(global_pred_np)\n",
    "    df.loc[df.id == img, 'predicted'] = rle\n",
    "    \n",
    "    if DEBUG:\n",
    "        shape = df_info[df_info.image_file == img + \".tiff\"][['width_pixels', 'height_pixels']].values.astype(int)[0]\n",
    "        mask_truth = enc2mask(rle_truth, shape)\n",
    "        score = dice_scores_img(global_pred_np, mask_truth)\n",
    "        print(f\" -> Scored {score :.4f} with threshold {THRESHOLD:.2f}\")\n",
    "        break\n",
    "        \n",
    "    del global_pred, global_pred_np\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print (sum_score, sum_pa, sum_ji, sum_haus)\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8932308617742565 0.9874270902695292 0.8098180637835913 14.591659628812916\n"
     ]
    }
   ],
   "source": [
    "l = len(df)\n",
    "print (sum_score/l, sum_pa/l, sum_ji/l, sum_haus/l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 -> scratch original params - uses external data <br>\n",
    "0.8816181460891861 0.9863231337508549 0.7919504636619105 15.113144216309955<hr>\n",
    "\n",
    "0 -> scratch original params - does not use external data <br>\n",
    "0.8809281876355349 0.986432402270873 0.7912188366263329 13.409417504915975<hr>\n",
    "\n",
    "1 -> 7 epochs, 1 fold<br>\n",
    "0.8883582297528501 0.9868836768062604 0.8021499246330458 15.764341813163822<hr>\n",
    "\n",
    "2 -> Changed loss func. - authors, overlap factor - 1.5, on spot sampling 0.8<br>\n",
    "0.892992921514862 0.9863255942257856 0.8080878569393268 16.084153375038156<hr>\n",
    "\n",
    "3 -> overlap factor 1.0, lr -  1e-2 <br>\n",
    "0.8932308617742565 0.9874270902695292 0.8098180637835913 14.591659628812916<hr>\n",
    "\n",
    "4 -> Transfer Learning - same params <br>\n",
    "0.879019399279444 0.9861661554502754 0.7882641378853943 14.45467522240244 <hr>\n",
    " \n",
    "5 -> Transfer Learning - same 40 epochs 1 fold <br>\n",
    "0.8679396256215788 0.984231050500006 0.7699609993042122 15.491362093071036 <hr>\n",
    "\n",
    "6 -> TL - on_spot_sampling = 0.9 overlap_factor = 1.5 7 epochs 1 fold <br>\n",
    "0.8857780596034637 0.9865012487027438 0.7980257598813476 15.178292191628948 <hr>\n",
    "\n",
    "7 -> TL - on_spot_sampling = 0.9 overlap_factor = 1.5 full run <br>\n",
    "8 -> 0.8770474515541554 0.9859149058102077 0.7851836053254269 14.517945089134951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
