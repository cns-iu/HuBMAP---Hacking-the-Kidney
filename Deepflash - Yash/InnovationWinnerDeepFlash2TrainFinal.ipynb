{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcsetTMwKXqC"
   },
   "source": [
    "# HuBMAP - Efficient Sampling Ensemble (deepflash2, pytorch, fastai) [train]\n",
    "\n",
    "> Kernel for model training with efficient region based sampling.\n",
    "\n",
    "Requires deepflash2 (git version), zarr, and segmentation-models-pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "1. Installation and package loading\n",
    "2. Helper functions and patches\n",
    "3. Configuration\n",
    "4. Training\n",
    "\n",
    "### Inputs\n",
    "- https://www.kaggle.com/matjes/hubmap-zarr converted images (downscaled with factor 2)\n",
    "- https://www.kaggle.com/matjes/hubmap-labels-pdf-0-5-0-25-0-01 masks and weights for sampling\n",
    "\n",
    "### Versions\n",
    "- V7: Fixed augmentations in deepflash2 `RandomTileDataset` config (random zoom) - LB 0.913\n",
    "- V8: Adding *albumentations* transforms, switching to Cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "### Background\n",
    "\n",
    "A glomerulus is a network of small blood vessels located at the beginning of a nephron in the kidney ([Wikipedia](https://en.wikipedia.org/wiki/Glomerulus_(kidney))\n",
    ")). Glomeruli are mainly found in the renal **cortex**, while the renal **medulla** contains mainly the renal tubule. Since we are dealing with biological structures, the separation is not not absolute and the transitions are not always perfectly sharp.\n",
    "\n",
    "![Diagram of a nephron](http://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1842/2017/05/26234530/m9skcbftjqzrokkkopam.png)\n",
    "[Diagram of a nephron from libretexts.org, Introductory and General Biology](https://bio.libretexts.org/Bookshelves/Introductory_and_General_Biology/Book%3A_General_Biology_(Boundless)/41%3A_Osmotic_Regulation_and_the_Excretory_System/41.4%3A_Human_Osmoregulatory_and_Excretory_Systems/41.4B%3A_Nephron%3A_The_Functional_Unit_of_the_Kidney)\n",
    "\n",
    "### Key Idea\n",
    "\n",
    "A common approach to deal with the very large (>500MB - 5GB) TIFF files in the dataset is to decompose the images in smaller patches/tiles, for instance by using a sliding window apporach.\n",
    "> **Knowing that the glomeruli are mainly found in the cortex, we should focus on this region during training**. \n",
    "\n",
    "Instead of preprocessing the images and saving them into fixed tiles, we sample tiles from the entire images with a higher probability on tiles that contain glumeroli and cortex. Have a look at [this kernel](https://www.kaggle.com/matjes/hubmap-labels-pdf-0-5-0-25-0-01) for more details.\n",
    "\n",
    "\n",
    "## Advantages of this approach\n",
    "\n",
    "In combination with [deepflash2](https://github.com/matjesg/deepflash2/tree/master/) and the deepflash2 [pytorch datasets](https://matjesg.github.io/deepflash2/data.html#Datasets) in particular, this approach has several advantages:\n",
    "- no preprocessing of the data (only saving them to .zarr files for memory efficient loading)\n",
    "    - flexible tile shapes (input shapes, e.g. 1024, 512, 256) at runtime\n",
    "    - flexible scaling (e.g., by facors of 2,3,4)\n",
    "- faster convergence during traing (~30 min for training a competitive model)\n",
    "    - focusing on the relevant regions (e.g., tiles that contain glumeroli and cortex)\n",
    "    - \"additional\" data augmentation from random sampling (compared to fixed windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation and package loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-07-07T03:39:14.602530Z",
     "iopub.status.busy": "2021-07-07T03:39:14.602245Z",
     "iopub.status.idle": "2021-07-07T03:39:47.249738Z",
     "shell.execute_reply": "2021-07-07T03:39:47.248733Z",
     "shell.execute_reply.started": "2021-07-07T03:39:14.602504Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
      "fatal: destination path 'segmentation_models.pytorch' already exists and is not an empty directory.\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/p-sodmann/Augmedical\n",
      "  Cloning https://github.com/p-sodmann/Augmedical to c:\\users\\soodn\\appdata\\local\\temp\\pip-req-build-0ao6iu87\n",
      "  Resolved https://github.com/p-sodmann/Augmedical to commit 2c1231f6f2a9dafaa0233bcdafd4b8c81693c75c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/p-sodmann/Augmedical 'C:\\Users\\soodn\\AppData\\Local\\Temp\\pip-req-build-0ao6iu87'\n"
     ]
    }
   ],
   "source": [
    "!pip install -q input/deepflash2-lfs\n",
    "!git clone https://github.com/qubvel/segmentation_models.pytorch.git\n",
    "!pip install -q ./segmentation_models.pytorch\n",
    "!pip install git+https://github.com/p-sodmann/Augmedical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:42:27.814638Z",
     "iopub.status.busy": "2021-07-07T03:42:27.814267Z",
     "iopub.status.idle": "2021-07-07T03:42:27.825683Z",
     "shell.execute_reply": "2021-07-07T03:42:27.824626Z",
     "shell.execute_reply.started": "2021-07-07T03:42:27.814606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "import zarr, cv2, random\n",
    "import numpy as np, pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "from fastai.vision.all import *\n",
    "from deepflash2.all import *\n",
    "from scipy import interpolate\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from hubmap_loss_metrics import *\n",
    "from augmedical.transforms.transforms import ImageTransform\n",
    "from augmedical.colors.colors import Deconvolution\n",
    "from tqdm.auto import tqdm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:08.315842Z",
     "iopub.status.busy": "2021-07-07T03:46:08.315490Z",
     "iopub.status.idle": "2021-07-07T03:46:10.155163Z",
     "shell.execute_reply": "2021-07-07T03:46:10.154397Z",
     "shell.execute_reply.started": "2021-07-07T03:46:08.315808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"6883cb3173ae477ba8d8bde16206f1eaa23dc106\")\n",
    "from fastai.callback.wandb import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:16.224387Z",
     "iopub.status.busy": "2021-07-07T03:46:16.224060Z",
     "iopub.status.idle": "2021-07-07T03:46:16.391818Z",
     "shell.execute_reply": "2021-07-07T03:46:16.390862Z",
     "shell.execute_reply.started": "2021-07-07T03:46:16.224356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Patch for deepflash2 'DeformationField' class, see https://fastcore.fast.ai/basics.html#patch\n",
    "@patch\n",
    "def apply(self:DeformationField, data, offset=(0, 0), pad=(0, 0), order=1):\n",
    "    \"Apply deformation field to image using interpolation\"\n",
    "    outshape = tuple(int(s - p) for (s, p) in zip(self.shape, pad))\n",
    "    coords = [np.squeeze(d).astype('float32').reshape(*outshape) for d in self.get(offset, pad)]\n",
    "    # Get slices to avoid loading all data (.zarr files)\n",
    "    sl = []\n",
    "    for i in range(len(coords)):\n",
    "        cmin, cmax = int(coords[i].min()), int(coords[i].max())\n",
    "        dmax = data.shape[i]\n",
    "        if cmin<0: \n",
    "            cmax = max(-cmin, cmax)\n",
    "            cmin = 0 \n",
    "        elif cmax>dmax:\n",
    "            cmin = min(cmin, 2*dmax-cmax)\n",
    "            cmax = dmax\n",
    "            coords[i] -= cmin\n",
    "        else: coords[i] -= cmin\n",
    "        sl.append(slice(cmin, cmax))    \n",
    "    if len(data.shape) == len(self.shape) + 1:\n",
    "        tile = np.empty((*outshape, data.shape[-1]))\n",
    "        for c in range(data.shape[-1]):\n",
    "            # Adding divide\n",
    "            tile[..., c] = cv2.remap(data[sl[0],sl[1], c]/255, coords[1],coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n",
    "    else:\n",
    "        tile = cv2.remap(data[sl[0], sl[1]], coords[1], coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n",
    "    return tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:21.744659Z",
     "iopub.status.busy": "2021-07-07T03:46:21.744324Z",
     "iopub.status.idle": "2021-07-07T03:46:21.778546Z",
     "shell.execute_reply": "2021-07-07T03:46:21.777287Z",
     "shell.execute_reply.started": "2021-07-07T03:46:21.744624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "class HubmapRandomTileDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch Dataset that creates random tiles with augmentations from the input images.\n",
    "    \"\"\"\n",
    "    n_inp = 1\n",
    "    def __init__(self, \n",
    "                 files,\n",
    "                 label_path,\n",
    "                 cdf_path, \n",
    "                 df_stats, \n",
    "                 sample_multiplier=50,\n",
    "                 tile_shape = (512,512),\n",
    "                 scale = 1,\n",
    "                 flip = True,                                \n",
    "                 rotation_range_deg = (0, 360),     \n",
    "                 deformation_grid = (150,150), \n",
    "                 deformation_magnitude = (10,10),\n",
    "                 value_minimum_range = (0, 0), \n",
    "                 value_maximum_range = (1, 1), \n",
    "                 value_slope_range = (1, 1),\n",
    "                 albumentations_tfms=None,\n",
    "                 augmedical_transforms=None,\n",
    "                 deconv=True,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        store_attr('files, df_stats, sample_multiplier, tile_shape, scale, albumentations_tfms')\n",
    "        store_attr('flip, rotation_range_deg, deformation_grid, deformation_magnitude, value_minimum_range, value_maximum_range, value_slope_range')\n",
    "        \n",
    "        self.data = zarr.open_group(self.files[0].parent.as_posix(), mode='r')\n",
    "        self.labels = zarr.open_group(label_path)\n",
    "        self.cdfs = zarr.open_group(cdf_path)\n",
    "        \n",
    "        self.indices = []\n",
    "        self.center_indices = []\n",
    "        self.df_stats = self.df_stats[self.df_stats.index.isin([f.stem for f in self.files],  level=0)]\n",
    "        print('Preparing sampling')\n",
    "        for key, grp in self.df_stats.groupby('idx'):\n",
    "            for (idx, i), row in grp.iterrows():\n",
    "                self.indices.append(idx)\n",
    "                self.center_indices.append(i)\n",
    "            for _ in range(self.sample_multiplier):\n",
    "                self.indices.append(idx)\n",
    "                self.center_indices.append(None)         \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        # briefly disable transformations to calc stats\n",
    "        self.albumentations_tfms = None   \n",
    "        self.augmedical_transforms = None\n",
    "        self.deconv = False\n",
    "        \n",
    "        if deconv:\n",
    "            print('Calculating stats for stain normalization w/o albumentation tfms')\n",
    "            self.dkv_stats = {}\n",
    "            self.dkv = Deconvolution()\n",
    "            for f in progress_bar(self.files):\n",
    "                idxs = [i for i, x in enumerate(self.indices) if x==f.stem]\n",
    "                t = []\n",
    "                for i in tqdm(idxs[:100], leave=False):\n",
    "                    t.append(self[i][0].numpy().transpose(1,2,0))\n",
    "                \n",
    "                self.dkv_stats[f.stem] = self.dkv.fit(t)\n",
    "                \n",
    "            self.deconv = True\n",
    "        \n",
    "            print(self.dkv_stats)\n",
    "        \n",
    "        self.albumentations_tfms = albumentations_tfms   \n",
    "        self.augmedical_transforms = augmedical_transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx): idx = idx.tolist()       \n",
    "        file_name = self.indices[idx]\n",
    "        center_idx = self.center_indices[idx]\n",
    "\n",
    "        img = self.data[file_name]\n",
    "        n_channels = img.shape[-1]\n",
    "\n",
    "        lbl = self.labels[file_name]\n",
    "        cdf = self.cdfs[file_name]\n",
    "\n",
    "        center = self.random_center(cdf[:], lbl.shape, scale=512, file=file_name, center_idx=center_idx)\n",
    "        X = self.gammaFcn(self.deformationField.apply(img, center).flatten()).reshape((*self.tile_shape, n_channels))\n",
    "        Y = self.deformationField.apply(lbl, center, (0,0), 0)\n",
    "\n",
    "        if self.albumentations_tfms:\n",
    "            augmented = self.albumentations_tfms(image=(X*255).astype('uint8'),mask=Y.astype('uint8'))\n",
    "            X = (augmented['image']/255)\n",
    "            Y = augmented['mask']\n",
    "            \n",
    "        if self.deconv:\n",
    "            d_mean,  d_std = self.dkv_stats[file_name]\n",
    "            X = self.dkv.apply(X, d_mean, 2*d_std)\n",
    "            X = np.clip(X, a_min=-5, a_max=5)\n",
    "            \n",
    "        X = X.transpose(2, 0, 1).astype('float32')\n",
    "        Y = Y.astype('int64')\n",
    "        \n",
    "        X = TensorImage(X)\n",
    "        \n",
    "        if self.augmedical_transforms:\n",
    "            for transform in self.augmedical_transforms:\n",
    "                X = transform(X)\n",
    "        \n",
    "        return  X, TensorMask(Y)\n",
    "        \n",
    "    def random_center(self, cdf, orig_shape, file, center_idx, scale=512):\n",
    "        'Sample random center'\n",
    "        if center_idx:\n",
    "            stats = self.df_stats.loc[file, center_idx]\n",
    "            cx = random.randrange(stats.top, stats.top+stats.height)\n",
    "            cy = random.randrange(stats.left, stats.left+stats.width)\n",
    "        else:\n",
    "            scale_y = int((orig_shape[1]/orig_shape[0])*scale)\n",
    "            # print (len(cdf), np.argmax(cdf > np.random.random()), scale, scale_y)\n",
    "            cx, cy, cz= np.unravel_index(np.argmax(cdf > np.random.random()), (scale,scale_y, 3))\n",
    "            cx = int(cx*orig_shape[0]/scale)\n",
    "            cy = int(cy*orig_shape[1]/scale_y)\n",
    "        return cx, cy\n",
    "        \n",
    "    def on_epoch_end(self, verbose=True):\n",
    "\n",
    "        if verbose: print(\"Generating deformation field\")\n",
    "        self.deformationField = DeformationField(self.tile_shape, self.scale)\n",
    "\n",
    "        if self.rotation_range_deg[1] > self.rotation_range_deg[0]:\n",
    "            self.deformationField.rotate(\n",
    "                theta=np.pi * (np.random.random()\n",
    "                            * (self.rotation_range_deg[1] - self.rotation_range_deg[0])\n",
    "                            + self.rotation_range_deg[0])\n",
    "                            / 180.0)\n",
    "\n",
    "        if self.flip:\n",
    "            self.deformationField.mirror(np.random.choice((True,False),2))\n",
    "\n",
    "        if self.deformation_grid is not None:\n",
    "            self.deformationField.addRandomDeformation(\n",
    "                self.deformation_grid, self.deformation_magnitude)\n",
    "\n",
    "        if verbose: print(\"Generating value augmentation function\")\n",
    "        minValue = (self.value_minimum_range[0]\n",
    "            + (self.value_minimum_range[1] - self.value_minimum_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        maxValue = (self.value_maximum_range[0]\n",
    "            + (self.value_maximum_range[1] - self.value_maximum_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        intermediateValue = 0.5 * (\n",
    "            self.value_slope_range[0]\n",
    "            + (self.value_slope_range[1] - self.value_slope_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        self.gammaFcn = interpolate.interp1d([0, 0.5, 1.0], [minValue, intermediateValue, maxValue], kind=\"quadratic\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:24.406242Z",
     "iopub.status.busy": "2021-07-07T03:46:24.405842Z",
     "iopub.status.idle": "2021-07-07T03:46:24.429832Z",
     "shell.execute_reply": "2021-07-07T03:46:24.428612Z",
     "shell.execute_reply.started": "2021-07-07T03:46:24.406212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HubmapValidationDataset(Dataset):\n",
    "    \"Pytorch Dataset that creates random tiles for validation and prediction on new data.\"\n",
    "    n_inp = 1\n",
    "    def __init__(self, \n",
    "                 files, \n",
    "                 label_path, \n",
    "                 tile_shape = (512,512),\n",
    "                 scale=1,\n",
    "                 val_length=None, \n",
    "                 val_seed=42, \n",
    "                 deconv=True,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        store_attr('files, label_path, tile_shape, scale, val_seed')\n",
    "        self.data = zarr.open_group(self.files[0].parent.as_posix())\n",
    "        self.labels = zarr.open_group(label_path)\n",
    "        self.output_shape = self.tile_shape\n",
    "        self.tiler = DeformationField(self.tile_shape, scale=self.scale)\n",
    "        self.image_indices = []\n",
    "        self.image_shapes = []\n",
    "        self.centers = []\n",
    "        self.valid_indices = None\n",
    "\n",
    "        j = 0\n",
    "        self.deconv = False\n",
    "        if deconv: \n",
    "            self.dkv = Deconvolution()\n",
    "            self.dkv_stats = {}\n",
    "            \n",
    "        for i, file in enumerate(progress_bar(self.files, leave=False)):\n",
    "            img = self.data[file.name]\n",
    "            \n",
    "            # Tiling\n",
    "            data_shape = tuple(int(x//self.scale) for x in img.shape[:-1])\n",
    "            start_points = [o//2 for o in self.output_shape]\n",
    "            end_points = [(s - st) for s, st in zip(data_shape, start_points)]\n",
    "            n_points = [int((s)//(o))+1 for s, o in zip(data_shape, self.output_shape)]\n",
    "            center_points = [np.linspace(st, e, num=n, endpoint=True, dtype=np.int64) for st, e, n in zip(start_points, end_points, n_points)]\n",
    "            # temp variable for deconv calculation\n",
    "            image_centers = []\n",
    "            for cx in center_points[1]:\n",
    "                for cy in center_points[0]:\n",
    "                    self.centers.append((int(cy*self.scale), int(cx*self.scale)))\n",
    "                    image_centers.append((int(cy*self.scale), int(cx*self.scale)))\n",
    "                    self.image_indices.append(i)\n",
    "                    self.image_shapes.append(data_shape)\n",
    "                    j += 1\n",
    "            \n",
    "            # Augmedical TFMS\n",
    "            if deconv:\n",
    "                count = 0\n",
    "                t = []\n",
    "                shuffle(image_centers)\n",
    "                for center in tqdm(image_centers, leave=False):\n",
    "                    t.append(self.tiler.apply(img, center))\n",
    "                \n",
    "                self.dkv_stats[file.stem] = self.dkv.fit(t)\n",
    "        \n",
    "        if deconv: \n",
    "            self.deconv = True\n",
    "            print(self.dkv_stats)\n",
    "        \n",
    "        if val_length:\n",
    "            if val_length>len(self.image_shapes):\n",
    "                print(f'Reducing validation from lenght {val_length} to {len(self.image_shapes)}')\n",
    "                val_length = len(self.image_shapes)\n",
    "            np.random.seed(self.val_seed)\n",
    "            choice = np.random.choice(len(self.image_indices), val_length, replace=False)\n",
    "            self.valid_indices = {i:idx for i, idx in  enumerate(choice)}\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.valid_indices: return len(self.valid_indices)\n",
    "        else: return len(self.image_shapes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if self.valid_indices: idx = self.valid_indices[idx]\n",
    "        img_path = self.files[self.image_indices[idx]]\n",
    "        img = self.data[img_path.name]\n",
    "        centerPos = self.centers[idx]\n",
    "        X = self.tiler.apply(img, centerPos)\n",
    "        \n",
    "        if self.deconv:\n",
    "            d_mean,  d_std = self.dkv_stats[img_path.name]\n",
    "            X = self.dkv.apply(X, d_mean, 2*d_std)\n",
    "            X = np.clip(X, a_min=-5, a_max=5)\n",
    "            \n",
    "        X = X.transpose(2, 0, 1).astype('float32')\n",
    "        \n",
    "        lbl = self.labels[img_path.name]\n",
    "        Y = self.tiler.apply(lbl, centerPos, (0,0), order=0).astype('int64')\n",
    "        \n",
    "        return  TensorImage(X), TensorMask(Y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:28.976850Z",
     "iopub.status.busy": "2021-07-07T03:46:28.976530Z",
     "iopub.status.idle": "2021-07-07T03:46:28.989259Z",
     "shell.execute_reply": "2021-07-07T03:46:28.988219Z",
     "shell.execute_reply.started": "2021-07-07T03:46:28.976818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_batch(batch):\n",
    "    fig, axs = plt.subplots(4,4, figsize=(20,20))   \n",
    "    images = batch[0].cpu().numpy()\n",
    "    labels = batch[1].cpu().numpy()\n",
    "\n",
    "    for i in range(16):     \n",
    "        axs[i%4, i//4].imshow(images[i, 1])\n",
    "        axs[i%4, i//4].imshow(labels[i], alpha=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(batch[0][:,0].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.hist(batch[0][:,1].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.hist(batch[0][:,2].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:39.833958Z",
     "iopub.status.busy": "2021-07-07T03:46:39.833601Z",
     "iopub.status.idle": "2021-07-07T03:46:39.841403Z",
     "shell.execute_reply": "2021-07-07T03:46:39.840273Z",
     "shell.execute_reply.started": "2021-07-07T03:46:39.833922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dc = TorchLoss(smp.losses.DiceLoss(mode='multiclass', classes=[1]))\n",
    "ce = CrossEntropyLossFlat(axis=1) #TorchLoss(smp.losses.SoftCrossEntropyLoss(smooth_factor=0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:41.991303Z",
     "iopub.status.busy": "2021-07-07T03:46:41.990873Z",
     "iopub.status.idle": "2021-07-07T03:46:42.242517Z",
     "shell.execute_reply": "2021-07-07T03:46:42.240807Z",
     "shell.execute_reply.started": "2021-07-07T03:46:41.991263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1770: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1744: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\albumentations\\imgaug\\transforms.py:337: FutureWarning: This IAAAffine is deprecated. Please use Affine instead\n",
      "  warnings.warn(\"This IAAAffine is deprecated. Please use Affine instead\", FutureWarning)\n",
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:688: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from augmentation import Desaturation, GaussianBlur, ChannelBleaching, StainShift\n",
    "\n",
    "class CONFIG():\n",
    "    # paths\n",
    "    path = Path(r'C:\\Users\\soodn\\Downloads\\Naveksha\\Kaggle HuBMAP\\Data\\hubmap_colon_data\\Colon_data_reprocessed\\Colon_data_reprocessed')\n",
    "    data_path = Path('images_scale2')\n",
    "    annotations_path = Path('masks_scale2')\n",
    "    model_path = r'C:\\Users\\soodn\\Downloads\\Naveksha\\Kaggle HuBMAP\\Scripts\\5. DeepFlash\\models'\n",
    "    \n",
    "    # deepflash2 dataset\n",
    "    scale = 1.5 # data is already downscaled to 2, so absulute downscale is 3\n",
    "    tile_shape = (512, 512)\n",
    "    sample_multiplier = 100 # Sample 100 tiles from each image, per epoch\n",
    "    val_length = 500 # Randomly sample 500 validation tiles\n",
    "    stats = np.array([0, 0 , 0]), np.array([1 , 1, 1])\n",
    "        \n",
    "    # pytorch model (segmentation_models_pytorch)\n",
    "    encoder_name = \"efficientnet-b2\"\n",
    "    encoder_weights = 'imagenet'\n",
    "    in_channels = 3\n",
    "    classes = 2\n",
    "    \n",
    "    # Training\n",
    "    n_splits = 5\n",
    "    mixed_precision_training = True\n",
    "    batch_size = 16\n",
    "    weight_decay = 0.00\n",
    "    loss_func = JointLoss(dc, ce, 1, 1)\n",
    "    metrics = [Dice(), Iou(), Recall(), Precision()]\n",
    "    max_learning_rate = 1e-3\n",
    "    epochs = 10\n",
    "    \n",
    "cfg = CONFIG()\n",
    "\n",
    "# Albumentations augmentations\n",
    "tfms = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomContrast(),\n",
    "        A.RandomGamma(),\n",
    "        A.RandomBrightness(),\n",
    "        ], p=0.3),\n",
    "    A.OneOf([\n",
    "        A.Blur(blur_limit=3, p=1),\n",
    "        A.MedianBlur(blur_limit=3, p=1)\n",
    "    ], p=.1),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(0.002, p=.5),\n",
    "        A.IAAAffine(p=.5),\n",
    "    ], p=.1),\n",
    "    # Additional position augmentations\n",
    "    A.RandomRotate90(p=.5),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "    A.VerticalFlip(p=.5),\n",
    "    A.Cutout(num_holes=10,fill_value=255, \n",
    "             max_h_size=int(.1 * cfg.tile_shape[0]), \n",
    "             max_w_size=int(.1 * cfg.tile_shape[0]), \n",
    "             p=.1),\n",
    "])\n",
    "\n",
    "# augmedical_transforms = [\n",
    "#     Desaturation(p=0.0625, max_desaturation=0.25, max_value_reduction=0.25),\n",
    "#     #Stamping(path=\"../input/augmentation-images\", files=range(1,24), p=cfg.stamping_p, intensity=cfg.stamping_intensity),\n",
    "\n",
    "#     GaussianBlur(channels=3, p=0.1, kernel_size=3, alpha=0.25),\n",
    "#     GaussianBlur(channels=3, p=0.0625, kernel_size=23, alpha=0.5),\n",
    "\n",
    "#     ChannelBleaching(channel=3, p=0.25, min_bleach=0.1, max_bleach=0.25, force_channel=1),\n",
    "#     ChannelBleaching(channel=3, p=0.0625, min_bleach=0.1, max_bleach=0.5, force_channel=2),\n",
    "#     ChannelBleaching(channel=3, p=0.0625, min_bleach=0.1, max_bleach=0.5, force_channel=0),\n",
    "\n",
    "#     #ChannelBlackout(channel=3, p=0.005),\n",
    "#     StainShift(channel=3, p=0.25, min_shift=1, max_shift=7, force_channel=0),\n",
    "#     StainShift(channel=3, p=0.25, min_shift=1, max_shift=7, force_channel=2)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Position Augmentations\n",
    "position_augmentation_kwargs = {\n",
    "    'flip':True,                                \n",
    "    'rotation_range_deg':(0, 360),     \n",
    "    'deformation_grid': (150,150), \n",
    "    'deformation_magnitude':(10,10),\n",
    "    'value_minimum_range':(0, 0), \n",
    "    'value_maximum_range':(1, 1), \n",
    "    'value_slope_range':(1, 1)}\n",
    "\n",
    "# Datasets\n",
    "ds_kwargs = {\n",
    "    'label_path': (cfg.annotations_path/'labels').as_posix(),\n",
    "    'cdf_path': (cfg.annotations_path/'cdfs').as_posix(),\n",
    "    'df_stats': pd.read_csv(cfg.annotations_path/'roi_stats.csv', index_col=[0,1]),\n",
    "    'tile_shape':cfg.tile_shape,\n",
    "    'scale': cfg.scale,\n",
    "    'val_length':cfg.val_length, \n",
    "    'sample_multiplier':cfg.sample_multiplier,\n",
    "    'albumentations_tfms': tfms,\n",
    "   # \"augmedical_transforms\": augmedical_transforms\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(cfg.path/'train.csv')\n",
    "df_train = df_train.rename(columns={\"predicted\":\"encoding\"})\n",
    "df_train = df_train[df_train.id != 'HandE_B005_CL_b_RGB_topright']\n",
    "\n",
    "df_info = pd.read_csv(cfg.path/'HuBMAP-20-dataset_information.csv')\n",
    "files = L([cfg.data_path/x for x in df_train.id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL_HandE_1234_B004_bottomright</td>\n",
       "      <td>12972850 36 12977382 42 12981914 47 12986448 50 12990981 54 12995515 57 13000050 58 13004585 60 13009002 19 13009120 61 13013532 27 13013655 62 13018066 30 13018190 64 13022600 33 13022725 65 13027134 36 13027260 67 13031667 39 13031795 68 13036201 42 13036330 69 13040735 45 13040866 69 13045270 48 13045401 70 13049805 50 13049936 71 13054339 53 13054471 72 13058874 55 13059006 73 13063408 57 13063542 73 13067943 59 13068077 74 13072476 62 13072613 74 13077011 64 13077148 75 13081547 65 13081683 76 13086082 67 13086218 77 13090618 68 13090753 78 13095153 69 13095289 78 13099688 71 13099824...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CL_HandE_1234_B004_topleft</td>\n",
       "      <td>2023885 36 2028419 40 2032953 44 2037487 47 2042022 51 2046557 54 2046664 23 2051092 57 2051197 28 2055627 60 2055730 32 2060162 63 2060264 36 2064698 64 2064798 40 2069233 68 2069331 45 2073768 71 2073864 49 2078303 147 2082838 150 2087373 153 2091908 156 2096443 159 2100979 161 2105514 164 2110050 165 2114585 167 2119120 170 2123655 172 2128191 173 2132724 177 2137258 180 2141793 182 2146328 183 2150863 185 2155399 185 2159933 188 2164468 189 2169003 190 2173538 192 2178074 193 2182609 195 2187144 196 2191679 198 2196215 198 2200750 200 2205286 200 2209821 201 2214357 201 2218892 202 222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CL_HandE_1234_B004_topright</td>\n",
       "      <td>372094 8 376628 12 381163 14 385698 16 390233 18 394768 20 399303 21 403839 32 408374 38 412910 41 417445 43 421981 45 426517 47 431052 50 435588 53 440123 56 444658 58 449194 60 453729 63 458265 65 462800 67 467336 68 471870 71 476405 74 480941 75 485476 77 490011 79 494546 80 499081 82 503616 84 508151 86 512686 88 517222 89 521756 91 526291 93 530827 94 535362 96 535468 7 539897 98 540002 11 544432 100 544537 13 548967 102 549072 15 553501 105 553607 17 558037 123 562572 125 567107 126 571643 127 576178 128 580714 128 585249 129 589784 130 594318 132 598853 133 603388 134 607923 135 612...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HandE_B005_CL_b_RGB_bottomright</td>\n",
       "      <td>2247721 26 2252254 31 2256788 34 2261323 36 2265858 38 2270393 40 2274928 42 2279463 44 2283998 46 2288532 48 2293066 51 2297601 53 2302136 55 2306671 56 2311206 58 2315741 59 2320276 61 2324812 61 2329347 62 2333882 63 2338417 64 2342952 66 2347487 67 2352023 68 2356557 70 2357178 11 2361092 71 2361712 19 2365627 72 2366246 34 2370162 73 2370778 44 2374697 75 2375313 51 2379232 76 2379847 54 2383767 77 2384382 57 2388302 78 2388917 61 2392837 79 2393453 62 2397372 80 2397988 65 2401907 82 2402524 68 2406442 83 2407059 71 2410977 85 2411595 73 2415512 86 2416131 76 2420048 87 2420667 78 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HandE_B005_CL_b_RGB_topleft</td>\n",
       "      <td>366048 27 370578 43 375111 48 379646 52 384181 55 388716 57 393251 60 397786 63 402321 65 406856 69 411391 72 415926 74 420461 77 424996 79 429531 81 434066 83 438602 85 443137 88 447672 91 452208 93 456743 95 461278 98 465813 105 470348 108 474884 109 479419 111 483954 113 488490 115 493026 116 497561 118 502097 119 506632 121 511168 122 515703 124 520239 125 524775 127 529311 129 533846 132 538382 133 542917 135 547453 136 551989 137 556525 138 560671 29 561061 139 565199 39 565596 141 569732 43 570132 141 574265 47 574668 142 578796 53 579203 143 583327 59 583739 144 587860 63 588274 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "0   CL_HandE_1234_B004_bottomright   \n",
       "1       CL_HandE_1234_B004_topleft   \n",
       "2      CL_HandE_1234_B004_topright   \n",
       "3  HandE_B005_CL_b_RGB_bottomright   \n",
       "4      HandE_B005_CL_b_RGB_topleft   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  encoding  \n",
       "0  12972850 36 12977382 42 12981914 47 12986448 50 12990981 54 12995515 57 13000050 58 13004585 60 13009002 19 13009120 61 13013532 27 13013655 62 13018066 30 13018190 64 13022600 33 13022725 65 13027134 36 13027260 67 13031667 39 13031795 68 13036201 42 13036330 69 13040735 45 13040866 69 13045270 48 13045401 70 13049805 50 13049936 71 13054339 53 13054471 72 13058874 55 13059006 73 13063408 57 13063542 73 13067943 59 13068077 74 13072476 62 13072613 74 13077011 64 13077148 75 13081547 65 13081683 76 13086082 67 13086218 77 13090618 68 13090753 78 13095153 69 13095289 78 13099688 71 13099824...  \n",
       "1  2023885 36 2028419 40 2032953 44 2037487 47 2042022 51 2046557 54 2046664 23 2051092 57 2051197 28 2055627 60 2055730 32 2060162 63 2060264 36 2064698 64 2064798 40 2069233 68 2069331 45 2073768 71 2073864 49 2078303 147 2082838 150 2087373 153 2091908 156 2096443 159 2100979 161 2105514 164 2110050 165 2114585 167 2119120 170 2123655 172 2128191 173 2132724 177 2137258 180 2141793 182 2146328 183 2150863 185 2155399 185 2159933 188 2164468 189 2169003 190 2173538 192 2178074 193 2182609 195 2187144 196 2191679 198 2196215 198 2200750 200 2205286 200 2209821 201 2214357 201 2218892 202 222...  \n",
       "2  372094 8 376628 12 381163 14 385698 16 390233 18 394768 20 399303 21 403839 32 408374 38 412910 41 417445 43 421981 45 426517 47 431052 50 435588 53 440123 56 444658 58 449194 60 453729 63 458265 65 462800 67 467336 68 471870 71 476405 74 480941 75 485476 77 490011 79 494546 80 499081 82 503616 84 508151 86 512686 88 517222 89 521756 91 526291 93 530827 94 535362 96 535468 7 539897 98 540002 11 544432 100 544537 13 548967 102 549072 15 553501 105 553607 17 558037 123 562572 125 567107 126 571643 127 576178 128 580714 128 585249 129 589784 130 594318 132 598853 133 603388 134 607923 135 612...  \n",
       "3  2247721 26 2252254 31 2256788 34 2261323 36 2265858 38 2270393 40 2274928 42 2279463 44 2283998 46 2288532 48 2293066 51 2297601 53 2302136 55 2306671 56 2311206 58 2315741 59 2320276 61 2324812 61 2329347 62 2333882 63 2338417 64 2342952 66 2347487 67 2352023 68 2356557 70 2357178 11 2361092 71 2361712 19 2365627 72 2366246 34 2370162 73 2370778 44 2374697 75 2375313 51 2379232 76 2379847 54 2383767 77 2384382 57 2388302 78 2388917 61 2392837 79 2393453 62 2397372 80 2397988 65 2401907 82 2402524 68 2406442 83 2407059 71 2410977 85 2411595 73 2415512 86 2416131 76 2420048 87 2420667 78 24...  \n",
       "4  366048 27 370578 43 375111 48 379646 52 384181 55 388716 57 393251 60 397786 63 402321 65 406856 69 411391 72 415926 74 420461 77 424996 79 429531 81 434066 83 438602 85 443137 88 447672 91 452208 93 456743 95 461278 98 465813 105 470348 108 474884 109 479419 111 483954 113 488490 115 493026 116 497561 118 502097 119 506632 121 511168 122 515703 124 520239 125 524775 127 529311 129 533846 132 538382 133 542917 135 547453 136 551989 137 556525 138 560671 29 561061 139 565199 39 565596 141 569732 43 570132 141 574265 47 574668 142 578796 53 579203 143 583327 59 583739 144 587860 63 588274 14...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [Path('images_scale2/CL_HandE_1234_B004_bottomright'),Path('images_scale2/CL_HandE_1234_B004_topleft'),Path('images_scale2/CL_HandE_1234_B004_topright'),Path('images_scale2/HandE_B005_CL_b_RGB_bottomright'),Path('images_scale2/HandE_B005_CL_b_RGB_topleft')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_model_weights(model, file, strict=True):\n",
    "    state = torch.load(file, map_location='cpu')\n",
    "    stats = state['stats']\n",
    "    model_state = state['model']\n",
    "    model.load_state_dict(model_state, strict=strict)\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=42, shuffle=True) ['C:\\\\Users\\\\soodn\\\\Downloads\\\\Naveksha\\\\Kaggle HuBMAP\\\\Scripts\\\\5. DeepFlash\\\\models\\\\Unet_model-1.pth', 'C:\\\\Users\\\\soodn\\\\Downloads\\\\Naveksha\\\\Kaggle HuBMAP\\\\Scripts\\\\5. DeepFlash\\\\models\\\\Unet_model-2.pth', 'C:\\\\Users\\\\soodn\\\\Downloads\\\\Naveksha\\\\Kaggle HuBMAP\\\\Scripts\\\\5. DeepFlash\\\\models\\\\Unet_model-3.pth', 'C:\\\\Users\\\\soodn\\\\Downloads\\\\Naveksha\\\\Kaggle HuBMAP\\\\Scripts\\\\5. DeepFlash\\\\models\\\\Unet_model-4.pth', 'C:\\\\Users\\\\soodn\\\\Downloads\\\\Naveksha\\\\Kaggle HuBMAP\\\\Scripts\\\\5. DeepFlash\\\\models\\\\Unet_model-5.pth']\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(cfg.n_splits, shuffle=True, random_state=42)\n",
    "MODELS = [name for name in glob.glob(cfg.model_path+'/*.pth')]\n",
    "print (kf, MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(cfg.n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(files)):\n",
    "    files_train, files_val = files[train_idx], files[val_idx]\n",
    "    print('Training on', [x.name for x in files_train])\n",
    "    \n",
    "    # Datasets\n",
    "    train_ds = HubmapRandomTileDataset(files_train, **ds_kwargs, **position_augmentation_kwargs)\n",
    "    valid_ds = HubmapValidationDataset(files_val, **ds_kwargs)\n",
    "    \n",
    "    print (\"Done til here!! \")\n",
    "    \n",
    "    # Model\n",
    "    model = smp.Unet(encoder_name=cfg.encoder_name, \n",
    "                     encoder_weights=cfg.encoder_weights, \n",
    "                     in_channels=cfg.in_channels, \n",
    "                     classes=cfg.classes)\n",
    "    model, stats = load_model_weights(model, m_path)\n",
    "    print(\"Done\")\n",
    "    # Dataloader and learner\n",
    "    dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=cfg.batch_size, after_batch=Normalize.from_stats(*cfg.stats))\n",
    "    if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "    \n",
    "    if i==0: \n",
    "        show_batch(dls.one_batch())\n",
    "        \n",
    "    run = wandb.init(project='bricknet', reinit=True, config=cfg, name=f\"default_with_phils_augment_{i}\")\n",
    "\n",
    "    cbs = [SaveModelCallback(monitor='dice'), ElasticDeformCallback, WandbCallback(log_preds=False, log_model=False)]\n",
    "    learn = Learner(dls, model, metrics=cfg.metrics, wd=cfg.weight_decay, loss_func=cfg.loss_func, opt_func=ranger, cbs=cbs)\n",
    "    if cfg.mixed_precision_training: learn.to_fp16()\n",
    "    \n",
    "    print (\"Start model fitting\", learn)\n",
    "    # Fit\n",
    "    learn.fit_one_cycle(cfg.epochs, lr_max=cfg.max_learning_rate)\n",
    "    learn.recorder.plot_metrics()\n",
    "    \n",
    "    # Save Model\n",
    "    print (\"Saving Model\")\n",
    "    state = {'model': learn.model.state_dict(), 'stats':cfg.stats}\n",
    "    torch.save(state, f'unet_{cfg.encoder_name}_{i}.pth', pickle_protocol=2, _use_new_zipfile_serialization=False)\n",
    "    print (\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('efficientnet-b2', 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.encoder_name,i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
