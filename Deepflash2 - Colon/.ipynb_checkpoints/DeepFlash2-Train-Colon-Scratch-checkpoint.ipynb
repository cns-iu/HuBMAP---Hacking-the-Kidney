{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcsetTMwKXqC"
   },
   "source": [
    "<h1> HubMap - Hacking the Kidney </h1>\n",
    "<h3> Goal - Mapping the human body at function tissue unit level - detect crypt FTUs in colon </h3>\n",
    "\n",
    "Implementation of Kaggle Notebook - Innovation Prize Winner - Deep Flash2 <br>\n",
    "Description - Train 5 fold model on rescaled images <br>\n",
    "Input - train.csv (csv file containing rle format mask), HuBMAP-20-dataset_information.csv (csv containing meta data about the images), Downscaled images and masks, roi-stats.csv (csv containing pdfs for each image), wandb credentials, download deepflash2 library (link - https://www.kaggle.com/matjes/deepflash2-lfs), hubmap_loss_metrics.py <br>\n",
    "Output - trained models learnt from scratch\n",
    "\n",
    "<b>How to use?</b><br> \n",
    "Change the basepath to where your data lives and you're good to go. <br>\n",
    "\n",
    "Link to the original notebook -  https://www.kaggle.com/matjes/hubmap-deepflash2-train/data?scriptVersionId=63051354\n",
    "\n",
    "<b> What is different from the original notebook? </b><br>\n",
    "Could not find the augmentation package, hence, some augmentations are excluded. <hr>\n",
    "\n",
    "<h6> Step 1 - Installation and package loading <h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-07-07T03:39:14.602530Z",
     "iopub.status.busy": "2021-07-07T03:39:14.602245Z",
     "iopub.status.idle": "2021-07-07T03:39:47.249738Z",
     "shell.execute_reply": "2021-07-07T03:39:47.248733Z",
     "shell.execute_reply.started": "2021-07-07T03:39:14.602504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "fatal: destination path 'segmentation_models.pytorch' already exists and is not an empty directory.\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/p-sodmann/Augmedical"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "  Running command git clone -q https://github.com/p-sodmann/Augmedical 'C:\\Users\\soodn\\AppData\\Local\\Temp\\pip-req-build-mxypeba6'\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\soodn\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/p-sodmann/Augmedical to c:\\users\\soodn\\appdata\\local\\temp\\pip-req-build-mxypeba6\n",
      "  Resolved https://github.com/p-sodmann/Augmedical to commit 2c1231f6f2a9dafaa0233bcdafd4b8c81693c75c\n"
     ]
    }
   ],
   "source": [
    "!pip install -q input/deepflash2-lfs\n",
    "!git clone https://github.com/qubvel/segmentation_models.pytorch.git\n",
    "!pip install -q ./segmentation_models.pytorch\n",
    "!pip install git+https://github.com/p-sodmann/Augmedical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:42:27.814638Z",
     "iopub.status.busy": "2021-07-07T03:42:27.814267Z",
     "iopub.status.idle": "2021-07-07T03:42:27.825683Z",
     "shell.execute_reply": "2021-07-07T03:42:27.824626Z",
     "shell.execute_reply.started": "2021-07-07T03:42:27.814606Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import zarr, cv2, random\n",
    "import numpy as np, pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "from fastai.vision.all import *\n",
    "from deepflash2.all import *\n",
    "from scipy import interpolate\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from hubmap_loss_metrics import *\n",
    "from augmedical.transforms.transforms import ImageTransform\n",
    "from augmedical.colors.colors import Deconvolution\n",
    "from tqdm.auto import tqdm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:08.315842Z",
     "iopub.status.busy": "2021-07-07T03:46:08.315490Z",
     "iopub.status.idle": "2021-07-07T03:46:10.155163Z",
     "shell.execute_reply": "2021-07-07T03:46:10.154397Z",
     "shell.execute_reply.started": "2021-07-07T03:46:08.315808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: soodn (use `wandb login --relogin` to force relogin)\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\soodn/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"6883cb3173ae477ba8d8bde16206f1eaa23dc106\")\n",
    "from fastai.callback.wandb import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Step 2 - Make patches of the image file, and define helper functions </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:16.224387Z",
     "iopub.status.busy": "2021-07-07T03:46:16.224060Z",
     "iopub.status.idle": "2021-07-07T03:46:16.391818Z",
     "shell.execute_reply": "2021-07-07T03:46:16.390862Z",
     "shell.execute_reply.started": "2021-07-07T03:46:16.224356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@patch\n",
    "def apply(self:DeformationField, data, offset=(0, 0), pad=(0, 0), order=1):\n",
    "    \"Apply deformation field to image using interpolation\"\n",
    "    outshape = tuple(int(s - p) for (s, p) in zip(self.shape, pad))\n",
    "    coords = [np.squeeze(d).astype('float32').reshape(*outshape) for d in self.get(offset, pad)]\n",
    "    # Get slices to avoid loading all data (.zarr files)\n",
    "    sl = []\n",
    "    for i in range(len(coords)):\n",
    "        cmin, cmax = int(coords[i].min()), int(coords[i].max())\n",
    "        dmax = data.shape[i]\n",
    "        if cmin<0: \n",
    "            cmax = max(-cmin, cmax)\n",
    "            cmin = 0 \n",
    "        elif cmax>dmax:\n",
    "            cmin = min(cmin, 2*dmax-cmax)\n",
    "            cmax = dmax\n",
    "            coords[i] -= cmin\n",
    "        else: coords[i] -= cmin\n",
    "        sl.append(slice(cmin, cmax))    \n",
    "    if len(data.shape) == len(self.shape) + 1:\n",
    "        tile = np.empty((*outshape, data.shape[-1]))\n",
    "        for c in range(data.shape[-1]):\n",
    "            # Adding divide\n",
    "            tile[..., c] = cv2.remap(data[sl[0],sl[1], c]/255, coords[1],coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n",
    "    else:\n",
    "        tile = cv2.remap(data[sl[0], sl[1]], coords[1], coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n",
    "    return tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:21.744659Z",
     "iopub.status.busy": "2021-07-07T03:46:21.744324Z",
     "iopub.status.idle": "2021-07-07T03:46:21.778546Z",
     "shell.execute_reply": "2021-07-07T03:46:21.777287Z",
     "shell.execute_reply.started": "2021-07-07T03:46:21.744624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "class HubmapRandomTileDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch Dataset that creates random tiles with augmentations from the input images.\n",
    "    \"\"\"\n",
    "    n_inp = 1\n",
    "    def __init__(self, \n",
    "                 files,\n",
    "                 label_path,\n",
    "                 cdf_path, \n",
    "                 df_stats, \n",
    "                 sample_multiplier=50,\n",
    "                 tile_shape = (512,512),\n",
    "                 scale = 1,\n",
    "                 flip = True,                                \n",
    "                 rotation_range_deg = (0, 360),     \n",
    "                 deformation_grid = (150,150), \n",
    "                 deformation_magnitude = (10,10),\n",
    "                 value_minimum_range = (0, 0), \n",
    "                 value_maximum_range = (1, 1), \n",
    "                 value_slope_range = (1, 1),\n",
    "                 albumentations_tfms=None,\n",
    "                 augmedical_transforms=None,\n",
    "                 deconv=True,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        store_attr('files, df_stats, sample_multiplier, tile_shape, scale, albumentations_tfms')\n",
    "        store_attr('flip, rotation_range_deg, deformation_grid, deformation_magnitude, value_minimum_range, value_maximum_range, value_slope_range')\n",
    "        \n",
    "        self.data = zarr.open_group(self.files[0].parent.as_posix(), mode='r')\n",
    "        self.labels = zarr.open_group(label_path)\n",
    "        self.cdfs = zarr.open_group(cdf_path)\n",
    "        \n",
    "        self.indices = []\n",
    "        self.center_indices = []\n",
    "        self.df_stats = self.df_stats[self.df_stats.index.isin([f.stem for f in self.files],  level=0)]\n",
    "        print('Preparing sampling')\n",
    "        for key, grp in self.df_stats.groupby('idx'):\n",
    "            for (idx, i), row in grp.iterrows():\n",
    "                self.indices.append(idx)\n",
    "                self.center_indices.append(i)\n",
    "            for _ in range(self.sample_multiplier):\n",
    "                self.indices.append(idx)\n",
    "                self.center_indices.append(None)         \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        # briefly disable transformations to calc stats\n",
    "        self.albumentations_tfms = None   \n",
    "        self.augmedical_transforms = None\n",
    "        self.deconv = False\n",
    "        \n",
    "        if deconv:\n",
    "            print('Calculating stats for stain normalization w/o albumentation tfms')\n",
    "            self.dkv_stats = {}\n",
    "            self.dkv = Deconvolution()\n",
    "            for f in progress_bar(self.files):\n",
    "                idxs = [i for i, x in enumerate(self.indices) if x==f.stem]\n",
    "                t = []\n",
    "                for i in tqdm(idxs[:100], leave=False):\n",
    "                    t.append(self[i][0].numpy().transpose(1,2,0))\n",
    "                \n",
    "                self.dkv_stats[f.stem] = self.dkv.fit(t)\n",
    "                \n",
    "            self.deconv = True\n",
    "        \n",
    "            print(self.dkv_stats)\n",
    "        \n",
    "        self.albumentations_tfms = albumentations_tfms   \n",
    "        self.augmedical_transforms = augmedical_transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx): idx = idx.tolist()       \n",
    "        file_name = self.indices[idx]\n",
    "        center_idx = self.center_indices[idx]\n",
    "\n",
    "        img = self.data[file_name]\n",
    "        n_channels = img.shape[-1]\n",
    "\n",
    "        lbl = self.labels[file_name]\n",
    "        cdf = self.cdfs[file_name]\n",
    "\n",
    "        center = self.random_center(cdf[:], lbl.shape, scale=512, file=file_name, center_idx=center_idx)\n",
    "        X = self.gammaFcn(self.deformationField.apply(img, center).flatten()).reshape((*self.tile_shape, n_channels))\n",
    "        Y = self.deformationField.apply(lbl, center, (0,0), 0)\n",
    "\n",
    "        if self.albumentations_tfms:\n",
    "            augmented = self.albumentations_tfms(image=(X*255).astype('uint8'),mask=Y.astype('uint8'))\n",
    "            X = (augmented['image']/255)\n",
    "            Y = augmented['mask']\n",
    "            \n",
    "        if self.deconv:\n",
    "            d_mean,  d_std = self.dkv_stats[file_name]\n",
    "            X = self.dkv.apply(X, d_mean, 2*d_std)\n",
    "            X = np.clip(X, a_min=-5, a_max=5)\n",
    "            \n",
    "        X = X.transpose(2, 0, 1).astype('float32')\n",
    "        Y = Y.astype('int64')\n",
    "        \n",
    "        X = TensorImage(X)\n",
    "        \n",
    "        if self.augmedical_transforms:\n",
    "            for transform in self.augmedical_transforms:\n",
    "                X = transform(X)\n",
    "        \n",
    "        return  X, TensorMask(Y)\n",
    "        \n",
    "    def random_center(self, cdf, orig_shape, file, center_idx, scale=512):\n",
    "        'Sample random center'\n",
    "        if center_idx:\n",
    "            stats = self.df_stats.loc[file, center_idx]\n",
    "            cx = random.randrange(stats.top, stats.top+stats.height)\n",
    "            cy = random.randrange(stats.left, stats.left+stats.width)\n",
    "        else:\n",
    "            scale_y = int((orig_shape[1]/orig_shape[0])*scale)\n",
    "            # print (len(cdf), np.argmax(cdf > np.random.random()), scale, scale_y)\n",
    "            cx, cy, cz= np.unravel_index(np.argmax(cdf > np.random.random()), (scale,scale_y, 3))\n",
    "            cx = int(cx*orig_shape[0]/scale)\n",
    "            cy = int(cy*orig_shape[1]/scale_y)\n",
    "        return cx, cy\n",
    "        \n",
    "    def on_epoch_end(self, verbose=True):\n",
    "\n",
    "        if verbose: print(\"Generating deformation field\")\n",
    "        self.deformationField = DeformationField(self.tile_shape, self.scale)\n",
    "\n",
    "        if self.rotation_range_deg[1] > self.rotation_range_deg[0]:\n",
    "            self.deformationField.rotate(\n",
    "                theta=np.pi * (np.random.random()\n",
    "                            * (self.rotation_range_deg[1] - self.rotation_range_deg[0])\n",
    "                            + self.rotation_range_deg[0])\n",
    "                            / 180.0)\n",
    "\n",
    "        if self.flip:\n",
    "            self.deformationField.mirror(np.random.choice((True,False),2))\n",
    "\n",
    "        if self.deformation_grid is not None:\n",
    "            self.deformationField.addRandomDeformation(\n",
    "                self.deformation_grid, self.deformation_magnitude)\n",
    "\n",
    "        if verbose: print(\"Generating value augmentation function\")\n",
    "        minValue = (self.value_minimum_range[0]\n",
    "            + (self.value_minimum_range[1] - self.value_minimum_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        maxValue = (self.value_maximum_range[0]\n",
    "            + (self.value_maximum_range[1] - self.value_maximum_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        intermediateValue = 0.5 * (\n",
    "            self.value_slope_range[0]\n",
    "            + (self.value_slope_range[1] - self.value_slope_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        self.gammaFcn = interpolate.interp1d([0, 0.5, 1.0], [minValue, intermediateValue, maxValue], kind=\"quadratic\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:24.406242Z",
     "iopub.status.busy": "2021-07-07T03:46:24.405842Z",
     "iopub.status.idle": "2021-07-07T03:46:24.429832Z",
     "shell.execute_reply": "2021-07-07T03:46:24.428612Z",
     "shell.execute_reply.started": "2021-07-07T03:46:24.406212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HubmapValidationDataset(Dataset):\n",
    "    \"Pytorch Dataset that creates random tiles for validation and prediction on new data.\"\n",
    "    n_inp = 1\n",
    "    def __init__(self, \n",
    "                 files, \n",
    "                 label_path, \n",
    "                 tile_shape = (512,512),\n",
    "                 scale=1,\n",
    "                 val_length=None, \n",
    "                 val_seed=42, \n",
    "                 deconv=True,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        store_attr('files, label_path, tile_shape, scale, val_seed')\n",
    "        self.data = zarr.open_group(self.files[0].parent.as_posix())\n",
    "        self.labels = zarr.open_group(label_path)\n",
    "        self.output_shape = self.tile_shape\n",
    "        self.tiler = DeformationField(self.tile_shape, scale=self.scale)\n",
    "        self.image_indices = []\n",
    "        self.image_shapes = []\n",
    "        self.centers = []\n",
    "        self.valid_indices = None\n",
    "\n",
    "        j = 0\n",
    "        self.deconv = False\n",
    "        if deconv: \n",
    "            self.dkv = Deconvolution()\n",
    "            self.dkv_stats = {}\n",
    "            \n",
    "        for i, file in enumerate(progress_bar(self.files, leave=False)):\n",
    "            img = self.data[file.name]\n",
    "            \n",
    "            # Tiling\n",
    "            data_shape = tuple(int(x//self.scale) for x in img.shape[:-1])\n",
    "            start_points = [o//2 for o in self.output_shape]\n",
    "            end_points = [(s - st) for s, st in zip(data_shape, start_points)]\n",
    "            n_points = [int((s)//(o))+1 for s, o in zip(data_shape, self.output_shape)]\n",
    "            center_points = [np.linspace(st, e, num=n, endpoint=True, dtype=np.int64) for st, e, n in zip(start_points, end_points, n_points)]\n",
    "            # temp variable for deconv calculation\n",
    "            image_centers = []\n",
    "            for cx in center_points[1]:\n",
    "                for cy in center_points[0]:\n",
    "                    self.centers.append((int(cy*self.scale), int(cx*self.scale)))\n",
    "                    image_centers.append((int(cy*self.scale), int(cx*self.scale)))\n",
    "                    self.image_indices.append(i)\n",
    "                    self.image_shapes.append(data_shape)\n",
    "                    j += 1\n",
    "            \n",
    "            # Augmedical TFMS\n",
    "            if deconv:\n",
    "                count = 0\n",
    "                t = []\n",
    "                shuffle(image_centers)\n",
    "                for center in tqdm(image_centers, leave=False):\n",
    "                    t.append(self.tiler.apply(img, center))\n",
    "                \n",
    "                self.dkv_stats[file.stem] = self.dkv.fit(t)\n",
    "        \n",
    "        if deconv: \n",
    "            self.deconv = True\n",
    "            print(self.dkv_stats)\n",
    "        \n",
    "        if val_length:\n",
    "            if val_length>len(self.image_shapes):\n",
    "                print(f'Reducing validation from lenght {val_length} to {len(self.image_shapes)}')\n",
    "                val_length = len(self.image_shapes)\n",
    "            np.random.seed(self.val_seed)\n",
    "            choice = np.random.choice(len(self.image_indices), val_length, replace=False)\n",
    "            self.valid_indices = {i:idx for i, idx in  enumerate(choice)}\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.valid_indices: return len(self.valid_indices)\n",
    "        else: return len(self.image_shapes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if self.valid_indices: idx = self.valid_indices[idx]\n",
    "        img_path = self.files[self.image_indices[idx]]\n",
    "        img = self.data[img_path.name]\n",
    "        centerPos = self.centers[idx]\n",
    "        X = self.tiler.apply(img, centerPos)\n",
    "        \n",
    "        if self.deconv:\n",
    "            d_mean,  d_std = self.dkv_stats[img_path.name]\n",
    "            X = self.dkv.apply(X, d_mean, 2*d_std)\n",
    "            X = np.clip(X, a_min=-5, a_max=5)\n",
    "            \n",
    "        X = X.transpose(2, 0, 1).astype('float32')\n",
    "        \n",
    "        lbl = self.labels[img_path.name]\n",
    "        Y = self.tiler.apply(lbl, centerPos, (0,0), order=0).astype('int64')\n",
    "        \n",
    "        return  TensorImage(X), TensorMask(Y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:28.976850Z",
     "iopub.status.busy": "2021-07-07T03:46:28.976530Z",
     "iopub.status.idle": "2021-07-07T03:46:28.989259Z",
     "shell.execute_reply": "2021-07-07T03:46:28.988219Z",
     "shell.execute_reply.started": "2021-07-07T03:46:28.976818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_batch(batch):\n",
    "    fig, axs = plt.subplots(4,4, figsize=(20,20))   \n",
    "    images = batch[0].cpu().numpy()\n",
    "    labels = batch[1].cpu().numpy()\n",
    "\n",
    "    for i in range(16):     \n",
    "        axs[i%4, i//4].imshow(images[i, 1])\n",
    "        axs[i%4, i//4].imshow(labels[i], alpha=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(batch[0][:,0].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.hist(batch[0][:,1].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.hist(batch[0][:,2].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:39.833958Z",
     "iopub.status.busy": "2021-07-07T03:46:39.833601Z",
     "iopub.status.idle": "2021-07-07T03:46:39.841403Z",
     "shell.execute_reply": "2021-07-07T03:46:39.840273Z",
     "shell.execute_reply.started": "2021-07-07T03:46:39.833922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dc = TorchLoss(smp.losses.DiceLoss(mode='multiclass', classes=[1]))\n",
    "ce = CrossEntropyLossFlat(axis=1) #TorchLoss(smp.losses.SoftCrossEntropyLoss(smooth_factor=0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Step 3 - Set configuration for model training </h6> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:41.991303Z",
     "iopub.status.busy": "2021-07-07T03:46:41.990873Z",
     "iopub.status.idle": "2021-07-07T03:46:42.242517Z",
     "shell.execute_reply": "2021-07-07T03:46:42.240807Z",
     "shell.execute_reply.started": "2021-07-07T03:46:41.991263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1770: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1744: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\albumentations\\imgaug\\transforms.py:337: FutureWarning: This IAAAffine is deprecated. Please use Affine instead\n",
      "  warnings.warn(\"This IAAAffine is deprecated. Please use Affine instead\", FutureWarning)\n",
      "C:\\Users\\soodn\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:688: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from augmentation import Desaturation, GaussianBlur, ChannelBleaching, StainShift\n",
    "\n",
    "class CONFIG():\n",
    "    # paths\n",
    "    path = Path(r'C:/Users/soodn/Downloads/Naveksha/Kaggle HuBMAP/Data/colon-data-reprocessed')\n",
    "    data_path = Path('output_colon/images_scale2')\n",
    "    annotations_path = Path('output_colon/masks_scale2')\n",
    "    \n",
    "    # deepflash2 dataset\n",
    "    scale = 1.5 # data is already downscaled to 2, so absulute downscale is 3\n",
    "    tile_shape = (512, 512)\n",
    "    sample_multiplier = 100 # Sample 100 tiles from each image, per epoch\n",
    "    val_length = 500 # Randomly sample 500 validation tiles\n",
    "    stats = np.array([0, 0 , 0]), np.array([1 , 1, 1])\n",
    "        \n",
    "    # pytorch model (segmentation_models_pytorch)\n",
    "    encoder_name = \"efficientnet-b2\"\n",
    "    encoder_weights = 'imagenet'\n",
    "    in_channels = 3\n",
    "    classes = 2\n",
    "    \n",
    "    # Training\n",
    "    n_splits = 5\n",
    "    mixed_precision_training = True\n",
    "    batch_size = 16\n",
    "    weight_decay = 0.00\n",
    "    loss_func = JointLoss(dc, ce, 1, 1)\n",
    "    metrics = [Dice(), Iou(), Recall(), Precision()]\n",
    "    max_learning_rate = 1e-3\n",
    "    epochs = 10\n",
    "    \n",
    "cfg = CONFIG()\n",
    "\n",
    "# Albumentations augmentations\n",
    "tfms = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomContrast(),\n",
    "        A.RandomGamma(),\n",
    "        A.RandomBrightness(),\n",
    "        ], p=0.3),\n",
    "    A.OneOf([\n",
    "        A.Blur(blur_limit=3, p=1),\n",
    "        A.MedianBlur(blur_limit=3, p=1)\n",
    "    ], p=.1),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(0.002, p=.5),\n",
    "        A.IAAAffine(p=.5),\n",
    "    ], p=.1),\n",
    "    # Additional position augmentations\n",
    "    A.RandomRotate90(p=.5),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "    A.VerticalFlip(p=.5),\n",
    "    A.Cutout(num_holes=10,fill_value=255, \n",
    "             max_h_size=int(.1 * cfg.tile_shape[0]), \n",
    "             max_w_size=int(.1 * cfg.tile_shape[0]), \n",
    "             p=.1),\n",
    "])\n",
    "\n",
    "# augmedical_transforms = [\n",
    "#     Desaturation(p=0.0625, max_desaturation=0.25, max_value_reduction=0.25),\n",
    "#     #Stamping(path=\"../input/augmentation-images\", files=range(1,24), p=cfg.stamping_p, intensity=cfg.stamping_intensity),\n",
    "\n",
    "#     GaussianBlur(channels=3, p=0.1, kernel_size=3, alpha=0.25),\n",
    "#     GaussianBlur(channels=3, p=0.0625, kernel_size=23, alpha=0.5),\n",
    "\n",
    "#     ChannelBleaching(channel=3, p=0.25, min_bleach=0.1, max_bleach=0.25, force_channel=1),\n",
    "#     ChannelBleaching(channel=3, p=0.0625, min_bleach=0.1, max_bleach=0.5, force_channel=2),\n",
    "#     ChannelBleaching(channel=3, p=0.0625, min_bleach=0.1, max_bleach=0.5, force_channel=0),\n",
    "\n",
    "#     #ChannelBlackout(channel=3, p=0.005),\n",
    "#     StainShift(channel=3, p=0.25, min_shift=1, max_shift=7, force_channel=0),\n",
    "#     StainShift(channel=3, p=0.25, min_shift=1, max_shift=7, force_channel=2)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Position Augmentations\n",
    "position_augmentation_kwargs = {\n",
    "    'flip':True,                                \n",
    "    'rotation_range_deg':(0, 360),     \n",
    "    'deformation_grid': (150,150), \n",
    "    'deformation_magnitude':(10,10),\n",
    "    'value_minimum_range':(0, 0), \n",
    "    'value_maximum_range':(1, 1), \n",
    "    'value_slope_range':(1, 1)}\n",
    "\n",
    "# Datasets\n",
    "ds_kwargs = {\n",
    "    'label_path': (cfg.annotations_path/'labels').as_posix(),\n",
    "    'cdf_path': (cfg.annotations_path/'cdfs').as_posix(),\n",
    "    'df_stats': pd.read_csv(cfg.annotations_path/'roi_stats.csv', index_col=[0,1]),\n",
    "    'tile_shape':cfg.tile_shape,\n",
    "    'scale': cfg.scale,\n",
    "    'val_length':cfg.val_length, \n",
    "    'sample_multiplier':cfg.sample_multiplier,\n",
    "    'albumentations_tfms': tfms,\n",
    "   # \"augmedical_transforms\": augmedical_transforms\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#5) [Path('output_colon/images_scale2/CL_HandE_1234_B004_bottomright'),Path('output_colon/images_scale2/CL_HandE_1234_B004_topleft'),Path('output_colon/images_scale2/CL_HandE_1234_B004_topright'),Path('output_colon/images_scale2/HandE_B005_CL_b_RGB_bottomright'),Path('output_colon/images_scale2/HandE_B005_CL_b_RGB_topleft')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(cfg.path/'train.csv')\n",
    "df_train = df_train.rename(columns={\"predicted\":\"encoding\"})\n",
    "df_train = df_train[df_train.id != 'HandE_B005_CL_b_RGB_topright']\n",
    "\n",
    "df_info = pd.read_csv(cfg.path/'HuBMAP-20-dataset_information.csv')\n",
    "files = L([cfg.data_path/x for x in df_train.id])\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Step 4 - Start k-fold training </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on ['CL_HandE_1234_B004_bottomright', 'CL_HandE_1234_B004_topright', 'HandE_B005_CL_b_RGB_bottomright', 'HandE_B005_CL_b_RGB_topleft']\n",
      "Preparing sampling\n",
      "Generating deformation field\n",
      "Generating value augmentation function\n",
      "Calculating stats for stain normalization w/o albumentation tfms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [2/4 00:25<00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04b320a11164977bd8ce2283863a476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (train_idx, val_idx) in enumerate(kf.split(files)):\n",
    "    files_train, files_val = files[train_idx], files[val_idx]\n",
    "    print('Training on', [x.name for x in files_train])\n",
    "    \n",
    "    # Datasets\n",
    "    train_ds = HubmapRandomTileDataset(files_train, **ds_kwargs, **position_augmentation_kwargs)\n",
    "    valid_ds = HubmapValidationDataset(files_val, **ds_kwargs)\n",
    "    \n",
    "    # Model\n",
    "    model = smp.Unet(encoder_name=cfg.encoder_name, \n",
    "                     encoder_weights=cfg.encoder_weights, \n",
    "                     in_channels=cfg.in_channels, \n",
    "                     classes=cfg.classes)\n",
    "\n",
    "    # Dataloader and learner\n",
    "    dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=cfg.batch_size, after_batch=Normalize.from_stats(*cfg.stats))\n",
    "    if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "    \n",
    "    if i==0: \n",
    "        show_batch(dls.one_batch())\n",
    "        \n",
    "    run = wandb.init(project='bricknet', reinit=True, config=cfg, name=f\"default_with_phils_augment_{i}\")\n",
    "\n",
    "    cbs = [SaveModelCallback(monitor='dice'), ElasticDeformCallback, WandbCallback(log_preds=False, log_model=False)]\n",
    "    learn = Learner(dls, model, metrics=cfg.metrics, wd=cfg.weight_decay, loss_func=cfg.loss_func, opt_func=ranger, cbs=cbs)\n",
    "    if cfg.mixed_precision_training: learn.to_fp16()\n",
    "    \n",
    "    print (\"Start model fitting\", learn)\n",
    "    # Fit\n",
    "    learn.fit_one_cycle(cfg.epochs, lr_max=cfg.max_learning_rate)\n",
    "    learn.recorder.plot_metrics()\n",
    "    \n",
    "    # Save Model\n",
    "    print (\"Saving Model\")\n",
    "    state = {'model': learn.model.state_dict(), 'stats':cfg.stats}\n",
    "    torch.save(state, f'models_colon_scratch/unet_{cfg.encoder_name}_{i}.pth', pickle_protocol=2, _use_new_zipfile_serialization=False)\n",
    "    print (\"Model Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
