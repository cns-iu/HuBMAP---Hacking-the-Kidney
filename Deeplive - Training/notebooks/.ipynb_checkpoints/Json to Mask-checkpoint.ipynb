{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to retrieve hand-made annotations. \n",
    "  - Use the `ADD_FC` and `ONLY_FC` parameters to generate labels for the healthy and unhealthy classes.\n",
    "  - Use the `SAVE_TIFF `parameter to save the external data as tiff files of half resolution.\n",
    "  - Use the `PLOT` parameter to visualize the masks.\n",
    "  - Use the `SAVE` parameter to save the masks as rle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import rasterio\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(\"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0567eb3ebc48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_contours_preds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Downloads\\Naveksha\\Kaggle HuBMAP\\Scripts\\4. DeepLive\\HubMap\\code\\utils\\plots.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from params import *\n",
    "from utils.rle import *\n",
    "from data.dataset import load_image\n",
    "from utils.plots import plot_contours_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTITY = rasterio.Affine(1, 0, 0, 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(DATA_PATH + f\"HuBMAP-20-dataset_information.csv\")\n",
    "df_mask = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "\n",
    "ANNOT_PATH = DATA_PATH + \"annotation_v3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = True\n",
    "ADD_FC = True\n",
    "ONLY_FC = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_mask.copy().set_index('id')\n",
    "if ONLY_FC:\n",
    "    new_df['encoding'] = \"\"\n",
    "\n",
    "for id_ in tqdm(df_mask['id']):\n",
    "    print(f' -> {id_}')\n",
    "    if id_ + \".json\" in os.listdir(ANNOT_PATH):        \n",
    "        annot = json.load(open(ANNOT_PATH + id_ + \".json\", 'r'))\n",
    "        \n",
    "        w, h = df_info[df_info['image_file'] == id_ + '.tiff'][['width_pixels', 'height_pixels']].values[0]\n",
    "        \n",
    "        rle = df_mask[df_mask['id'] == id_]['encoding']\n",
    "        \n",
    "#         mask = enc2mask(rle, (w, h)).astype(np.uint8)  # smh not working\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        if not ONLY_FC:\n",
    "            mask += enc2mask(rle, (w, h)).astype(np.uint8)\n",
    "        \n",
    "        added = 0\n",
    "        for info in annot:\n",
    "            label = info['properties']['classification']['name']\n",
    "\n",
    "            if (not ADD_FC) and (label == \"FC\"):\n",
    "                continue\n",
    "                    \n",
    "            if ONLY_FC and label != \"FC\":\n",
    "                continue\n",
    "\n",
    "            poly = info['geometry']['coordinates']\n",
    "            try:\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            except ValueError:\n",
    "                poly = np.concatenate([np.array(poly[i]).squeeze() for i in range(len(poly))])\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            added +=1\n",
    "            \n",
    "        print(f\"Added {added} glomerulis\")\n",
    "        \n",
    "        new_df.loc[id_] = rle_encode_less_memory(mask)\n",
    "        \n",
    "        if PLOT:\n",
    "            img = load_image(os.path.join(TIFF_PATH_4, id_ + \".tiff\"), full_size=False)\n",
    "            \n",
    "            mask = cv2.resize(\n",
    "                mask,\n",
    "                (w // 4, h // 4),\n",
    "                interpolation=cv2.INTER_NEAREST,\n",
    "            )\n",
    "            assert mask.shape == img.shape[:2], (mask.shape, img.shape)\n",
    "        \n",
    "            fig = plot_contours_preds(img, mask, w=1, downsize=4)\n",
    "            w = 1000\n",
    "            h = int(w *  mask.shape[0] / mask.shape[1])\n",
    "            fig.update_layout(\n",
    "                autosize=False,\n",
    "                width=w,\n",
    "                height=h,\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "            break\n",
    "\n",
    "if not PLOT:\n",
    "    name = \"train_fix.csv\" if not ADD_FC else \"train_fc.csv\"\n",
    "    if ONLY_FC:\n",
    "        name = \"train_onlyfc.csv\"\n",
    "    new_df.to_csv(DATA_PATH + name)\n",
    "    \n",
    "    print(f'\\n -> Saved masks to {DATA_PATH + name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = True\n",
    "SAVE_TIFF = False\n",
    "SAVE = False\n",
    "ADD_FC = False\n",
    "ONLY_FC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = [p for p in os.listdir(DATA_PATH + \"extra/\") if p.endswith(\"svs\")]\n",
    "rles = {}\n",
    "\n",
    "for file in tqdm(files):\n",
    "    id_ = file[:-4]\n",
    "    print(f' -> {id_}')\n",
    "    \n",
    "#     if id_ != \"SAS_21908_001\":\n",
    "#         continue\n",
    "    \n",
    "    if os.path.exists(ANNOT_PATH + id_ + \".json\"):\n",
    "        original_img = rasterio.open(DATA_PATH + \"extra/\" + file, transform=IDENTITY, num_threads='all_cpus')\n",
    "        img = original_img.read([1, 2, 3]).transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "        shape = img.shape[:2]\n",
    "        \n",
    "        annot = json.load(open(ANNOT_PATH + id_ + \".json\", 'r'))\n",
    "\n",
    "        mask = np.zeros(shape, dtype=np.uint8)\n",
    "\n",
    "        added = 0\n",
    "        for info in annot:\n",
    "            poly = np.array(info['geometry']['coordinates'])\n",
    "            \n",
    "            try:\n",
    "                label = info['properties']['classification']['name']\n",
    "            except KeyError:\n",
    "                print('??')\n",
    "                label = \"G\"\n",
    "            \n",
    "            if not ADD_FC and label == \"FC\":\n",
    "                continue\n",
    "\n",
    "            if ONLY_FC and label != \"FC\":\n",
    "                continue\n",
    "                \n",
    "            poly = info['geometry']['coordinates']\n",
    "            try:\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            except ValueError:\n",
    "                poly = np.concatenate([np.array(poly[i]).squeeze() for i in range(len(poly))])\n",
    "                mask = cv2.fillPoly(mask, np.int32([poly]), True)\n",
    "            added += 1\n",
    "        \n",
    "        print(f\"Added {added} glomerulis\")\n",
    "        \n",
    "        if PLOT:\n",
    "            print('plot')\n",
    "            fig = plot_contours_preds(img, mask, w=2, downsize=8)\n",
    "\n",
    "            w = 1000\n",
    "            h = int(w *  mask.shape[0] / mask.shape[1])\n",
    "            fig.update_layout(\n",
    "                autosize=False,\n",
    "                width=w,\n",
    "                height=h,\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "            break\n",
    "            \n",
    "        if SAVE:\n",
    "            if SAVE_TIFF:\n",
    "                img = cv2.resize(\n",
    "                    img,\n",
    "                    (img.shape[1] // 2, img.shape[0] // 2),\n",
    "                    interpolation=cv2.INTER_AREA,\n",
    "                )\n",
    "                    \n",
    "                if not os.path.exists(DATA_PATH + \"extra_tiff/\"):\n",
    "                    os.mkdir(DATA_PATH + \"extra_tiff/\")\n",
    "                tifffile.imsave(DATA_PATH + \"extra_tiff/\" + f\"{id_}.tiff\", img)\n",
    "\n",
    "            mask = cv2.resize(\n",
    "                mask,\n",
    "                (mask.shape[1] // 2, mask.shape[0] // 2),\n",
    "                interpolation=cv2.INTER_NEAREST,\n",
    "            )\n",
    "\n",
    "            rles[id_] = rle_encode_less_memory(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot_extra = pd.DataFrame.from_dict(rles, orient='index', columns=['encoding'])\n",
    "\n",
    "if SAVE and not PLOT:\n",
    "    name = \"train_extra.csv\" if not ADD_FC else \"train_extra_fc.csv\"\n",
    "    if ONLY_FC:\n",
    "        name = \"train_extra_onlyfc.csv\"\n",
    "    df_annot_extra.to_csv(DATA_PATH + name)\n",
    "    print(f'\\n -> Saved masks to {DATA_PATH + name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
