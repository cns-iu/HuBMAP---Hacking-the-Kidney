{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-njGXZoIu7l",
    "papermill": {
     "duration": 0.009365,
     "end_time": "2021-05-12T18:31:16.661237",
     "exception": false,
     "start_time": "2021-05-12T18:31:16.651872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Description\n",
    "This kernel provides a starter Pytorch code for inference that performs dividing the images into tiles([based on this kernel](https://www.kaggle.com/iafoss/256x256-images)), selection of tiles with tissue, evaluation of the predictions of multiple models with TTA, combining the tile masks back into image level masks, and conversion into RLE. The inference is performed based on models trained in the [fast.ai starter kernel](https://www.kaggle.com/iafoss/hubmap-fast-ai-starter), provided by me. I hope it will help you to get started with this competition.\n",
    "\n",
    "* Update (12/4): Fix problem with submission to private LB using **rasterio** (thanks to @leighplt for suggesting it in [his kernel](https://www.kaggle.com/leighplt/pytorch-fcn-resnet50)). For the prediction on the public part of the test set the predictions are identical except one of the images, where the new method predicts a mask different by several pixels, but the LB is the same. I think the tiles loaded by rasterio may be slightly different from ones loaded by tifffile for some image compressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-20T18:04:40.036388Z",
     "iopub.status.busy": "2021-05-20T18:04:40.035927Z",
     "iopub.status.idle": "2021-05-20T18:04:43.446588Z",
     "shell.execute_reply": "2021-05-20T18:04:43.445612Z",
     "shell.execute_reply.started": "2021-05-20T18:04:40.036305Z"
    },
    "id": "pHEON1kvIu7r",
    "papermill": {
     "duration": 3.08492,
     "end_time": "2021-05-12T18:31:19.754675",
     "exception": false,
     "start_time": "2021-05-12T18:31:16.669755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T18:23:03.656014Z",
     "iopub.status.busy": "2021-05-20T18:23:03.655682Z",
     "iopub.status.idle": "2021-05-20T18:23:03.66935Z",
     "shell.execute_reply": "2021-05-20T18:23:03.668406Z",
     "shell.execute_reply.started": "2021-05-20T18:23:03.655972Z"
    },
    "id": "WfY_KuBPIu7s",
    "papermill": {
     "duration": 0.029592,
     "end_time": "2021-05-12T18:31:19.79435",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.764758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hubmaptest44/fold0.pth', 'hubmaptest44/fold1.pth', 'hubmaptest44/fold2.pth', 'hubmaptest44/fold3.pth', 'hubmaptest44/fold4.pth']\n"
     ]
    }
   ],
   "source": [
    "sz = 2048   #the size of tiles\n",
    "sz_reduction = 2 #reduce the original images by 4 times\n",
    "expansion = 512\n",
    "TH = 0.5  #threshold for positive predictions\n",
    "DATA = r'C:\\Users\\soodn\\Downloads\\Naveksha\\Kaggle HuBMAP\\Data\\hubmap-kidney-segmentation-data/test'\n",
    "MODELS_rsxt50 = [f'hubmaptest44/fold{i}.pth' for i in range(5)]\n",
    "MODELS_rsxt101 = [f'hubmaptest45/fold{i}.pth' for i in range(5)]\n",
    "\n",
    "print (MODELS_rsxt50)\n",
    "df_sample = pd.read_csv(r'C:\\Users\\soodn\\Downloads\\Naveksha\\Kaggle HuBMAP\\Data\\hubmap-kidney-segmentation-data\\sample_submission.csv')\n",
    "bs = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsC7s0NBIu7s",
    "papermill": {
     "duration": 0.008339,
     "end_time": "2021-05-12T18:31:19.81165",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.803311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-05-20T18:09:09.879459Z",
     "iopub.status.busy": "2021-05-20T18:09:09.879118Z",
     "iopub.status.idle": "2021-05-20T18:09:09.890568Z",
     "shell.execute_reply": "2021-05-20T18:09:09.889275Z",
     "shell.execute_reply.started": "2021-05-20T18:09:09.879432Z"
    },
    "id": "bjjwgkUnIu7s",
    "papermill": {
     "duration": 0.026863,
     "end_time": "2021-05-12T18:31:19.847047",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.820184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions to convert encoding to mask and mask to encoding\n",
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for m,enc in enumerate(encs):\n",
    "        if isinstance(enc,np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2enc(mask, n=1):\n",
    "    pixels = mask.T.flatten()\n",
    "    encs = []\n",
    "    for i in range(1,n+1):\n",
    "        p = (pixels == i).astype(np.int8)\n",
    "        if p.sum() == 0: encs.append(np.nan)\n",
    "        else:\n",
    "            p = np.concatenate([[0], p, [0]])\n",
    "            runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "            runs[1::2] -= runs[::2]\n",
    "            encs.append(' '.join(str(x) for x in runs))\n",
    "    return encs\n",
    "\n",
    "#https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n",
    "#with transposed mask\n",
    "def rle_encode_less_memory(img):\n",
    "    #the image should be transposed\n",
    "    pixels = img.T.flatten()\n",
    "    \n",
    "    # This simplified method requires first and last pixel to be zero\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    \n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T18:09:11.10572Z",
     "iopub.status.busy": "2021-05-20T18:09:11.105397Z",
     "iopub.status.idle": "2021-05-20T18:09:11.123592Z",
     "shell.execute_reply": "2021-05-20T18:09:11.122241Z",
     "shell.execute_reply.started": "2021-05-20T18:09:11.105694Z"
    },
    "id": "TR94UeLoIu7t",
    "papermill": {
     "duration": 0.041336,
     "end_time": "2021-05-12T18:31:19.896992",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.855656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/iafoss/256x256-images\n",
    "mean = np.array([0.65459856,0.48386562,0.69428385])\n",
    "std = np.array([0.15167958,0.23584107,0.13146145])\n",
    "\n",
    "s_th = 40  #saturation blancking threshold\n",
    "p_th = 1000*(sz//256)**2 #threshold for the minimum number of pixels\n",
    "identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "\n",
    "def img2tensor(img,dtype:np.dtype=np.float32):\n",
    "    if img.ndim==2 : img = np.expand_dims(img,2)\n",
    "    img = np.transpose(img,(2,0,1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self, idx, sz=sz, sz_reduction=sz_reduction, expansion=expansion):\n",
    "        self.data = rasterio.open(os.path.join(DATA,idx+'.tiff'), transform = identity,\n",
    "                                 num_threads='all_cpus')\n",
    "        # some images have issues with their format \n",
    "        # and must be saved correctly before reading with rasterio\n",
    "        if self.data.count != 3:\n",
    "            subdatasets = self.data.subdatasets\n",
    "            self.layers = []\n",
    "            if len(subdatasets) > 0:\n",
    "                for i, subdataset in enumerate(subdatasets, 0):\n",
    "                    self.layers.append(rasterio.open(subdataset))\n",
    "        self.shape = self.data.shape\n",
    "        self.sz_reduction = sz_reduction\n",
    "        self.sz = sz_reduction*sz\n",
    "        self.expansion = sz_reduction*expansion\n",
    "        self.pad0 = (self.sz - self.shape[0]%self.sz)%self.sz\n",
    "        self.pad1 = (self.sz - self.shape[1]%self.sz)%self.sz\n",
    "        self.n0max = (self.shape[0] + self.pad0)//self.sz\n",
    "        self.n1max = (self.shape[1] + self.pad1)//self.sz\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n0max*self.n1max\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # the code below may be a little bit difficult to understand,\n",
    "        # but the thing it does is mapping the original image to\n",
    "        # tiles created with adding padding, as done in\n",
    "        # https://www.kaggle.com/iafoss/256x256-images ,\n",
    "        # and then the tiles are loaded with rasterio\n",
    "        # n0,n1 - are the x and y index of the tile (idx = n0*self.n1max + n1)\n",
    "        n0,n1 = idx//self.n1max, idx%self.n1max\n",
    "        # x0,y0 - are the coordinates of the lower left corner of the tile in the image\n",
    "        # negative numbers correspond to padding (which must not be loaded)\n",
    "        x0,y0 = -self.pad0//2 + n0*self.sz - self.expansion//2, -self.pad1//2 + n1*self.sz- self.expansion//2\n",
    "        # make sure that the region to read is within the image\n",
    "        p00,p01 = max(0,x0), min(x0+self.sz+self.expansion,self.shape[0])\n",
    "        p10,p11 = max(0,y0), min(y0+self.sz+self.expansion,self.shape[1])\n",
    "        img = np.zeros((self.sz+self.expansion,self.sz+self.expansion,3),np.uint8)\n",
    "        # mapping the loade region to the tile\n",
    "        if self.data.count == 3:\n",
    "            img[(p00-x0):(p01-x0),(p10-y0):(p11-y0)] = np.moveaxis(self.data.read([1,2,3],\n",
    "                window=Window.from_slices((p00,p01),(p10,p11))), 0, -1)\n",
    "        else:\n",
    "            for i,layer in enumerate(self.layers):\n",
    "                img[(p00-x0):(p01-x0),(p10-y0):(p11-y0),i] =\\\n",
    "                  layer.read(1,window=Window.from_slices((p00,p01),(p10,p11)))\n",
    "        \n",
    "        if self.sz_reduction != 1:\n",
    "            img = cv2.resize(img,((self.sz+self.expansion)//self.sz_reduction,(self.sz+self.expansion)//self.sz_reduction),\n",
    "                             interpolation = cv2.INTER_AREA)\n",
    "        #check for empty imges\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h,s,v = cv2.split(hsv)\n",
    "        if (s>s_th).sum() <= p_th or img.sum() <= p_th:\n",
    "            #images with -1 will be skipped\n",
    "            return img2tensor((img/255.0 - mean)/std), -1\n",
    "        else: return img2tensor((img/255.0 - mean)/std), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T18:09:12.531286Z",
     "iopub.status.busy": "2021-05-20T18:09:12.530928Z",
     "iopub.status.idle": "2021-05-20T18:09:12.54271Z",
     "shell.execute_reply": "2021-05-20T18:09:12.541378Z",
     "shell.execute_reply.started": "2021-05-20T18:09:12.531257Z"
    },
    "id": "oza-gjKAIu7t",
    "papermill": {
     "duration": 0.027498,
     "end_time": "2021-05-12T18:31:19.933229",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.905731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterator like wrapper that returns predicted masks\n",
    "class Model_pred:\n",
    "    def __init__(self, models, dl, tta:bool=True, half:bool=False):\n",
    "        self.models = models\n",
    "        self.dl = dl\n",
    "        self.tta = tta\n",
    "        self.half = half\n",
    "        \n",
    "    def __iter__(self):\n",
    "        count=0\n",
    "        with torch.no_grad():\n",
    "            for x,y in iter(self.dl):\n",
    "                if ((y>=0).sum() > 0): #exclude empty images\n",
    "                    x = x[y>=0].to(device)\n",
    "                    y = y[y>=0]\n",
    "                    if self.half: x = x.half()\n",
    "                    py = None\n",
    "                    for model in self.models:\n",
    "                        p = model(x)\n",
    "                        p = torch.sigmoid(p).detach()\n",
    "                        if py is None: py = p\n",
    "                        else: py += p\n",
    "                    if self.tta:\n",
    "                        #x,y,xy flips as TTA\n",
    "                        flips = [[-1],[-2],[-2,-1]]\n",
    "                        for f in flips:\n",
    "                            xf = torch.flip(x,f)\n",
    "                            for model in self.models:\n",
    "                                p = model(xf)\n",
    "                                p = torch.flip(p,f)\n",
    "                                py += torch.sigmoid(p).detach()\n",
    "                        py /= (1+len(flips))        \n",
    "                    py /= len(self.models)\n",
    "\n",
    "                    py = F.upsample(py, scale_factor=sz_reduction, mode=\"bilinear\")\n",
    "                    py = py.permute(0,2,3,1).float().cpu()\n",
    "                    \n",
    "                    batch_size = len(py)\n",
    "                    for i in range(batch_size):\n",
    "                        yield py[i,expansion*sz_reduction//2:-expansion*sz_reduction//2,expansion*sz_reduction//2:-expansion*sz_reduction//2],y[i]\n",
    "                        count += 1\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.dl.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5aUJ3oWIu7u",
    "papermill": {
     "duration": 0.008713,
     "end_time": "2021-05-12T18:31:19.950865",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.942152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-05-20T18:09:15.114078Z",
     "iopub.status.busy": "2021-05-20T18:09:15.113711Z",
     "iopub.status.idle": "2021-05-20T18:09:15.151006Z",
     "shell.execute_reply": "2021-05-20T18:09:15.149967Z",
     "shell.execute_reply.started": "2021-05-20T18:09:15.114046Z"
    },
    "id": "gpVGG-_5Iu7u",
    "papermill": {
     "duration": 0.061964,
     "end_time": "2021-05-12T18:31:20.021808",
     "exception": false,
     "start_time": "2021-05-12T18:31:19.959844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.tensor as Tensor\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self, input_channels:list, output_channels:list):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Sequential(nn.Conv2d(in_ch, out_ch*2, kernel_size=3, padding=1),\n",
    "             nn.ReLU(inplace=True), nn.BatchNorm2d(out_ch*2),\n",
    "             nn.Conv2d(out_ch*2, out_ch, kernel_size=3, padding=1))\n",
    "            for in_ch, out_ch in zip(input_channels, output_channels)])\n",
    "\n",
    "    def forward(self, xs:list, last_layer):\n",
    "        hcs = [F.interpolate(c(x),scale_factor=2**(len(self.convs)-i),mode='bilinear')\n",
    "               for i,(c,x) in enumerate(zip(self.convs, xs))]\n",
    "        hcs.append(last_layer)\n",
    "        return torch.cat(hcs, dim=1)\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in_c:int, x_in_c:int, nf:int=None, blur:bool=False,\n",
    "                 self_attention:bool=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(x_in_c)\n",
    "        ni = up_in_c//2 + x_in_c\n",
    "        nf = nf if nf is not None else max(up_in_c//2,32)\n",
    "        self.conv1 = ConvLayer(ni, nf, norm_type=None, **kwargs)\n",
    "        self.conv2 = ConvLayer(nf, nf, norm_type=None,\n",
    "            xtra=SelfAttention(nf) if self_attention else None, **kwargs)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, up_in:Tensor, left_in:Tensor) -> Tensor:\n",
    "        s = left_in\n",
    "        up_out = self.shuf(up_in)\n",
    "        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n",
    "        return self.conv2(self.conv1(cat_x))\n",
    "\n",
    "class _ASPPModule(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size, padding, dilation, groups=1):\n",
    "        super().__init__()\n",
    "        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                stride=1, padding=padding, dilation=dilation, bias=False, groups=groups)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_conv(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, inplanes=512, mid_c=256, dilations=[6, 12, 18, 24], out_c=None):\n",
    "        super().__init__()\n",
    "        self.aspps = [_ASPPModule(inplanes, mid_c, 1, padding=0, dilation=1)] + \\\n",
    "            [_ASPPModule(inplanes, mid_c, 3, padding=d, dilation=d,groups=4) for d in dilations]\n",
    "        self.aspps = nn.ModuleList(self.aspps)\n",
    "        self.global_pool = nn.Sequential(nn.AdaptiveMaxPool2d((1, 1)),\n",
    "                        nn.Conv2d(inplanes, mid_c, 1, stride=1, bias=False),\n",
    "                        nn.BatchNorm2d(mid_c), nn.ReLU())\n",
    "        out_c = out_c if out_c is not None else mid_c\n",
    "        self.out_conv = nn.Sequential(nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False),\n",
    "                                    nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n",
    "        self.conv1 = nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False)\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.global_pool(x)\n",
    "        xs = [aspp(x) for aspp in self.aspps]\n",
    "        x0 = F.interpolate(x0, size=xs[0].size()[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x0] + xs, dim=1)\n",
    "        return self.out_conv(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "import torch.hub\n",
    "# hub_model = torch.hub.load(\n",
    "#     'moskomule/senet.pytorch',\n",
    "#     'se_resnet50',\n",
    "#     pretrained=True,)\n",
    "import torchvision\n",
    "class UneXt(nn.Module):\n",
    "    def __init__(self, m, stride=1, **kwargs):\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "        # m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models',\n",
    "        #                    'resnext101_32x4d_swsl')\n",
    "#         m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models',\n",
    "#                            'resnext50_32x4d_swsl', pretrained=False)\n",
    "        #m = ResNet(Bottleneck, [3, 4, 23, 3], groups=32, width_per_group=4)\n",
    "        #m = torchvision.models.resnext50_32x4d(pretrained=False)\n",
    "        # m = torch.hub.load(\n",
    "        #     'moskomule/senet.pytorch',\n",
    "        #     'se_resnet101',\n",
    "        #     pretrained=True,)\n",
    "\n",
    "        #m=torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "        self.enc0 = nn.Sequential(m.conv1, m.bn1, nn.ReLU(inplace=True))\n",
    "        self.enc1 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "                            m.layer1) #256\n",
    "        self.enc2 = m.layer2 #512\n",
    "        self.enc3 = m.layer3 #1024\n",
    "        self.enc4 = m.layer4 #2048\n",
    "        #aspp with customized dilatations\n",
    "        self.aspp = ASPP(2048,256,out_c=512,dilations=[stride*1,stride*2,stride*3,stride*4])\n",
    "        self.drop_aspp = nn.Dropout2d(0.5)\n",
    "        #decoder\n",
    "        self.dec4 = UnetBlock(512,1024,256)\n",
    "        self.dec3 = UnetBlock(256,512,128)\n",
    "        self.dec2 = UnetBlock(128,256,64)\n",
    "        self.dec1 = UnetBlock(64,64,32)\n",
    "        self.fpn = FPN([512,256,128,64],[16]*4)\n",
    "        self.drop = nn.Dropout2d(0.1)\n",
    "        self.final_conv = ConvLayer(32+16*4, 1, ks=1, norm_type=None, act_cls=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc0 = self.enc0(x)\n",
    "        enc1 = self.enc1(enc0)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        enc5 = self.aspp(enc4)\n",
    "        dec3 = self.dec4(self.drop_aspp(enc5),enc3)\n",
    "        dec2 = self.dec3(dec3,enc2)\n",
    "        dec1 = self.dec2(dec2,enc1)\n",
    "        dec0 = self.dec1(dec1,enc0)\n",
    "        x = self.fpn([enc5, dec3, dec2, dec1], dec0)\n",
    "        x = self.final_conv(self.drop(x))\n",
    "        x = F.interpolate(x,scale_factor=2,mode='bilinear')\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T18:13:54.978235Z",
     "iopub.status.busy": "2021-05-20T18:13:54.977838Z",
     "iopub.status.idle": "2021-05-20T18:13:55.005608Z",
     "shell.execute_reply": "2021-05-20T18:13:55.003511Z",
     "shell.execute_reply.started": "2021-05-20T18:13:54.978203Z"
    },
    "id": "4NmLCbtVIu7w",
    "papermill": {
     "duration": 44.771748,
     "end_time": "2021-05-12T18:32:04.802749",
     "exception": false,
     "start_time": "2021-05-12T18:31:20.031001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hubmaptest44/fold0.pth', 'hubmaptest44/fold1.pth', 'hubmaptest44/fold2.pth', 'hubmaptest44/fold3.pth', 'hubmaptest44/fold4.pth']\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "print (MODELS_rsxt50)\n",
    "for path in MODELS_rsxt50:\n",
    "    state_dict = torch.load(path)\n",
    "    model = UneXt(m=torchvision.models.resnext50_32x4d(pretrained=False)).cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.float()\n",
    "    model.eval()\n",
    "    #model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "for path in MODELS_rsxt101:\n",
    "    state_dict = torch.load(path)\n",
    "    model = UneXt(m=ResNet(Bottleneck, [3, 4, 23, 3], groups=32, width_per_group=4)).cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.float()\n",
    "    model.eval()\n",
    "    #model.to(device)\n",
    "    models.append(model)    \n",
    "    \n",
    "    \n",
    "del state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcJ0WYIuIu7x",
    "papermill": {
     "duration": 0.008819,
     "end_time": "2021-05-12T18:32:04.820874",
     "exception": false,
     "start_time": "2021-05-12T18:32:04.812055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-12T18:32:04.851742Z",
     "iopub.status.busy": "2021-05-12T18:32:04.851143Z",
     "iopub.status.idle": "2021-05-12T20:15:53.32829Z",
     "shell.execute_reply": "2021-05-12T20:15:53.324774Z"
    },
    "id": "exgfYD2aIu7y",
    "outputId": "ac17da08-7794-4fbe-86f3-b2b308331460",
    "papermill": {
     "duration": 6228.498649,
     "end_time": "2021-05-12T20:15:53.328441",
     "exception": false,
     "start_time": "2021-05-12T18:32:04.829792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a15663d11f4baabe1a8fa12e4ffe05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n",
      "torch.Size([4096, 4096, 1])\n"
     ]
    }
   ],
   "source": [
    "names,preds = [],[]\n",
    "for idx,row in tqdm(df_sample.iterrows(),total=len(df_sample)):\n",
    "    idx = row['id']\n",
    "    ds = HuBMAPDataset(idx)\n",
    "    #rasterio cannot be used with multiple workers\n",
    "    dl = DataLoader(ds,bs,num_workers=0,shuffle=False,pin_memory=True)\n",
    "    mp = Model_pred(models,dl)\n",
    "    #generate masks\n",
    "    mask = torch.zeros(len(ds),ds.sz,ds.sz,dtype=torch.int8)\n",
    "    for p,i in iter(mp): \n",
    "        print(p.shape)\n",
    "        mask[i.item()] = p.squeeze(-1) > TH\n",
    "    \n",
    "    #reshape tiled masks into a single mask and crop padding\n",
    "    mask = mask.view(ds.n0max,ds.n1max,ds.sz,ds.sz).\\\n",
    "        permute(0,2,1,3).reshape(ds.n0max*ds.sz,ds.n1max*ds.sz)\n",
    "    mask = mask[ds.pad0//2:-(ds.pad0-ds.pad0//2) if ds.pad0 > 0 else ds.n0max*ds.sz,\n",
    "        ds.pad1//2:-(ds.pad1-ds.pad1//2) if ds.pad1 > 0 else ds.n1max*ds.sz]\n",
    "    \n",
    "    #convert to rle\n",
    "    #https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n",
    "    rle = rle_encode_less_memory(mask.numpy())\n",
    "    names.append(idx)\n",
    "    preds.append(rle)\n",
    "    del mask, ds, dl\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T20:15:53.451599Z",
     "iopub.status.busy": "2021-05-12T20:15:53.450983Z",
     "iopub.status.idle": "2021-05-12T20:15:53.900909Z",
     "shell.execute_reply": "2021-05-12T20:15:53.899785Z"
    },
    "id": "Vs-ofmkEIu7y",
    "papermill": {
     "duration": 0.513902,
     "end_time": "2021-05-12T20:15:53.901034",
     "exception": false,
     "start_time": "2021-05-12T20:15:53.387132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':names,'predicted':preds})\n",
    "df.to_csv('submission-wgo.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T20:15:54.038621Z",
     "iopub.status.busy": "2021-05-12T20:15:54.03758Z",
     "iopub.status.idle": "2021-05-12T20:15:54.057824Z",
     "shell.execute_reply": "2021-05-12T20:15:54.058323Z"
    },
    "id": "PX5v2PpcIu7y",
    "outputId": "777c3b6e-51e8-4767-b537-fcf647debb22",
    "papermill": {
     "duration": 0.101321,
     "end_time": "2021-05-12T20:15:54.05848",
     "exception": false,
     "start_time": "2021-05-12T20:15:53.957159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ec3f1bb9</td>\n",
       "      <td>60810276 25 60834258 41 60858240 55 60882224 67 60906209 76 60930195 84 60954182 91 60978168 99 61002155 106 61026143 111 61050130 117 61074118 122 61098107 125 61122095 129 61146083 134 61170071 138 61194060 142 61218049 145 61242037 149 61266026 152 61290015 155 61314003 158 61337992 161 61361981 164 61385970 167 61409959 170 61433948 172 61457937 175 61481926 177 61505915 180 61529904 182 61553893 185 61577882 187 61601871 190 61625860 192 61649849 194 61673838 196 61697828 197 61721817 199 61745806 201 61769795 203 61793784 205 61817773 207 61841763 207 61865752 209 61889741 211 619137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3589adb90</td>\n",
       "      <td>68688396 27 68717824 57 68747252 66 68776681 74 68806111 80 68835541 85 68864971 91 68894402 96 68923832 101 68953263 106 68982694 110 69012125 115 69041556 120 69070987 126 69100417 132 69129848 137 69159279 141 69188711 145 69218142 150 69247573 156 69277005 161 69306436 165 69335867 170 69365299 174 69394730 179 69424161 183 69453593 187 69483024 191 69512456 193 69541887 197 69571318 201 69600750 203 69630181 207 69659613 209 69689045 212 69718476 215 69747908 217 69777340 220 69806771 223 69836203 225 69865635 227 69895067 229 69924498 232 69953930 234 69983362 236 70012794 238 700422...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d488c759a</td>\n",
       "      <td>548435551 21 548482203 37 548528858 47 548575514 55 548622171 62 548668828 69 548715485 75 548762142 81 548808799 86 548855457 91 548902115 95 548948773 99 548995431 103 549042089 106 549088747 110 549135405 114 549182063 117 549228721 121 549275380 123 549322038 127 549368696 130 549415354 133 549462012 137 549508670 140 549555328 143 549601986 146 549648644 150 549695302 153 549741960 156 549788618 159 549835276 162 549881934 165 549928592 168 549975251 170 550021909 173 550068567 176 550115225 179 550161883 182 550208542 184 550255200 186 550301858 189 550348517 191 550395175 194 550441...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa05346ff</td>\n",
       "      <td>52856692 23 52887404 40 52918118 51 52948832 61 52979547 70 53010261 80 53040976 89 53071692 97 53102409 103 53133126 110 53163843 116 53194560 122 53225277 129 53255994 136 53286712 142 53317429 149 53348147 155 53378864 162 53409582 168 53440300 174 53471018 180 53501736 186 53532455 191 53563173 196 53593891 201 53624610 206 53655329 210 53686047 215 53716766 219 53747485 224 53778204 228 53808923 232 53839641 238 53870360 242 53901080 246 53931799 251 53962518 256 53993237 261 54023956 267 54054675 272 54085394 276 54116113 281 54146833 283 54177552 287 54208271 291 54238990 296 542697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57512b7f1</td>\n",
       "      <td>233201200 4 233234440 5 233267679 6 233300919 7 233334159 7 233367399 7 233400639 7 233433879 8 233467119 8 233500360 7 233533601 6 233566842 5 233600082 5 233600252 3 233633322 6 233633491 5 233666563 4 233666730 7 233699803 4 233699969 9 233733044 2 233733209 11 233766448 13 233799688 13 233832927 15 233866165 16 233899405 16 233932645 16 233965885 16 233999125 16 234032365 17 234065605 18 234098845 19 234132085 20 234165325 20 234198565 20 234231805 20 234265045 20 234298285 20 234331525 20 234364765 20 234398005 20 234431245 20 234464485 20 234497725 19 234530965 19 234564205 18 234597...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "0  2ec3f1bb9   \n",
       "1  3589adb90   \n",
       "2  d488c759a   \n",
       "3  aa05346ff   \n",
       "4  57512b7f1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 predicted  \n",
       "0  60810276 25 60834258 41 60858240 55 60882224 67 60906209 76 60930195 84 60954182 91 60978168 99 61002155 106 61026143 111 61050130 117 61074118 122 61098107 125 61122095 129 61146083 134 61170071 138 61194060 142 61218049 145 61242037 149 61266026 152 61290015 155 61314003 158 61337992 161 61361981 164 61385970 167 61409959 170 61433948 172 61457937 175 61481926 177 61505915 180 61529904 182 61553893 185 61577882 187 61601871 190 61625860 192 61649849 194 61673838 196 61697828 197 61721817 199 61745806 201 61769795 203 61793784 205 61817773 207 61841763 207 61865752 209 61889741 211 619137...  \n",
       "1  68688396 27 68717824 57 68747252 66 68776681 74 68806111 80 68835541 85 68864971 91 68894402 96 68923832 101 68953263 106 68982694 110 69012125 115 69041556 120 69070987 126 69100417 132 69129848 137 69159279 141 69188711 145 69218142 150 69247573 156 69277005 161 69306436 165 69335867 170 69365299 174 69394730 179 69424161 183 69453593 187 69483024 191 69512456 193 69541887 197 69571318 201 69600750 203 69630181 207 69659613 209 69689045 212 69718476 215 69747908 217 69777340 220 69806771 223 69836203 225 69865635 227 69895067 229 69924498 232 69953930 234 69983362 236 70012794 238 700422...  \n",
       "2  548435551 21 548482203 37 548528858 47 548575514 55 548622171 62 548668828 69 548715485 75 548762142 81 548808799 86 548855457 91 548902115 95 548948773 99 548995431 103 549042089 106 549088747 110 549135405 114 549182063 117 549228721 121 549275380 123 549322038 127 549368696 130 549415354 133 549462012 137 549508670 140 549555328 143 549601986 146 549648644 150 549695302 153 549741960 156 549788618 159 549835276 162 549881934 165 549928592 168 549975251 170 550021909 173 550068567 176 550115225 179 550161883 182 550208542 184 550255200 186 550301858 189 550348517 191 550395175 194 550441...  \n",
       "3  52856692 23 52887404 40 52918118 51 52948832 61 52979547 70 53010261 80 53040976 89 53071692 97 53102409 103 53133126 110 53163843 116 53194560 122 53225277 129 53255994 136 53286712 142 53317429 149 53348147 155 53378864 162 53409582 168 53440300 174 53471018 180 53501736 186 53532455 191 53563173 196 53593891 201 53624610 206 53655329 210 53686047 215 53716766 219 53747485 224 53778204 228 53808923 232 53839641 238 53870360 242 53901080 246 53931799 251 53962518 256 53993237 261 54023956 267 54054675 272 54085394 276 54116113 281 54146833 283 54177552 287 54208271 291 54238990 296 542697...  \n",
       "4  233201200 4 233234440 5 233267679 6 233300919 7 233334159 7 233367399 7 233400639 7 233433879 8 233467119 8 233500360 7 233533601 6 233566842 5 233600082 5 233600252 3 233633322 6 233633491 5 233666563 4 233666730 7 233699803 4 233699969 9 233733044 2 233733209 11 233766448 13 233799688 13 233832927 15 233866165 16 233899405 16 233932645 16 233965885 16 233999125 16 234032365 17 234065605 18 234098845 19 234132085 20 234165325 20 234198565 20 234231805 20 234265045 20 234298285 20 234331525 20 234364765 20 234398005 20 234431245 20 234464485 20 234497725 19 234530965 19 234564205 18 234597...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
