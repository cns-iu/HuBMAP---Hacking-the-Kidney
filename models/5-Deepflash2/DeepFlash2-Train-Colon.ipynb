{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcsetTMwKXqC"
   },
   "source": [
    "<h1> HubMap - Hacking the Kidney </h1>\n",
    "<h3> Goal - Mapping the human body at function tissue unit level - detect crypt FTUs in colon </h3>\n",
    "\n",
    "Implementation of Kaggle Notebook - Innovation Prize Winner - Deep Flash2 <br>\n",
    "Description - Train 5 fold model on rescaled images <br>\n",
    "Input - train.csv (csv file containing rle format mask), HuBMAP-20-dataset_information.csv (csv containing meta data about the images), Downscaled images and masks, roi-stats.csv (csv containing pdfs for each image), wandb credentials, download deepflash2 library (link - https://www.kaggle.com/matjes/deepflash2-lfs), hubmap_loss_metrics.py <br>\n",
    "Output - trained models\n",
    "\n",
    "<b>How to use?</b><br> \n",
    "Change the basepath to where your data lives and you're good to go. <br>\n",
    "Use the `num_frozen_layers` and `transfer_learning` variables in the Config to turn transfer learning on/off.\n",
    "\n",
    "For transfer learning: Set `transfer_learning=True` and `num_frozen_layers=168`. The default number of layers frozen is 168 since it gave the best results, but you can change it to experiment.\n",
    "\n",
    "For no transfer learning: Set `transfer_learning=False` and `num_frozen_layers=0`.\n",
    "\n",
    "Link to the original notebook -  https://www.kaggle.com/matjes/hubmap-deepflash2-train/data?scriptVersionId=63051354\n",
    "\n",
    "\n",
    "<h6> Step 1 - Installation and package loading <h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-07-07T03:39:14.602530Z",
     "iopub.status.busy": "2021-07-07T03:39:14.602245Z",
     "iopub.status.idle": "2021-07-07T03:39:47.249738Z",
     "shell.execute_reply": "2021-07-07T03:39:47.248733Z",
     "shell.execute_reply.started": "2021-07-07T03:39:14.602504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/N/soft/rhel7/deeplearning/Python-3.9.6/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q ../../../../input/deepflash2-lfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!git clone https://github.com/qubvel/segmentation_models.pytorch.git\n",
    "!pip install -q ./segmentation_models.pytorch\n",
    "!pip install git+https://github.com/p-sodmann/Augmedical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:42:27.814638Z",
     "iopub.status.busy": "2021-07-07T03:42:27.814267Z",
     "iopub.status.idle": "2021-07-07T03:42:27.825683Z",
     "shell.execute_reply": "2021-07-07T03:42:27.824626Z",
     "shell.execute_reply.started": "2021-07-07T03:42:27.814606Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import zarr, cv2, random\n",
    "import numpy as np, pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "from fastai.vision.all import *\n",
    "from deepflash2.all import *\n",
    "from scipy import interpolate\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from hubmap_loss_metrics import *\n",
    "from augmedical.transforms.transforms import ImageTransform\n",
    "from augmedical.colors.colors import Deconvolution\n",
    "from tqdm.auto import tqdm\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:08.315842Z",
     "iopub.status.busy": "2021-07-07T03:46:08.315490Z",
     "iopub.status.idle": "2021-07-07T03:46:10.155163Z",
     "shell.execute_reply": "2021-07-07T03:46:10.154397Z",
     "shell.execute_reply.started": "2021-07-07T03:46:08.315808Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msoodn\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /N/u/yashjain/Carbonate/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"6883cb3173ae477ba8d8bde16206f1eaa23dc106\")\n",
    "from fastai.callback.wandb import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Step 2 - Make patches of the image file, and define helper functions </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:16.224387Z",
     "iopub.status.busy": "2021-07-07T03:46:16.224060Z",
     "iopub.status.idle": "2021-07-07T03:46:16.391818Z",
     "shell.execute_reply": "2021-07-07T03:46:16.390862Z",
     "shell.execute_reply.started": "2021-07-07T03:46:16.224356Z"
    }
   },
   "outputs": [],
   "source": [
    "@patch\n",
    "def apply(self:DeformationField, data, offset=(0, 0), pad=(0, 0), order=1):\n",
    "    \"Apply deformation field to image using interpolation\"\n",
    "    outshape = tuple(int(s - p) for (s, p) in zip(self.shape, pad))\n",
    "    coords = [np.squeeze(d).astype('float32').reshape(*outshape) for d in self.get(offset, pad)]\n",
    "    # Get slices to avoid loading all data (.zarr files)\n",
    "    sl = []\n",
    "    for i in range(len(coords)):\n",
    "        cmin, cmax = int(coords[i].min()), int(coords[i].max())\n",
    "        dmax = data.shape[i]\n",
    "        if cmin<0: \n",
    "            cmax = max(-cmin, cmax)\n",
    "            cmin = 0 \n",
    "        elif cmax>dmax:\n",
    "            cmin = min(cmin, 2*dmax-cmax)\n",
    "            cmax = dmax\n",
    "            coords[i] -= cmin\n",
    "        else: coords[i] -= cmin\n",
    "        sl.append(slice(cmin, cmax))    \n",
    "    if len(data.shape) == len(self.shape) + 1:\n",
    "        tile = np.empty((*outshape, data.shape[-1]))\n",
    "        for c in range(data.shape[-1]):\n",
    "            # Adding divide\n",
    "            tile[..., c] = cv2.remap(data[sl[0],sl[1], c]/255, coords[1],coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n",
    "    else:\n",
    "        tile = cv2.remap(data[sl[0], sl[1]], coords[1], coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT)\n",
    "    return tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:21.744659Z",
     "iopub.status.busy": "2021-07-07T03:46:21.744324Z",
     "iopub.status.idle": "2021-07-07T03:46:21.778546Z",
     "shell.execute_reply": "2021-07-07T03:46:21.777287Z",
     "shell.execute_reply.started": "2021-07-07T03:46:21.744624Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "class HubmapRandomTileDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch Dataset that creates random tiles with augmentations from the input images.\n",
    "    \"\"\"\n",
    "    n_inp = 1\n",
    "    def __init__(self, \n",
    "                 files,\n",
    "                 label_path,\n",
    "                 cdf_path, \n",
    "                 df_stats, \n",
    "                 sample_multiplier=50,\n",
    "                 tile_shape = (512,512),\n",
    "                 scale = 1,\n",
    "                 flip = True,                                \n",
    "                 rotation_range_deg = (0, 360),     \n",
    "                 deformation_grid = (150,150), \n",
    "                 deformation_magnitude = (10,10),\n",
    "                 value_minimum_range = (0, 0), \n",
    "                 value_maximum_range = (1, 1), \n",
    "                 value_slope_range = (1, 1),\n",
    "                 albumentations_tfms=None,\n",
    "                 augmedical_transforms=None,\n",
    "                 deconv=True,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        store_attr('files, df_stats, sample_multiplier, tile_shape, scale, albumentations_tfms')\n",
    "        store_attr('flip, rotation_range_deg, deformation_grid, deformation_magnitude, value_minimum_range, value_maximum_range, value_slope_range')\n",
    "        \n",
    "        self.data = zarr.open_group(self.files[0].parent.as_posix(), mode='r')\n",
    "        self.labels = zarr.open_group(label_path)\n",
    "        self.cdfs = zarr.open_group(cdf_path)\n",
    "        \n",
    "        self.indices = []\n",
    "        self.center_indices = []\n",
    "        self.df_stats = self.df_stats[self.df_stats.index.isin([f.stem for f in self.files],  level=0)]\n",
    "        print('Preparing sampling')\n",
    "        for key, grp in self.df_stats.groupby('idx'):\n",
    "            for (idx, i), row in grp.iterrows():\n",
    "                self.indices.append(idx)\n",
    "                self.center_indices.append(i)\n",
    "            for _ in range(self.sample_multiplier):\n",
    "                self.indices.append(idx)\n",
    "                self.center_indices.append(None)         \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        # briefly disable transformations to calc stats\n",
    "        self.albumentations_tfms = None   \n",
    "        self.augmedical_transforms = None\n",
    "        self.deconv = False\n",
    "        \n",
    "        if deconv:\n",
    "            print('Calculating stats for stain normalization w/o albumentation tfms')\n",
    "            self.dkv_stats = {}\n",
    "            self.dkv = Deconvolution()\n",
    "            for f in progress_bar(self.files):\n",
    "                idxs = [i for i, x in enumerate(self.indices) if x==f.stem]\n",
    "                t = []\n",
    "                for i in tqdm(idxs[:100], leave=False):\n",
    "                    t.append(self[i][0].numpy().transpose(1,2,0))\n",
    "                \n",
    "                self.dkv_stats[f.stem] = self.dkv.fit(t)\n",
    "                \n",
    "            self.deconv = True\n",
    "        \n",
    "            print(self.dkv_stats)\n",
    "        \n",
    "        self.albumentations_tfms = albumentations_tfms   \n",
    "        self.augmedical_transforms = augmedical_transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx): idx = idx.tolist()       \n",
    "        file_name = self.indices[idx]\n",
    "        center_idx = self.center_indices[idx]\n",
    "\n",
    "        img = self.data[file_name]\n",
    "        n_channels = img.shape[-1]\n",
    "\n",
    "        lbl = self.labels[file_name]\n",
    "        cdf = self.cdfs[file_name]\n",
    "\n",
    "        center = self.random_center(cdf[:], lbl.shape, scale=512, file=file_name, center_idx=center_idx)\n",
    "        X = self.gammaFcn(self.deformationField.apply(img, center).flatten()).reshape((*self.tile_shape, n_channels))\n",
    "        Y = self.deformationField.apply(lbl, center, (0,0), 0)\n",
    "\n",
    "        if self.albumentations_tfms:\n",
    "            augmented = self.albumentations_tfms(image=(X*255).astype('uint8'),mask=Y.astype('uint8'))\n",
    "            X = (augmented['image']/255)\n",
    "            Y = augmented['mask']\n",
    "            \n",
    "        if self.deconv:\n",
    "            d_mean,  d_std = self.dkv_stats[file_name]\n",
    "            X = self.dkv.apply(X, d_mean, 2*d_std)\n",
    "            X = np.clip(X, a_min=-5, a_max=5)\n",
    "            \n",
    "        X = X.transpose(2, 0, 1).astype('float32')\n",
    "        Y = Y.astype('int64')\n",
    "        \n",
    "        X = TensorImage(X)\n",
    "        \n",
    "        if self.augmedical_transforms:\n",
    "            for transform in self.augmedical_transforms:\n",
    "                X = transform(X)\n",
    "        \n",
    "        return  X, TensorMask(Y)\n",
    "        \n",
    "    def random_center(self, cdf, orig_shape, file, center_idx, scale=512):\n",
    "        'Sample random center'\n",
    "        if center_idx:\n",
    "            stats = self.df_stats.loc[file, center_idx]\n",
    "            cx = random.randrange(stats.top, stats.top+stats.height)\n",
    "            cy = random.randrange(stats.left, stats.left+stats.width)\n",
    "        else:\n",
    "            scale_y = int((orig_shape[1]/orig_shape[0])*scale)\n",
    "            # print (len(cdf), np.argmax(cdf > np.random.random()), scale, scale_y)\n",
    "            cx, cy, cz= np.unravel_index(np.argmax(cdf > np.random.random()), (scale,scale_y, 3))\n",
    "            cx = int(cx*orig_shape[0]/scale)\n",
    "            cy = int(cy*orig_shape[1]/scale_y)\n",
    "        return cx, cy\n",
    "        \n",
    "    def on_epoch_end(self, verbose=True):\n",
    "\n",
    "        if verbose: print(\"Generating deformation field\")\n",
    "        self.deformationField = DeformationField(self.tile_shape, self.scale)\n",
    "\n",
    "        if self.rotation_range_deg[1] > self.rotation_range_deg[0]:\n",
    "            self.deformationField.rotate(\n",
    "                theta=np.pi * (np.random.random()\n",
    "                            * (self.rotation_range_deg[1] - self.rotation_range_deg[0])\n",
    "                            + self.rotation_range_deg[0])\n",
    "                            / 180.0)\n",
    "\n",
    "        if self.flip:\n",
    "            self.deformationField.mirror(np.random.choice((True,False),2))\n",
    "\n",
    "        if self.deformation_grid is not None:\n",
    "            self.deformationField.addRandomDeformation(\n",
    "                self.deformation_grid, self.deformation_magnitude)\n",
    "\n",
    "        if verbose: print(\"Generating value augmentation function\")\n",
    "        minValue = (self.value_minimum_range[0]\n",
    "            + (self.value_minimum_range[1] - self.value_minimum_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        maxValue = (self.value_maximum_range[0]\n",
    "            + (self.value_maximum_range[1] - self.value_maximum_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        intermediateValue = 0.5 * (\n",
    "            self.value_slope_range[0]\n",
    "            + (self.value_slope_range[1] - self.value_slope_range[0])\n",
    "            * np.random.random())\n",
    "\n",
    "        self.gammaFcn = interpolate.interp1d([0, 0.5, 1.0], [minValue, intermediateValue, maxValue], kind=\"quadratic\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:24.406242Z",
     "iopub.status.busy": "2021-07-07T03:46:24.405842Z",
     "iopub.status.idle": "2021-07-07T03:46:24.429832Z",
     "shell.execute_reply": "2021-07-07T03:46:24.428612Z",
     "shell.execute_reply.started": "2021-07-07T03:46:24.406212Z"
    }
   },
   "outputs": [],
   "source": [
    "class HubmapValidationDataset(Dataset):\n",
    "    \"Pytorch Dataset that creates random tiles for validation and prediction on new data.\"\n",
    "    n_inp = 1\n",
    "    def __init__(self, \n",
    "                 files, \n",
    "                 label_path, \n",
    "                 tile_shape = (512,512),\n",
    "                 scale=1,\n",
    "                 val_length=None, \n",
    "                 val_seed=42, \n",
    "                 deconv=True,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        store_attr('files, label_path, tile_shape, scale, val_seed')\n",
    "        self.data = zarr.open_group(self.files[0].parent.as_posix())\n",
    "        self.labels = zarr.open_group(label_path)\n",
    "        self.output_shape = self.tile_shape\n",
    "        self.tiler = DeformationField(self.tile_shape, scale=self.scale)\n",
    "        self.image_indices = []\n",
    "        self.image_shapes = []\n",
    "        self.centers = []\n",
    "        self.valid_indices = None\n",
    "\n",
    "        j = 0\n",
    "        self.deconv = False\n",
    "        if deconv: \n",
    "            self.dkv = Deconvolution()\n",
    "            self.dkv_stats = {}\n",
    "            \n",
    "        for i, file in enumerate(progress_bar(self.files, leave=False)):\n",
    "            img = self.data[file.name]\n",
    "            \n",
    "            # Tiling\n",
    "            data_shape = tuple(int(x//self.scale) for x in img.shape[:-1])\n",
    "            start_points = [o//2 for o in self.output_shape]\n",
    "            end_points = [(s - st) for s, st in zip(data_shape, start_points)]\n",
    "            n_points = [int((s)//(o))+1 for s, o in zip(data_shape, self.output_shape)]\n",
    "            center_points = [np.linspace(st, e, num=n, endpoint=True, dtype=np.int64) for st, e, n in zip(start_points, end_points, n_points)]\n",
    "            # temp variable for deconv calculation\n",
    "            image_centers = []\n",
    "            for cx in center_points[1]:\n",
    "                for cy in center_points[0]:\n",
    "                    self.centers.append((int(cy*self.scale), int(cx*self.scale)))\n",
    "                    image_centers.append((int(cy*self.scale), int(cx*self.scale)))\n",
    "                    self.image_indices.append(i)\n",
    "                    self.image_shapes.append(data_shape)\n",
    "                    j += 1\n",
    "            \n",
    "            # Augmedical TFMS\n",
    "            if deconv:\n",
    "                count = 0\n",
    "                t = []\n",
    "                shuffle(image_centers)\n",
    "                for center in tqdm(image_centers, leave=False):\n",
    "                    t.append(self.tiler.apply(img, center))\n",
    "                \n",
    "                self.dkv_stats[file.stem] = self.dkv.fit(t)\n",
    "        \n",
    "        if deconv: \n",
    "            self.deconv = True\n",
    "            print(self.dkv_stats)\n",
    "        \n",
    "        if val_length:\n",
    "            if val_length>len(self.image_shapes):\n",
    "                print(f'Reducing validation from lenght {val_length} to {len(self.image_shapes)}')\n",
    "                val_length = len(self.image_shapes)\n",
    "            np.random.seed(self.val_seed)\n",
    "            choice = np.random.choice(len(self.image_indices), val_length, replace=False)\n",
    "            self.valid_indices = {i:idx for i, idx in  enumerate(choice)}\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.valid_indices: return len(self.valid_indices)\n",
    "        else: return len(self.image_shapes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if self.valid_indices: idx = self.valid_indices[idx]\n",
    "        img_path = self.files[self.image_indices[idx]]\n",
    "        img = self.data[img_path.name]\n",
    "        centerPos = self.centers[idx]\n",
    "        X = self.tiler.apply(img, centerPos)\n",
    "        \n",
    "        if self.deconv:\n",
    "            d_mean,  d_std = self.dkv_stats[img_path.name]\n",
    "            X = self.dkv.apply(X, d_mean, 2*d_std)\n",
    "            X = np.clip(X, a_min=-5, a_max=5)\n",
    "            \n",
    "        X = X.transpose(2, 0, 1).astype('float32')\n",
    "        \n",
    "        lbl = self.labels[img_path.name]\n",
    "        Y = self.tiler.apply(lbl, centerPos, (0,0), order=0).astype('int64')\n",
    "        \n",
    "        return  TensorImage(X), TensorMask(Y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:28.976850Z",
     "iopub.status.busy": "2021-07-07T03:46:28.976530Z",
     "iopub.status.idle": "2021-07-07T03:46:28.989259Z",
     "shell.execute_reply": "2021-07-07T03:46:28.988219Z",
     "shell.execute_reply.started": "2021-07-07T03:46:28.976818Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_batch(batch):\n",
    "    fig, axs = plt.subplots(4,4, figsize=(20,20))   \n",
    "    images = batch[0].cpu().numpy()\n",
    "    labels = batch[1].cpu().numpy()\n",
    "\n",
    "    for i in range(16):     \n",
    "        axs[i%4, i//4].imshow(images[i, 1])\n",
    "        axs[i%4, i//4].imshow(labels[i], alpha=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(batch[0][:,0].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.hist(batch[0][:,1].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.hist(batch[0][:,2].cpu().numpy().flatten(), bins=100, alpha=0.5)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:39.833958Z",
     "iopub.status.busy": "2021-07-07T03:46:39.833601Z",
     "iopub.status.idle": "2021-07-07T03:46:39.841403Z",
     "shell.execute_reply": "2021-07-07T03:46:39.840273Z",
     "shell.execute_reply.started": "2021-07-07T03:46:39.833922Z"
    }
   },
   "outputs": [],
   "source": [
    "dc = TorchLoss(smp.losses.DiceLoss(mode='multiclass', classes=[1]))\n",
    "ce = CrossEntropyLossFlat(axis=1) #TorchLoss(smp.losses.SoftCrossEntropyLoss(smooth_factor=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_model_weights(model, file, strict=True):\n",
    "    state = torch.load(file, map_location='cpu')\n",
    "    stats = state['stats']\n",
    "    model_state = state['model']\n",
    "    model.load_state_dict(model_state, strict=strict)\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Step 3 - Set configuration for model training </h6> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T03:46:41.991303Z",
     "iopub.status.busy": "2021-07-07T03:46:41.990873Z",
     "iopub.status.idle": "2021-07-07T03:46:42.242517Z",
     "shell.execute_reply": "2021-07-07T03:46:42.240807Z",
     "shell.execute_reply.started": "2021-07-07T03:46:41.991263Z"
    }
   },
   "outputs": [],
   "source": [
    "# from augmentation import Desaturation, GaussianBlur, ChannelBleaching, StainShift\n",
    "\n",
    "class CONFIG():\n",
    "    # paths\n",
    "    path = Path(r'../../../Colonic_crypt_dataset/')\n",
    "    data_path = Path('../../../Colonic_crypt_dataset/zarr/images_scale2')\n",
    "    annotations_path = Path('../../../Colonic_crypt_dataset/zarr/masks_scale2')\n",
    "    model_path = r'models'\n",
    "    model_path_transfer_learning = r'models_trained_kidney/unet_model-scale3.pth' \n",
    "    \n",
    "    # deepflash2 dataset\n",
    "    scale = 1.5 # data is already downscaled to 2, so absolute downscale is 3\n",
    "    tile_shape = (512, 512)\n",
    "    sample_multiplier = 100 # Sample 100 tiles from each image, per epoch\n",
    "    val_length = 500 # Randomly sample 500 validation tiles\n",
    "    stats = np.array([ 0.0241, -0.0148,  0.0236]), np.array([0.4777, 0.5113, 0.4935]) \n",
    "    \n",
    "    # pytorch model (segmentation_models_pytorch)\n",
    "    encoder_name = \"efficientnet-b2\"\n",
    "    encoder_weights = 'imagenet'\n",
    "    in_channels = 3\n",
    "    classes = 2\n",
    "    \n",
    "    # Training\n",
    "    n_splits = 5\n",
    "    mixed_precision_training = True\n",
    "    batch_size = 32\n",
    "    weight_decay = 1e-4 # CHANGED FROM 0.00\n",
    "    loss_func = JointLoss(dc, ce, 1, 1)\n",
    "    metrics = [Dice(), Iou(), Recall(), Precision()]\n",
    "    max_learning_rate = 1e-3\n",
    "    epochs = 10 # CHANGED FROM 10\n",
    "    num_frozen_layers = 0 #168\n",
    "    transfer_learning = False\n",
    "    \n",
    "cfg = CONFIG()\n",
    "\n",
    "# Albumentations augmentations\n",
    "tfms = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomContrast(),\n",
    "        A.RandomGamma(),\n",
    "        A.RandomBrightness(),\n",
    "        ], p=0.3),\n",
    "    A.OneOf([\n",
    "        A.Blur(blur_limit=3, p=1),\n",
    "        A.MedianBlur(blur_limit=3, p=1)\n",
    "    ], p=.1),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(0.002, p=.5),\n",
    "        A.IAAAffine(p=.5),\n",
    "    ], p=.1),\n",
    "    # Additional position augmentations\n",
    "    A.RandomRotate90(p=.5),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "    A.VerticalFlip(p=.5),\n",
    "    A.Cutout(num_holes=10,fill_value=255, \n",
    "             max_h_size=int(.1 * cfg.tile_shape[0]), \n",
    "             max_w_size=int(.1 * cfg.tile_shape[0]), \n",
    "             p=.1),\n",
    "])\n",
    "\n",
    "# augmedical_transforms = [\n",
    "#     Desaturation(p=0.0625, max_desaturation=0.25, max_value_reduction=0.25),\n",
    "#     #Stamping(path=\"../input/augmentation-images\", files=range(1,24), p=cfg.stamping_p, intensity=cfg.stamping_intensity),\n",
    "\n",
    "#     GaussianBlur(channels=3, p=0.1, kernel_size=3, alpha=0.25),\n",
    "#     GaussianBlur(channels=3, p=0.0625, kernel_size=23, alpha=0.5),\n",
    "\n",
    "#     ChannelBleaching(channel=3, p=0.25, min_bleach=0.1, max_bleach=0.25, force_channel=1),\n",
    "#     ChannelBleaching(channel=3, p=0.0625, min_bleach=0.1, max_bleach=0.5, force_channel=2),\n",
    "#     ChannelBleaching(channel=3, p=0.0625, min_bleach=0.1, max_bleach=0.5, force_channel=0),\n",
    "\n",
    "#     #ChannelBlackout(channel=3, p=0.005),\n",
    "#     StainShift(channel=3, p=0.25, min_shift=1, max_shift=7, force_channel=0),\n",
    "#     StainShift(channel=3, p=0.25, min_shift=1, max_shift=7, force_channel=2)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Position Augmentations\n",
    "position_augmentation_kwargs = {\n",
    "    'flip':True,                                \n",
    "    'rotation_range_deg':(0, 360),     \n",
    "    'deformation_grid': (150,150), \n",
    "    'deformation_magnitude':(10,10),\n",
    "    'value_minimum_range':(0, 0), \n",
    "    'value_maximum_range':(1, 1), \n",
    "    'value_slope_range':(1, 1)}\n",
    "\n",
    "# Datasets\n",
    "ds_kwargs = {\n",
    "    'label_path': (cfg.annotations_path/'labels').as_posix(),\n",
    "    'cdf_path': (cfg.annotations_path/'cdfs').as_posix(),\n",
    "    'df_stats': pd.read_csv(cfg.annotations_path/'roi_stats.csv', index_col=[0,1]),\n",
    "    'tile_shape':cfg.tile_shape,\n",
    "    'scale': cfg.scale,\n",
    "    'val_length':cfg.val_length, \n",
    "    'sample_multiplier':cfg.sample_multiplier,\n",
    "    'albumentations_tfms': tfms,\n",
    "   # \"augmedical_transforms\": augmedical_transforms\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(cfg.path/'train.csv')\n",
    "df_train = df_train.rename(columns={\"predicted\":\"encoding\"})\n",
    "df_train = df_train[df_train.id != 'HandE_B005_CL_b_RGB_topright']\n",
    "\n",
    "df_info = pd.read_csv(cfg.path/'colon-dataset_information.csv')\n",
    "files = L([cfg.data_path/x for x in df_train.id])\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Step 4 - Start k-fold training </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(cfg.n_splits, shuffle=True, random_state=42)\n",
    "MODELS = [name for name in glob.glob(cfg.model_path+'/*.pth')]\n",
    "print (kf, MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, (train_idx, val_idx) in enumerate(kf.split(files)):\n",
    "    files_train, files_val = files[train_idx], files[val_idx]\n",
    "    print('Training on', [x.name for x in files_train])\n",
    "    \n",
    "    # Datasets\n",
    "    train_ds = HubmapRandomTileDataset(files_train, **ds_kwargs, **position_augmentation_kwargs)\n",
    "    valid_ds = HubmapValidationDataset(files_val, **ds_kwargs)\n",
    "    \n",
    "    # Model\n",
    "    model = smp.Unet(encoder_name=cfg.encoder_name, \n",
    "                     encoder_weights=cfg.encoder_weights, \n",
    "                     in_channels=cfg.in_channels, \n",
    "                     classes=cfg.classes)\n",
    "    \n",
    "    if cfg.transfer_learning:\n",
    "        print(\"Transfer learning: True\")\n",
    "        m_path = cfg.model_path_transfer_learning\n",
    "        model, stats = load_model_weights(model, m_path)\n",
    "    print(\"Done\")\n",
    "\n",
    "    val = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name)\n",
    "        if val == cfg.num_frozen_layers:\n",
    "            break    \n",
    "        else:\n",
    "        #if \"encoder\" in name:\n",
    "        #    print(\"Frozen: \", name)\n",
    "            param.requires_grad = False\n",
    "        val+=1\n",
    "    \n",
    "    count_frozen = 0\n",
    "    count_unfrozen = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == False:\n",
    "            count_frozen +=1 \n",
    "        else:\n",
    "            count_unfrozen += 1\n",
    "    \n",
    "    print(f\"Number of frozen layers: {count_frozen}\")\n",
    "    print(f\"Number of unfrozen layers: {count_unfrozen}\")\n",
    "    \n",
    "    # Dataloader and learner\n",
    "    dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=cfg.batch_size, after_batch=Normalize.from_stats(*cfg.stats))\n",
    "    if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "    \n",
    "    if i==0: \n",
    "        show_batch(dls.one_batch())\n",
    "        \n",
    "    run = wandb.init(project='bricknet', reinit=True, config=cfg, name=f\"default_with_phils_augment_{i}\")\n",
    "\n",
    "    cbs = [SaveModelCallback(monitor='dice'), ElasticDeformCallback, WandbCallback(log_preds=False, log_model=False)]\n",
    "    learn = Learner(dls, model, metrics=cfg.metrics, wd=cfg.weight_decay, loss_func=cfg.loss_func, opt_func=ranger, cbs=cbs)\n",
    "    if cfg.mixed_precision_training: learn.to_fp16()\n",
    "    \n",
    "    print (\"Start model fitting\", learn)\n",
    "    # Fit\n",
    "    learn.fit_one_cycle(cfg.epochs, lr_max=cfg.max_learning_rate)\n",
    "    learn.recorder.plot_metrics()\n",
    "    \n",
    "    # Save Model\n",
    "    print (\"Saving Model\")\n",
    "    state = {'model': learn.model.state_dict(), 'stats':cfg.stats}\n",
    "    torch.save(state, f'models/unet_{cfg.encoder_name}_{i}.pth', pickle_protocol=2, _use_new_zipfile_serialization=False)\n",
    "    print (\"Model Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
