{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp losses\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses\n",
    "\n",
    "> Implements custom loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *\n",
    "from fastai.torch_core import TensorImage, TensorMask\n",
    "from deepflash2.utils import import_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fastai.torch_core import TensorBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Softmax Cross Entropy Loss\n",
    "\n",
    "as described by Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70.\n",
    "\n",
    "\n",
    "- `axis` for softmax calculations. Defaulted at 1 (channel dimension).\n",
    "- `reduction` will be used when we call `Learner.get_preds`\n",
    "- `activation` function will be applied on the raw output logits of the model when calling `Learner.get_preds` or `Learner.predict`\n",
    "- `decodes` function converts the output of the model to a format similar to the target (here binary masks). This is used in `Learner.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WeightedSoftmaxCrossEntropy(torch.nn.Module):\n",
    "    \"Weighted Softmax Cross Entropy loss functions\"\n",
    "    def __init__(self, *args, axis=-1, reduction = 'mean'):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        self.axis = axis\n",
    "    \n",
    "    def _contiguous(self,x): return TensorBase(x.contiguous())\n",
    "    def forward(self, inp, targ, weights):\n",
    "    \n",
    "        inp, targ  = map(self._contiguous, (inp, targ))\n",
    "        # Weighted soft-max cross-entropy loss\n",
    "        loss = F.cross_entropy(inp, targ, reduction='none')\n",
    "        loss = loss * weights\n",
    "        if  self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def decodes(self, x): return x.argmax(dim=self.axis)\n",
    "    def activation(self, x): return F.softmax(x, dim=self.axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a segmentation task, we want to take the softmax over the channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "tst = WeightedSoftmaxCrossEntropy(axis=1)\n",
    "output = TensorImage(torch.randn(4, 5, 356, 356, requires_grad=True))\n",
    "targets = TensorMask(torch.ones(4, 356, 356).long())\n",
    "weights = torch.randn(4, 356, 356)\n",
    "loss = tst(output, targets, weights)\n",
    "test_eq(loss.detach().numpy(), -0.002415925730019808)\n",
    "test_eq(tst.activation(output), F.softmax(output, dim=1))\n",
    "test_eq(tst.decodes(output), output.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kornia Segmentation Losses Integration\n",
    "\n",
    "Helper functions to load segmentation losses from [kornia](https://github.com/kornia/kornia). \n",
    "Read the [docs](https://kornia.readthedocs.io/en/latest/losses.html#module) for a detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def load_kornia_loss(loss_name, alpha=0.5, beta=0.5, gamma=2.0, reduction='mean', eps = 1e-08):\n",
    "    'Load segmentation_models_pytorch model'\n",
    "    kornia = import_package('kornia')\n",
    "    if loss_name==\"DiceLoss\": return kornia.losses.DiceLoss(eps=eps)\n",
    "    elif loss_name==\"TverskyLoss\": \n",
    "        return kornia.losses.TverskyLoss(alpha=alpha, beta=beta, eps=eps)\n",
    "    elif loss_name==\"FocalLoss\": \n",
    "        return kornia.losses.FocalLoss(alpha=alpha, gamma=gamma, reduction=reduction, eps=eps)\n",
    "    else: raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = TensorImage(torch.randn(4, 5, 356, 356, requires_grad=True))\n",
    "targets = TensorMask(torch.ones(4, 356, 356).long())\n",
    "tst = load_kornia_loss(\"TverskyLoss\", alpha=0.5, beta=0.5) # equals dice loss\n",
    "loss = tst(output, targets)\n",
    "tst2 = load_kornia_loss(\"DiceLoss\")\n",
    "loss2 = tst2(output, targets)\n",
    "test_eq(loss.detach().numpy(), loss2.detach().numpy())\n",
    "\n",
    "tst3 = load_kornia_loss(\"FocalLoss\")\n",
    "loss3 = tst3(output, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 02a_transforms.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 04_callbacks.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted deepflash2.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
