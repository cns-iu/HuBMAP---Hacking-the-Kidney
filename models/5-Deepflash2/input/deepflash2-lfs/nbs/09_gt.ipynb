{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp gt\n",
    "from nbdev.showdoc import show_doc, add_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Estimation\n",
    "\n",
    "> Implements functions for ground truth estimation from the annotations of multiple experts. Based on [SimpleITK](http://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/Python_html/34_Segmentation_Evaluation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "from deepflash2.gui import _get_expert_sample_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "import imageio, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from fastcore.basics import GetAttr\n",
    "from fastprogress import progress_bar\n",
    "from fastai.data.transforms import get_image_files\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepflash2.data import _read_msk\n",
    "from deepflash2.learner import Config\n",
    "from deepflash2.utils import save_mask, iou, install_package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing [SimpleITK](http://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/Python_html/34_Segmentation_Evaluation.html), which is not a dependency of `deepflash2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def import_sitk():\n",
    "    try:\n",
    "        import SimpleITK\n",
    "        assert SimpleITK.Version_MajorVersion()==2\n",
    "    except:\n",
    "        print('Installing SimpleITK. Please wait.')\n",
    "        install_package(\"SimpleITK==2.0.2\")\n",
    "    import SimpleITK\n",
    "    return SimpleITK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simultaneous truth and performance level estimation (STAPLE) \n",
    "\n",
    "The STAPLE algorithm considers a collection of segmentations and computes a probabilistic estimate of the true segmentation and a measure of the performance level represented by each segmentation. \n",
    "\n",
    "_Source: Warfield, Simon K., Kelly H. Zou, and William M. Wells. \"Simultaneous truth and performance level estimation (STAPLE): an algorithm for the validation of image segmentation.\" IEEE transactions on medical imaging 23.7 (2004): 903-921_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "def staple(segmentations, foregroundValue = 1, threshold = 0.5):\n",
    "    'STAPLE: Simultaneous Truth and Performance Level Estimation with simple ITK'\n",
    "    sitk = import_sitk()\n",
    "    segmentations = [sitk.GetImageFromArray(x) for x in segmentations]\n",
    "    STAPLE_probabilities = sitk.STAPLE(segmentations)\n",
    "    STAPLE = STAPLE_probabilities > threshold\n",
    "    #STAPLE = sitk.GetArrayViewFromImage(STAPLE)\n",
    "    return sitk.GetArrayFromImage(STAPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting\n",
    "Use majority voting to obtain the reference segmentation. Note that this filter does not resolve ties. In case of ties it will assign the backgtound label (0) to the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "def m_voting(segmentations, labelForUndecidedPixels = 0):\n",
    "    'Majority Voting from  simple ITK Label Voting'\n",
    "    sitk = import_sitk()\n",
    "    segmentations = [sitk.GetImageFromArray(x) for x in segmentations]\n",
    "    mv_segmentation = sitk.LabelVoting(segmentations, labelForUndecidedPixels)\n",
    "    return sitk.GetArrayFromImage(mv_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GT Estimator\n",
    "\n",
    "Class for ground truth estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def msk_show(ax, msk, title, cbar=None, ticks=None, **kwargs):\n",
    "    img = ax.imshow(msk, **kwargs)\n",
    "    if cbar is not None:\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        if cbar=='plot': \n",
    "            scale = ticks/(ticks+1)\n",
    "            cbr = plt.colorbar(img, cax=cax, ticks=[i*(scale)+(scale/2) for i in range(0, ticks+1)])\n",
    "            cbr.set_ticklabels([i for i in range(0, ticks+1)])\n",
    "            cbr.set_label('# of experts', rotation=270, labelpad=+15, fontsize=\"larger\")\n",
    "        else: cax.set_axis_off()\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(title)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "class GTEstimator(GetAttr):\n",
    "    \"Class for ground truth estimation\"\n",
    "    _default = 'config' \n",
    "    \n",
    "    def __init__(self, exp_dir='expert_segmentations', config=None, path=None, cmap='viridis' , verbose=1):\n",
    "        self.exp_dir = exp_dir\n",
    "        self.config = config or Config()\n",
    "        self.path = Path(path) if path is not None else Path('.')\n",
    "        self.mask_fn = lambda exp,msk: self.path/self.exp_dir/exp/msk\n",
    "        self.cmap = cmap\n",
    "        self.gt = {}\n",
    "        \n",
    "        f_list = get_image_files(self.path/self.exp_dir)\n",
    "        assert len(f_list)>0, f'Found {len(f_list)} masks in \"{self.path/self.exp_dir}\". Please check your masks and expert folders.'\n",
    "        ass_str = f'Found unexpected folder structure in {self.path/self.exp_dir}. Please check your provided masks and folders.'\n",
    "        assert len(f_list[0].relative_to(self.path/self.exp_dir).parents)==2, ass_str\n",
    "              \n",
    "        self.masks = {}\n",
    "        self.experts = []\n",
    "        for m in sorted(f_list):\n",
    "            exp = m.parent.name\n",
    "            if m.name in self.masks:\n",
    "                self.masks[m.name].append(exp)\n",
    "            else:\n",
    "                self.masks[m.name] = [exp]\n",
    "            self.experts.append(exp)\n",
    "        self.experts = sorted(set(self.experts))\n",
    "        if verbose>0: print(f'Found {len(self.masks)} unique segmentation mask(s) from {len(self.experts)} expert(s)')\n",
    "                   \n",
    "    def show_data(self, max_n=6, files=None, figsize=None, **kwargs):\n",
    "        if files is not None:\n",
    "            files = [(m,self.masks[m]) for m in files]\n",
    "        else:\n",
    "            max_n = min((max_n, len(self.masks)))\n",
    "            files = list(self.masks.items())[:max_n]\n",
    "        if not figsize: figsize = (len(self.experts)*3,3)\n",
    "        for m, exps in files:\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=len(exps), figsize=figsize, **kwargs)\n",
    "            for i, exp in enumerate(exps):\n",
    "                msk = _read_msk(self.mask_fn(exp,m))\n",
    "                msk_show(axs[i], msk, exp, cmap=self.cmap)\n",
    "            fig.text(0, .5, m, ha='center', va='center', rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    def gt_estimation(self, method='STAPLE', save_dir=None, filetype='.png', **kwargs):\n",
    "        assert method in ['STAPLE', 'majority_voting']\n",
    "        res = []\n",
    "        refs = {}\n",
    "        print(f'Starting ground truth estimation - {method}')\n",
    "        for m, exps in progress_bar(self.masks.items()):\n",
    "            masks = [_read_msk(self.mask_fn(exp,m)) for exp in exps]\n",
    "            if method=='STAPLE': \n",
    "                ref = staple(masks, self.staple_fval, self.staple_thres)\n",
    "            elif method=='majority_voting':\n",
    "                ref = m_voting(masks, self.mv_undec)\n",
    "            refs[m] = ref\n",
    "            #assert ref.mean() > 0, 'Please try again!'\n",
    "            df_tmp = pd.DataFrame({'method': method, 'file' : m, 'exp' : exps, 'iou': [iou(ref, msk) for msk in masks]})\n",
    "            res.append(df_tmp)\n",
    "            if save_dir:  \n",
    "                path = self.path/save_dir\n",
    "                path.mkdir(exist_ok=True, parents=True)\n",
    "                save_mask(ref, path/Path(m).stem, filetype)\n",
    "        self.gt[method] = refs\n",
    "        self.df_res = pd.concat(res)\n",
    "        self.df_agg = self.df_res.groupby('exp').agg(average_iou=('iou', 'mean'), std_iou=('iou', 'std'))\n",
    "        if save_dir: \n",
    "            self.df_res.to_csv(path.parent/f'{method}_vs_experts.csv', index=False)\n",
    "            self.df_agg.to_csv(path.parent/f'{method}_vs_experts_agg.csv', index=False)\n",
    "            \n",
    "    def show_gt(self, method='STAPLE', max_n=6, files=None, figsize=(15,5), **kwargs):\n",
    "        if not files: files = list(t.masks.keys())[:max_n]\n",
    "        for f in files:\n",
    "            fig, ax = plt.subplots(ncols=3, figsize=figsize, **kwargs)\n",
    "            # GT\n",
    "            msk_show(ax[0], self.gt[method][f], f'{method} (binary mask)', cbar='', cmap=self.cmap)\n",
    "            # Experts\n",
    "            masks = [_read_msk(self.mask_fn(exp,f)) for exp in self.masks[f]]\n",
    "            masks_av = np.array(masks).sum(axis=0)#/len(masks)\n",
    "            msk_show(ax[1], masks_av, 'Expert Overlay', cbar='plot', ticks=len(masks), cmap=plt.cm.get_cmap(self.cmap, len(masks)+1))\n",
    "            # Results\n",
    "            av_df = pd.DataFrame([self.df_res[self.df_res.file==f][['iou']].mean()], index=['average'], columns=['iou'])\n",
    "            plt_df = self.df_res[self.df_res.file==f].set_index('exp')[['iou']].append(av_df)\n",
    "            plt_df.columns = [f'Similarity (iou)']\n",
    "            tbl = pd.plotting.table(ax[2], np.round(plt_df,3), loc='center', colWidths=[.5])\n",
    "            tbl.set_fontsize(14)\n",
    "            tbl.scale(1, 2)\n",
    "            ax[2].set_axis_off()\n",
    "            fig.text(0, .5, f, ha='center', va='center', rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".tooltip {\n",
       "  position: relative;\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".tooltip .tooltiptext {\n",
       "  visibility: hidden;\n",
       "  width: max-content;\n",
       "  max-width: 280px;\n",
       "  background-color: #00bcd4;\n",
       "  text-align: left;\n",
       "  color: white;\n",
       "  border-radius: 4px;\n",
       "  padding: 4px 4px;\n",
       "  border: solid 0px black;\n",
       "  line-height: 1em;\n",
       "\n",
       "  /* Position the tooltip */\n",
       "  position: absolute;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".tooltip:hover .tooltiptext {\n",
       "  visibility: visible;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_dir = Path('deepflash2/sample_data/expert_segmentations')\n",
    "_get_expert_sample_masks(exp_dir)\n",
    "files=['0004_mask.png', '0001_mask.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = GTEstimator(exp_dir=exp_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.show_data(files=files);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.gt_estimation()\n",
    "t.show_gt(files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.gt_estimation(method='majority_voting', save_dir='mv_test')\n",
    "t.show_gt(method='majority_voting', max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
