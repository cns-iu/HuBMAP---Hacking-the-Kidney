{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Information\n",
    "> This Notebook contains information on use of _deepflash2_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Data Structure and Naming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth Estimation \n",
    "- __One parent folder__\n",
    "- __One folder per expert__\n",
    "- __Identical names for segmentations__\n",
    "\n",
    "_Examplary structure:_\n",
    "\n",
    "* [folder] parent_folder\n",
    "    * [folder] expert1\n",
    "        * [file] mask1.png\n",
    "        * [file] mask2.png\n",
    "    * [folder] expert1\n",
    "        * [file] mask1.png\n",
    "        * [file] mask2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "- __One folder for training images__\n",
    "    - Images must have unique name or ID\n",
    "    - _0001.tif --> name/ID: 0001; img_5.png --> name/ID: img_5, ..._ \n",
    "- __One folder for segmentation masks__\n",
    "    - Corresponding masks must start with name or ID + a mask suffix__\n",
    "        - _0001 -> 0001_mask.png (mask_suffix = \"_mask.png\")_\n",
    "        - _0001 -> 0001.png (mask_suffix = \".png\")_\n",
    "        - mask suffix is inferred automatically \n",
    "\n",
    "_Examplary structure:_\n",
    "* [folder] images\n",
    "  * [file] 0001.tif\n",
    "  * [file] 0002.tif\n",
    "* [folder] masks\n",
    "  * [file] 0001_mask.png\n",
    "  * [file] 0002_mask.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "- __One folder for training images__\n",
    "    - Images must have unique name or ID\n",
    "        - _0001.tif --> name/ID: 0001; img_5.png --> name/ID: img_5, ..._ \n",
    "- __One folder containing trained models (ensemble)__\n",
    "    - Ensemble folder and models will be created during Training__\n",
    "        - Do not change the naming of the models\n",
    "        - If you want to train different ensembles, simply rename the ensemble folder\n",
    "\n",
    "_Examplary structure:_\n",
    "* [folder] images\n",
    "  * [file] 0001.tif\n",
    "  * [file] 0002.tif\n",
    "* [folder] ensemble\n",
    "  * [file] unext50_deepflash2_model-1.pth\n",
    "  * [file] unext50_deepflash2_model-2.pth\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation-split\n",
    "\n",
    "The train-validation-split is defined as _[k-fold cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)_ with `n_splits`\n",
    "- `n_splits` is the minimum of: (number of files in dataset,  `max_splits` (default:5))\n",
    "- By default, the number of models per ensemble is limited to `n_splits`\n",
    "\n",
    "_Example for a dataset containing 15 images_\n",
    "- `model_1` is trained on 12 images (3 validation images) \n",
    "- `model_2` is trained on 12 images (3 different validation images) \n",
    "- ...\n",
    "- `model_5` is trained on 12 images (3 different validation images) \n",
    "\n",
    "_Example for a dataset containing 2 images_\n",
    "- `model_1` is trained on 1 image (1 validation image) \n",
    "- `model_2` is trained on 1 images (1 different validation image) \n",
    "- Only two models per ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Epochs and Iterations\n",
    "\n",
    "To streamline the training process and allow an easier comparison across differently sized datasets, we decided to use the number of training _iterations_ instead of _epochs_ to define the lenght of a [training cycle](https://matjesg.github.io/deepflash2/utils.html#calc_iterations).\n",
    "\n",
    "Some useful definitions (adapted from [stackoverflow](https://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks)):\n",
    "- Epoch: one training pass (forward pass and one backward pass) of all the training examples\n",
    "- Batch size: the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
    "- Iteration: One forward pass and one backward pass using [batch size] number of examples.\n",
    "\n",
    "_Example:_\n",
    "Your dataset comprises 20 images and you want to train for 1000 iterations given a batch size of 4. The [algorithm](https://matjesg.github.io/deepflash2/utils.html#calc_iterations) calculates the minimum of epochs needed to train 1000 iterations):\n",
    "\n",
    "$Epochs = \\frac{iterations}{\\frac{\\#images}{batch size}} = \\frac{1000}{\\frac{20}{4}} = 200$\n",
    "\n",
    "The number of epochs will be ceiled to the next integer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
