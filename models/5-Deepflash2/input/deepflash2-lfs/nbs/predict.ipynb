{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEk4DlRqWZgT"
   },
   "source": [
    "# Prediction on new data (Legacy Version)\n",
    "\n",
    "> Notebook to predict the segmentation masks on new data using pretrained or customized models. \n",
    "\n",
    "This notebook is optmizied to be executed on [Google Colab](https://colab.research.google.com).\n",
    "\n",
    "* If youre new on _Google Colab_, try out the [tutorial](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "* Use Firefox or Google Chrome if you want to upload and download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "E3kFC6VYWZgV"
   },
   "outputs": [],
   "source": [
    "#@title Set up environment\n",
    "#@markdown Please run this cell to get started.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "try:\n",
    "    from google.colab import files, drive\n",
    "except ImportError:\n",
    "    pass\n",
    "try:\n",
    "    import deepflash2\n",
    "except ImportError:\n",
    "    !pip install -q deepflash2==0.0.14\n",
    "import zipfile\n",
    "import shutil\n",
    "import imageio\n",
    "from fastai.vision.all import *\n",
    "from deepflash2.all import *\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FIVbRznWZgg"
   },
   "source": [
    "## Provide Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ycDOzIZzWZgh"
   },
   "source": [
    "__Required data structure: One folder for images__ (different from training image folder!)\n",
    "\n",
    "_Examplary structure:_\n",
    "\n",
    "[folder] images_new\n",
    "* [file] 0001.tif\n",
    "* [file] 0002.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8VDvXaEWZgi"
   },
   "source": [
    "### Option A: Upload via _Google Drive_ (recommended, Colab only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IXnmCZ4WZgj"
   },
   "source": [
    "- The folder in your drive must contain all images in one folder.\n",
    "- See [here](https://support.google.com/drive/answer/2375091?co=GENIE.Platform%3DDesktop&hl=en) how to organize your files in _Google Drive_.\n",
    "- See this [stackoverflow post](https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory) for browsing files with the file browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "KyXgfI9oWZgj"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide the path to the folder on your _Google Drive_\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    path = \"/content/drive/My Drive/data\" #@param {type:\"string\"}\n",
    "    path = Path(path)\n",
    "    print('Path contains the following files and folders: \\n', L(os.listdir(path)))\n",
    "    #@markdown Follow the instructions and press Enter after copying and pasting the key.\n",
    "except:\n",
    "    print(\"Warning: Connecting to Google Drive only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJ7STyO1WZgn"
   },
   "source": [
    "### Option B: Upload via _zip_ file (Colab only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQVGRsRgWZgo"
   },
   "source": [
    "- The *zip* file must contain all images in one folder\n",
    "- See [here](https://www.hellotech.com/guide/for/how-to-zip-a-file-mac-windows-pc) how to _zip_ files on Windows or Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "zWSTt-zEWZgp"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to upload a *zip* file\n",
    "path = Path('data')\n",
    "try:\n",
    "    u_dict = files.upload()\n",
    "    for key in u_dict.keys():\n",
    "        unzip(path, key)\n",
    "    print('Path contains the following files and folders: \\n', L(os.listdir(path)))\n",
    "except:\n",
    "    print(\"Warning: File upload only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZcwXGwLWZgu"
   },
   "source": [
    "### Option C: Provide path (Local installation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-S4iYkaWZgu"
   },
   "source": [
    "If you're working on your local machine or server, provide a path to the correct folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "P7G0SnV7WZgv"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide path (either relative to notebook or absolute) and run cell\n",
    "path = \"data\" #@param {type:\"string\"}\n",
    "path = Path(path)\n",
    "print('Path contains the following files and folders: \\n', L(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lD5i-xI8WZg0"
   },
   "source": [
    "###  Option D: Try with sample data (Testing only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vk6wVUhAWZg0"
   },
   "source": [
    "If you don't have any data available yet, try our sample data [Description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "kCleKfcBWZg1"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to use sample files\n",
    "path = Path('sample_data_cFOS')\n",
    "url = \"https://github.com/matjesg/deepflash2/releases/download/model_library/wue1_cFOS_small.zip\"\n",
    "urllib.request.urlretrieve(url, 'sample_data_cFOS.zip')\n",
    "unzip(path, 'sample_data_cFOS.zip')\n",
    "_ = shutil.move(path/'images', path/'images_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qh5wgt8uWZg5"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "XqNjJak8WZg6"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide your parameters according to your provided data\n",
    "image_folder = \"images_new\" #@param {type:\"string\"}\n",
    "f_names = get_image_files(path/image_folder)\n",
    "print(f'Found {len(f_names)} images in \"{path}\".')\n",
    "#@markdown Number of classes: e.g., 2 for binary segmentation (foreground and background class)\n",
    "n_classes = 2 #@param {type:\"integer\"}\n",
    "ds = TileDataset(f_names, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "ecVE9-yAWZg-"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to show data. { run: \"auto\" }\n",
    "#@markdown Use the slider to control the number of displayed images\n",
    "first_n = 3 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "ds.show_data(max_n=first_n, figsize=(5,5), overlay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrPYatoPWZhC"
   },
   "source": [
    "## Model Defintion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIs691SCWZhE"
   },
   "source": [
    "- Select the same [model architecture](https://matjesg.github.io/deepflash2/models.html#U-Net-architectures) as used during [Model Training](https://matjesg.github.io/deepflash2/train.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "DWAGePIsWZhE"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "model_arch = 'unet_deepflash2' #@param [\"unet_deepflash2\",  \"unet_falk2019\", \"unet_ronnberger2015\"]\n",
    "n_channels = ds.get_data(max_n=1)[0].shape[-1]\n",
    "model = torch.hub.load('matjesg/deepflash2', model_arch, pretrained=False, n_classes=ds.c, in_channels=n_channels, force_reload=True)\n",
    "model_list = L()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsDU6yooWZhI"
   },
   "source": [
    "#### Option A: Load customized weights (recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZLFuvKcWZhL"
   },
   "source": [
    "- Works with _Google Drive_ connection or local installation.\n",
    "- If you haven't already done it, train your own models in the [Model Training Notebook](https://colab.research.google.com/github/matjesg/deepflash2/blob/master/nbs/train.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "EhoF3uOjWZhO"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "#@markdown Run to select models from `models_folder`. \n",
    "#@markdown Models should be saved in the 'models' folder of your provided path.\n",
    "models_folder = \"models\" #@param {type:\"string\"}\n",
    "model_list = get_files(path/models_folder, extensions='.pth')\n",
    "print('Found models', model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lhD9hr5bWZhT"
   },
   "source": [
    "#### Option B: Upload customized weights (Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "Ecv0OXB4WZhW"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to upload models. **CAN BE VERY SLOW**. { run: \"auto\" }\n",
    "try:\n",
    "    u_dict = files.upload()\n",
    "    model_list += [Path(u) for u in u_dict]\n",
    "except:\n",
    "    print(\"Warning: File upload only works on Google Colab.\")\n",
    "    pass\n",
    "print('Found models', model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X14tAgiOWZhi"
   },
   "source": [
    "#### Option C: Use pretrained weights from deepflash2 (dangerous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1GHv0_9WZhl"
   },
   "source": [
    "- Out-of-the-box prediction without prior validation can lead to invalid results.\n",
    "- See [Model Libray](https://matjesg.github.io/deepflash2/model_library.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "tcaNz-d3WZhm"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "pretrained_weights = \"wue_cFOS\" #@param [\"wue_cFOS\", \"wue_Parv\", \"wue_GFAP\", \"wue_GFP\", \"wue_OPN3\"]\n",
    "model = torch.hub.load('matjesg/deepflash2', model_arch, pretrained=True, dataset=pretrained_weights, n_classes=ds.c, in_channels=n_channels)\n",
    "model_list = L(Path(f'{torch.hub.get_dir()}/checkpoints/{pretrained_weights}.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwbRKezcWZht"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "0tHbVtTkWZhu"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to predict segmentation masks for new images.\n",
    "res, res_mc = {}, {}\n",
    "for m in progress_bar(model_list):\n",
    "    print(f'Model {m.stem}')\n",
    "    dls = DataLoaders.from_dsets(ds, batch_size=4 ,shuffle=False, drop_last=False)\n",
    "    state_dict = torch.load(m)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "    learn = Learner(dls, model, loss_func=0)#.to_fp16()\n",
    "    \n",
    "    print(f'Predicting segmentation masks')\n",
    "    smxs, segs, _ = learn.predict_tiles(dl=dls.train)   \n",
    "    print(f'Predicting uncertainty maps')\n",
    "    smxs_mc, segs_mc, std = learn.predict_tiles(dl=dls.train, mc_dropout=True, n_times=10)\n",
    "    \n",
    "    #TODO Save results not using RAM\n",
    "    for i, file in enumerate(f_names):\n",
    "        res[(m.stem, file)] = smxs[i], segs[i]\n",
    "        res_mc[(m.stem, file)] = smxs_mc[i], segs_mc[i], std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7TbaTHHWZhz"
   },
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Rr3IvYMWZh0"
   },
   "source": [
    "In this section you can ensemble (combine) the single model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "SKzMhzqMWZh1"
   },
   "outputs": [],
   "source": [
    "#@markdown Create folders to save the resuls. They will be created at your provided 'path'.\n",
    "pred_dir = 'preds' #@param {type:\"string\"}\n",
    "pred_path = path/pred_dir/'ensemble'\n",
    "pred_path.mkdir(parents=True, exist_ok=True)\n",
    "uncertainty_dir = 'uncertainties' #@param {type:\"string\"}\n",
    "uncertainty_path = path/uncertainty_dir/'ensemble'\n",
    "uncertainty_path.mkdir(parents=True, exist_ok=True)\n",
    "result_path = path/'results'\n",
    "result_path.mkdir(exist_ok=True)\n",
    "\n",
    "#@markdown Define `filetype` to save the predictions and uncertainties. All common filetypes are supported.\n",
    "filetype = 'png' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "p2-kwqhmWZh4"
   },
   "outputs": [],
   "source": [
    "#@markdown Show and save ensemble results\n",
    "res_list = []\n",
    "for file in f_names:\n",
    "    img = ds.get_data(file)[0]\n",
    "    pred = ensemble_results(res, file)\n",
    "    pred_std = ensemble_results(res_mc, file, std=True)\n",
    "    df_tmp = pd.Series({'file' : file.name, 'entropy': entropy(pred_std, axis=None)})\n",
    "    plot_results(img, pred, pred_std, df=df_tmp)\n",
    "    res_list.append(df_tmp)\n",
    "    imageio.imsave(pred_path/f'{file.name}_pred.{filetype}', pred.astype(np.uint8) if np.max(pred)>1 else pred.astype(np.uint8)*255)\n",
    "    imageio.imsave(uncertainty_path/f'{file.name}_uncertainty.{filetype}', pred_std.astype(np.uint8)*255)\n",
    "df_res = pd.DataFrame(res_list)\n",
    "df_res.to_csv(result_path/'ensemble_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "4qbtq4M6WZh7"
   },
   "outputs": [],
   "source": [
    "#@markdown Show and save single model results\n",
    "res_list = []\n",
    "for file in f_names:\n",
    "    print(f'###### File {file.name} ######')\n",
    "    img = ds.get_data(file)[0]\n",
    "    for model_path in model_list:\n",
    "        model_name = model_path.stem\n",
    "        val_files = [f for mod , f in res.keys() if mod == model_name]\n",
    "        print(f'{model_name}')\n",
    "        pred_path = path/pred_dir/model_name\n",
    "        pred_path.mkdir(parents=True, exist_ok=True)\n",
    "        uncertainty_path = path/uncertainty_dir/model_name\n",
    "        uncertainty_path.mkdir(parents=True, exist_ok=True)\n",
    "        pred = res[(model_name,file)][1]\n",
    "        pred_std = res_mc[(model_name,file)][2][...,0]\n",
    "        df_tmp = pd.Series({'file' : file.name,\n",
    "                            'model' : model_name,\n",
    "                            'entropy': entropy(pred_std, axis=None)})\n",
    "        plot_results(img, pred, pred_std, df=df_tmp)\n",
    "        res_list.append(df_tmp)\n",
    "        imageio.imsave(pred_path/f'{file.stem}_pred.{filetype}', pred.astype(np.uint8) if np.max(pred)>1 else pred.astype(np.uint8)*255)\n",
    "        imageio.imsave(uncertainty_path/f'{file.stem}_uncertainty.{filetype}', pred_std.astype(np.uint8)*255)\n",
    "pd.DataFrame(res_list).to_csv(result_path/'model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PHZqiB4rWZh-"
   },
   "source": [
    "## Download Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ck3O0OJWZh_"
   },
   "source": [
    "To download validation predictions and uncertainties, you first need to execute Section _Validate models and ensembles_.\n",
    "\n",
    "_Note: If you're connected to *Google Drive*, the models are automatically saved to your drive._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "CqpPqBTQWZiA"
   },
   "outputs": [],
   "source": [
    "#@markdown Download predicitions { run: \"auto\" }\n",
    "out_name = 'predictions'\n",
    "shutil.make_archive(path/out_name, 'zip', path/pred_dir)\n",
    "try:\n",
    "    files.download(path/f'{out_name}.zip')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "RgooRxlCWZiE"
   },
   "outputs": [],
   "source": [
    "#@markdown Download uncertainties\n",
    "out_name = 'uncertainties'\n",
    "shutil.make_archive(path/out_name, 'zip', path/uncertainty_dir)\n",
    "try:\n",
    "    files.download(path/f'{out_name}.zip')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "wMWLHJc8WZiH"
   },
   "outputs": [],
   "source": [
    "#@markdown Download ensemble result analysis '.csv' files\n",
    "try:\n",
    "    files.download(result_path/f'ensemble_results.csv')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "7s7G03YiWZiJ"
   },
   "outputs": [],
   "source": [
    "#@markdown Download model result analysis '.csv' files\n",
    "try:\n",
    "    files.download(result_path/'model_results.csv')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "fJ7STyO1WZgn",
    "KZcwXGwLWZgu",
    "lD5i-xI8WZg0",
    "lhD9hr5bWZhT",
    "X14tAgiOWZhi",
    "PHZqiB4rWZh-"
   ],
   "name": "predict.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
