{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcsetTMwKXqC"
   },
   "source": [
    "# Training (Legacy Version)\n",
    "\n",
    "> Notebook to train deep learning models or ensembles for segmentation of fluorescent labels in microscopy images.\n",
    "\n",
    "This notebook is optmizied to be executed on [Google Colab](https://colab.research.google.com).\n",
    "\n",
    "* If youre new on _Google Colab_, try out the [tutorial](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "* Use Firefox or Google Chrome if you want to upload and download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "BUvjOHtOKXqD"
   },
   "outputs": [],
   "source": [
    "#@title Set up environment\n",
    "#@markdown Please run this cell to get started.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "try:\n",
    "    from google.colab import files, drive\n",
    "except ImportError:\n",
    "    pass\n",
    "try:\n",
    "    import deepflash2\n",
    "except ImportError:\n",
    "    !pip install -q deepflash2==0.0.14\n",
    "import zipfile\n",
    "import shutil\n",
    "import imageio\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from fastai.vision.all import *\n",
    "from deepflash2.all import *\n",
    "from deepflash2.data import _read_msk\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s07wUKrDKXqa"
   },
   "source": [
    "## Provide Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVLr_qIPKXqb"
   },
   "source": [
    "__Required data structure__\n",
    "\n",
    "- __One folder for training images__\n",
    "- __One folder for segmentation masks__\n",
    "    - We highly recommend using [ground truth estimation](https://matjesg.github.io/deepflash2/gt_estimation.html)\n",
    "\n",
    "_Examplary structure: see [naming conventions](https://matjesg.github.io/deepflash2/add_information.html#Naming)_\n",
    "\n",
    "* [folder] images\n",
    "  * [file] 0001.tif\n",
    "  * [file] 0002.tif\n",
    "* [folder] masks\n",
    "  * [file] 0001_mask.png\n",
    "  * [file] 0002_mask.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK7DTJDfKXqc"
   },
   "source": [
    "### Option A: Upload via _Google Drive_ (recommended, Colab only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHgRnxpYKXqc"
   },
   "source": [
    "- The folder in your drive must contain all files and correct folder structure. \n",
    "- See [here](https://support.google.com/drive/answer/2375091?co=GENIE.Platform%3DDesktop&hl=en) how to organize your files in _Google Drive_.\n",
    "- See this [stackoverflow post](https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory) for browsing files with the file browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "CVOsPeNxKXqd"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide the path to the folder on your _Google Drive_\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    path = \"/content/drive/My Drive/data\" #@param {type:\"string\"}\n",
    "    path = Path(path)\n",
    "    print('Path contains the following files and folders: \\n', L(os.listdir(path)))\n",
    "    #@markdown Follow the instructions and press Enter after copying and pasting the key.\n",
    "except:\n",
    "    print(\"Warning: Connecting to Google Drive only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qg0Ni1QRKXqj"
   },
   "source": [
    "### Option B: Upload via _zip_ file (Colab only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nu2YzLuAKXqk"
   },
   "source": [
    "- The *zip* file must contain all images and segmentations and correct folder structure. \n",
    "- See [here](https://www.hellotech.com/guide/for/how-to-zip-a-file-mac-windows-pc) how to _zip_ files on Windows or Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "toUkqU7FKXqn"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to upload a *zip* file\n",
    "path = Path('data')\n",
    "try:\n",
    "    u_dict = files.upload()\n",
    "    for key in u_dict.keys():\n",
    "        unzip(path, key)\n",
    "    print('Path contains the following files and folders: \\n', L(os.listdir(path)))\n",
    "except:\n",
    "    print(\"Warning: File upload only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zpwPtQGsKXqr"
   },
   "source": [
    "### Option C: Provide path (Local installation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qk5mwC-kKXqr"
   },
   "source": [
    "If you're working on your local machine or server, provide a path to the correct folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "93QgoZIQKXqs"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide path (either relative to notebook or absolute) and run cell\n",
    "path = \"\" #@param {type:\"string\"}\n",
    "path = Path(path)\n",
    "print('Path contains the following files and folders: \\n', L(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ym7ZktGpKXq4"
   },
   "source": [
    "###  Option D: Try with sample data (Testing only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rE74lqMFKXq5"
   },
   "source": [
    "If you don't have any data available yet, try our sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "EvSFmLPEKXq5"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to use sample files\n",
    "path = Path('sample_data_cFOS')\n",
    "url = \"https://github.com/matjesg/deepflash2/releases/download/model_library/wue1_cFOS_small.zip\"\n",
    "urllib.request.urlretrieve(url, 'sample_data_cFOS.zip')\n",
    "unzip(path, 'sample_data_cFOS.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quRrAQd0KXrC"
   },
   "source": [
    "## Check and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "ocaY_zSqKXrC"
   },
   "outputs": [],
   "source": [
    "#@markdown Provide your parameters according to your provided data\n",
    "image_folder = \"images\" #@param {type:\"string\"}\n",
    "mask_folder = \"masks\" #@param {type:\"string\"}\n",
    "mask_suffix = \"_mask.png\" #@param {type:\"string\"}\n",
    "#@markdown Number of classes: e.g., 2 for binary segmentation (foreground and background class)\n",
    "n_classes = 2 #@param {type:\"integer\"}\n",
    "#@markdown Check if you are providing instance labels (class-aware and instance-aware)\n",
    "instance_labels = False #@param {type:\"boolean\"}\n",
    "\n",
    "f_names = get_image_files(path/image_folder)\n",
    "label_fn = lambda o: path/mask_folder/f'{o.stem}{mask_suffix}'\n",
    "#Check if corresponding masks exist\n",
    "mask_check = [os.path.isfile(label_fn(x)) for x in f_names]\n",
    "if len(f_names)==sum(mask_check) and len(f_names)>0:\n",
    "    print(f'Found {len(f_names)} images and {sum(mask_check)} masks in \"{path}\".')\n",
    "else:\n",
    "    print(f'IMAGE/MASK MISMATCH! Found {len(f_names)} images and {sum(mask_check)} masks in \"{path}\".')\n",
    "    print('Please check the steps above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzOXPOo7KXrF"
   },
   "source": [
    "### Customize [mask weights](https://matjesg.github.io/deepflash2/data.html#Weight-Calculation) (optional)\n",
    "\n",
    "- Default values should work for most of the data. \n",
    "- However, this choice can significantly change the model performance later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "J8W48jElKXrK"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "#@markdown Run to set weight parameters\n",
    "border_weight_sigma=10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
    "foreground_dist_sigma=10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
    "border_weight_factor=10 #@param {type:\"slider\", min:1, max:50, step:1}\n",
    "foreground_background_ratio= 0.1 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
    "\n",
    "#@markdown Check if want to plot the resulting weights of one mask\n",
    "plot_weights = False #@param {type:\"boolean\"}\n",
    "#@markdown Check `reset_to_defaults` to reset your parameters.\n",
    "reset_to_defaults = False #@param {type:\"boolean\"}\n",
    "\n",
    "mw_dict = {'bws': 10 if reset_to_defaults else border_weight_sigma ,\n",
    "           'fds': 10 if reset_to_defaults else foreground_dist_sigma, \n",
    "           'bwf': 10 if reset_to_defaults else border_weight_factor,\n",
    "           'fbr' : 0.1 if reset_to_defaults else foreground_background_ratio}\n",
    "\n",
    "#@markdown Select image number\n",
    "image_number = 0 #@param {type:\"slider\", min:0, max:100, step:1}\n",
    "if plot_weights:\n",
    "    idx = np.minimum(len(f_names), image_number)\n",
    "    print('Plotting mask for image', f_names[idx].name, '- Please wait.')\n",
    "    msk = _read_msk(label_fn(f_names[idx]))\n",
    "    _, w, _ = calculate_weights(msk, n_dims=n_classes, **mw_dict)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,12))\n",
    "    axes[0].imshow(msk)\n",
    "    axes[0].set_axis_off()\n",
    "    axes[0].set_title('Mask')\n",
    "    axes[1].imshow(w)\n",
    "    axes[1].set_axis_off()\n",
    "    axes[1].set_title('Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IIno15cMslG"
   },
   "source": [
    "### Create mask weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "zLbdVOHMKXrN"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to create mask weights for the whole dataset.\n",
    "try: \n",
    "    mw_dict=mw_dict\n",
    "except:\n",
    "    mw_dict = {'bws': 10,'fds': 10, 'bwf': 10,'fbr' : 0.1}\n",
    "\n",
    "ds = RandomTileDataset(f_names, label_fn, n_classes=n_classes, instance_labels=instance_labels, **mw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "LatF2h2TKXrR"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "#@markdown Run to show data.\n",
    "#@markdown Use the slider to control the number of displayed images\n",
    "first_n = 3 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "ds.show_data(max_n = first_n, figsize=(15,15), overlay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXg6c6hzKXrV"
   },
   "source": [
    "## Model Defintion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqeFq0fhKXrV"
   },
   "source": [
    "Select one of the available [model architectures](https://matjesg.github.io/deepflash2/models.html#U-Net-architectures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "x49wKHqoKXrW"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "model_arch = 'unet_deepflash2' #@param [\"unet_deepflash2\",  \"unet_falk2019\", \"unet_ronnberger2015\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6F0rnC9oKXrj"
   },
   "source": [
    "Pretrained weights \n",
    "- Select 'new' to use an untrained model (no pretrained weights)\n",
    "- Or select [pretraind](https://matjesg.github.io/deepflash2/model_library.html) model weights from dropdown menu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "1P4eoMCeKXrk"
   },
   "outputs": [],
   "source": [
    "pretrained_weights = \"wue_cFOS\" #@param [\"new\", \"wue_cFOS\", \"wue_Parv\", \"wue_GFAP\", \"wue_GFP\", \"wue_OPN3\"]\n",
    "pre = False if pretrained_weights==\"new\" else True\n",
    "n_channels = ds.get_data(max_n=1)[0].shape[-1]\n",
    "model = torch.hub.load('matjesg/deepflash2', model_arch, pretrained=pre, dataset=pretrained_weights, n_classes=ds.c, in_channels=n_channels)\n",
    "if pretrained_weights==\"new\": apply_init(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbUfv4xkKXrs"
   },
   "source": [
    "### Setting model hyperparameters (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVGJnkDDKXru"
   },
   "source": [
    "- *mixed_precision_training*: enables [Mixed precision training](https://docs.fast.ai/callback.fp16#A-little-bit-of-theory)\n",
    "    - decreases memory usage and speed-up training\n",
    "    - may effect model accuracy\n",
    "- *batch_size*: the number of samples that will be propagated through the network during one iteration\n",
    "    - 4 works best in our experiements\n",
    "    - 4-8 works good for [mixed precision training](https://docs.fast.ai/callback.fp16#A-little-bit-of-theory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "xqahl2ONKXrv"
   },
   "outputs": [],
   "source": [
    "mixed_precision_training = False #@param {type:\"boolean\"}\n",
    "batch_size = 4 #@param {type:\"slider\", min:2, max:8, step:2}\n",
    "loss_fn = WeightedSoftmaxCrossEntropy(axis=1)\n",
    "cbs = [ElasticDeformCallback]\n",
    "dls = DataLoaders.from_dsets(ds,ds, bs=batch_size)\n",
    "if torch.cuda.is_available(): dls.cuda(), model.cuda()\n",
    "learn = Learner(dls, model, wd=0.001, loss_func=loss_fn, cbs=cbs)\n",
    "if mixed_precision_training: learn.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcJYGIS8KXr1"
   },
   "source": [
    "- `max_lr`: The learning rate controls how quickly or slowly a neural network model learns.\n",
    "    - We found that a maximum learning rate of 5e-4 (i.e., 0.0005) yielded the best results across experiments.\n",
    "    - `learning_rate_finder`: Check only if you want use the [Learning Rate Finder](https://matjesg.github.io/deepflash2/add_information.html#Learning-Rate-Finder) on your dataset.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "_L-L17XyKXr2"
   },
   "outputs": [],
   "source": [
    "#@markdown Check and run to use learning rate finder\n",
    "learning_rate_finder = False #@param {type:\"boolean\"}\n",
    "if learning_rate_finder:\n",
    "    lr_min,lr_steep = learn.lr_find()\n",
    "    print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "QX8FdsTnKXsE"
   },
   "outputs": [],
   "source": [
    "max_lr = 5e-4 #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TXBRr0v4KXrs"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUu9D2jDQ4ZR"
   },
   "source": [
    "### Setting training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2e55PF5KXsM"
   },
   "source": [
    "- `n_models`: Number of models to train.\n",
    "    - If you're experimenting with parameters, try only one model first.\n",
    "    - Depending on the data, ensembles should comprise 3-5 models.\n",
    "    - _Note: Number of model affects the [Train-validation-split](https://matjesg.github.io/deepflash2/add_information.html#Train-validation-split)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "PqJsqhQdKXsN"
   },
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "try:\n",
    "    batch_size=batch_size\n",
    "except:\n",
    "    batch_size=4\n",
    "    mixed_precision_training = False\n",
    "    loss_fn = WeightedSoftmaxCrossEntropy(axis=1)\n",
    "try:\n",
    "    max_lr=max_lr\n",
    "except:\n",
    "    max_lr = 5e-4 \n",
    "\n",
    "metrics = [Dice_f1(), Iou()]\n",
    "n_models = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n",
    "print(\"Suggested epochs for 1000 iterations:\", calc_iterations(len(ds), batch_size, n_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pVdouyqKXsP"
   },
   "source": [
    "- `epochs`: One epoch is when an entire (augemented) dataset is passed through the model for training.\n",
    "    - Epochs need to be adusted depending on the size and number of images\n",
    "    - We found that choosing the number of epochs such that the network parameters are update about 1000 times (iterations) leads to satiesfying results in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "yX8klm0JKXsQ"
   },
   "outputs": [],
   "source": [
    "epochs = 30 #@param {type:\"slider\", min:1, max:200, step:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71rnYQ6dKXsS"
   },
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "655-lZbWKXsT"
   },
   "outputs": [],
   "source": [
    "#@markdown Run to train model(s).<br/> **THIS CAN TAKE A FEW HOURS FOR MULTIPLE MODELS!**\n",
    "kf = KFold(n_splits=max(n_models,2))\n",
    "model_path = path/'models'\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "res, res_mc = {}, {}\n",
    "fold = 0\n",
    "for train_idx, val_idx in kf.split(f_names):\n",
    "    fold += 1\n",
    "    name = f'model{fold}'\n",
    "    print('Train', name)\n",
    "    if n_models==1:\n",
    "        files_train, files_val = train_test_split(f_names)\n",
    "    else:\n",
    "        files_train, files_val = f_names[train_idx], f_names[val_idx]\n",
    "    print(f'Validation Images: {files_val}')    \n",
    "    train_ds = RandomTileDataset(files_train, label_fn, **mw_dict)\n",
    "    valid_ds = TileDataset(files_val, label_fn, **mw_dict)\n",
    "    \n",
    "    dls = DataLoaders.from_dsets(train_ds, valid_ds, bs=batch_size)\n",
    "    dls_valid = DataLoaders.from_dsets(valid_ds, batch_size=batch_size ,shuffle=False, drop_last=False)\n",
    "    model = torch.hub.load('matjesg/deepflash2', model_arch, pretrained=pre, \n",
    "                           dataset=pretrained_weights, n_classes=ds.c, in_channels=n_channels)\n",
    "    if pretrained_weights==\"new\": apply_init(model)\n",
    "    if torch.cuda.is_available(): dls.cuda(), model.cuda(), dls_valid.cuda()\n",
    "    \n",
    "    cbs = [SaveModelCallback(monitor='iou'), ElasticDeformCallback]\n",
    "    metrics = [Dice_f1(), Iou()]\n",
    "    learn = Learner(dls, model, metrics = metrics, wd=0.001, loss_func=loss_fn, cbs=cbs)\n",
    "    if mixed_precision_training: learn.to_fp16()\n",
    "    learn.fit_one_cycle(epochs, max_lr)\n",
    "    # save_model(model_path/f'{name}.pth', learn.model, opt=None)\n",
    "    torch.save(learn.model.state_dict(), model_path/f'{name}.pth', _use_new_zipfile_serialization=False)\n",
    "    \n",
    "    smxs, segs, _ = learn.predict_tiles(dl=dls_valid.train)    \n",
    "    smxs_mc, segs_mc, std = learn.predict_tiles(dl=dls_valid.train, mc_dropout=True, n_times=10)\n",
    "    \n",
    "    for i, file in enumerate(files_val):\n",
    "        res[(name, file)] = smxs[i], segs[i]\n",
    "        res_mc[(name, file)] = smxs_mc[i], segs_mc[i], std[i]\n",
    "    \n",
    "    if n_models==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RSKf-atKXsW"
   },
   "source": [
    "## Validate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhZLMYH4KXsW"
   },
   "source": [
    "Here you can validate your models. To avoid information leakage, only predictions on the respective models' validation set are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "fY_twaXbKXsX"
   },
   "outputs": [],
   "source": [
    "#@markdown Create folders to save the resuls. They will be created at your provided 'path'.\n",
    "pred_dir = 'val_preds' #@param {type:\"string\"}\n",
    "pred_path = path/pred_dir/'ensemble'\n",
    "pred_path.mkdir(parents=True, exist_ok=True)\n",
    "uncertainty_dir = 'val_uncertainties' #@param {type:\"string\"}\n",
    "uncertainty_path = path/uncertainty_dir/'ensemble'\n",
    "uncertainty_path.mkdir(parents=True, exist_ok=True)\n",
    "result_path = path/'results'\n",
    "result_path.mkdir(exist_ok=True)\n",
    "\n",
    "#@markdown Define `filetype` to save the predictions and uncertainties. All common [file formats](https://imageio.readthedocs.io/en/stable/formats.html) are supported.\n",
    "filetype = 'png' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "60vhGuL1KXse"
   },
   "outputs": [],
   "source": [
    "#@markdown Show and save results\n",
    "res_list = []\n",
    "for model_number in range(1,n_models+1):\n",
    "    model_name = f'model{model_number}'\n",
    "    val_files = [f for mod , f in res.keys() if mod == model_name]\n",
    "    print(f'Validating {model_name}')\n",
    "    pred_path = path/pred_dir/model_name\n",
    "    pred_path.mkdir(parents=True, exist_ok=True)\n",
    "    uncertainty_path = path/uncertainty_dir/model_name\n",
    "    uncertainty_path.mkdir(parents=True, exist_ok=True)\n",
    "    for file in val_files:\n",
    "        img = ds.get_data(file)[0]\n",
    "        msk = ds.get_data(file, mask=True)[0]\n",
    "        pred = res[(model_name,file)][1]\n",
    "        pred_std = res_mc[(model_name,file)][2][...,0]\n",
    "        df_tmp = pd.Series({'file' : file.name,\n",
    "                            'model' : model_name,\n",
    "                            'iou': iou(msk, pred),\n",
    "                            'entropy': entropy(pred_std, axis=None)})\n",
    "        plot_results(img, msk, pred, pred_std, df=df_tmp)\n",
    "        res_list.append(df_tmp)\n",
    "        imageio.imsave(pred_path/f'{file.stem}_pred.{filetype}', pred.astype(np.uint8) if np.max(pred)>1 else pred.astype(np.uint8)*255)\n",
    "        imageio.imsave(uncertainty_path/f'{file.stem}_uncertainty.{filetype}', pred_std.astype(np.uint8)*255)\n",
    "df_res = pd.DataFrame(res_list)\n",
    "df_res.to_csv(result_path/f'val_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqyqRWJdKXsm"
   },
   "source": [
    "## Download Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PRChbNy0KXsn"
   },
   "source": [
    "- The models will always be the _last_ version trained in section _Model Training_\n",
    "- To download validation predictions and uncertainties, you first need to execute section _Validate models_.\n",
    "\n",
    "_Note: If you're connected to *Google Drive*, the models are automatically saved to your drive._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "PixlKHNMKXso"
   },
   "outputs": [],
   "source": [
    "#@title Download models { run: \"auto\" }\n",
    "model_number = \"1\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "model_path = path/'models'/f'model{model_number}.pth'\n",
    "try:\n",
    "    files.download(model_path)\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    print(f\"Models are saved at {model_path.parent}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "LjY1Bur8KXsv"
   },
   "outputs": [],
   "source": [
    "#@markdown Download validation predicitions { run: \"auto\" }\n",
    "out_name = 'val_predictions'\n",
    "shutil.make_archive(path/out_name, 'zip', path/pred_dir)\n",
    "try:\n",
    "    files.download(path/f'{out_name}.zip')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "ir_MaWNfKXsy"
   },
   "outputs": [],
   "source": [
    "#@markdown Download validation uncertainties\n",
    "out_name = 'val_uncertainties'\n",
    "shutil.make_archive(path/out_name, 'zip', path/uncertainty_dir)\n",
    "try:\n",
    "    files.download(path/f'{out_name}.zip')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab_type": "code",
    "id": "ue7bEmJ3KXs0"
   },
   "outputs": [],
   "source": [
    "#@markdown Download result analysis '.csv' files\n",
    "try:\n",
    "    files.download(result_path/f'val_results.csv')\n",
    "except:\n",
    "    print(\"Warning: File download only works on Google Colab.\")\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Qg0Ni1QRKXqj",
    "zpwPtQGsKXqr",
    "Ym7ZktGpKXq4",
    "MzOXPOo7KXrF",
    "zbUfv4xkKXrs",
    "OqyqRWJdKXsm"
   ],
   "name": "train.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
